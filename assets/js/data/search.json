[ { "title": "LeetCode", "url": "/posts/LeetCode/", "categories": "Tutorial, LeetCode", "tags": "leetcode", "date": "2022-07-29 10:00:00 +0800", "snippet": "LeetCode https://leetcode.cn1331. 数组序号转换给你一个整数数组 arr ，请你将数组中的每个元素替换为它们排序后的序号。序号代表了一个元素有多大。序号编号的规则如下： 序号从 1 开始编号。 一个元素越大，那么序号越大。如果两个元素相等，那么它们的序号相同。 每个数字的序号都应该尽可能地小。示例 1：输入：arr = [40,10,20,30]输出：[4,1,2,3]解释：40 是最大的元素。 10 是最小的元素。 20 是第二小的数字。 30 是第三小的数字。示例 2：输入：arr = [100,100,100]输出：[1,1,1]解释：所有元素有相同的序号。示例 3：输入：arr = [37,12,28,9,100,56,80,5,12]输出：[5,3,4,2,8,6,7,1,3]提示： 0 &amp;lt;= arr.length &amp;lt;= 10^5 -10^9 &amp;lt;= arr[i] &amp;lt;= 10^9答案： C++ #include &amp;lt;vector&amp;gt;#include &amp;lt;numeric&amp;gt;#include &amp;lt;algorithm&amp;gt;#include &amp;lt;iostream&amp;gt;using namespace std; vector&amp;lt;int&amp;gt; arrayRankTransform(vector&amp;lt;int&amp;gt; &amp;amp;arr) { vector&amp;lt;int&amp;gt; idx(arr.size()); iota(idx.begin(), idx.end(), 0); sort(idx.begin(), idx.end(), [r = arr.data()](int a, int b){return r[a] &amp;lt; r[b];}); int rk = 0, rear = INT_MIN; for (auto x: idx) { if (arr[x] &amp;gt; rear) ++rk; rear = arr[x]; arr[x] = rk; } return arr;} int main() { vector&amp;lt;int&amp;gt; arr = {37,12,28,9,100,56,80,5,12}; arr = arrayRankTransform(arr); std::cout &amp;lt;&amp;lt; &#39;[&#39;; for (auto &amp;amp;x: arr) std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; &#39;,&#39;; std::cout &amp;lt;&amp;lt; &#39;\\b&#39; &amp;lt;&amp;lt; &#39;]&#39;; return 0;} 难点： iota() 函数构建连续的值，用于构建索引，位于 numeric 头文件；区别 itoa() 把一个整数转换为字符串 sort() 位于 algorithmn 头文件中 lambda 函数基本格式 [capture](parameters) -&amp;gt; return_type { /* ... */ } [capture]: [] 内为外部变量的传递方式，值、引用等，如下 ```c++[] //表示的是在lambda定义之前的域，对外部参数的调用；[=] //表示外部参数直接传值[&amp;amp;] //表示外部参数传引用，可修改值。当默认捕获符是 &amp;amp; 时，后继的简单捕获符必须不以 &amp;amp; 开始。而当默认捕获符是 = 时，后继的简单捕获符必须以 &amp;amp; 开始。[x, &amp;amp;y] //x is captured by value, y is captured by reference[&amp;amp;, x] //x is explicitly captured by value. Other variables will be captured by reference[=, &amp;amp;z] //z is explicitly captured by reference. Other variables will be captured by value``` (parameters): () 内为形参，和普通函数的形参一样。 -&amp;gt; return_type: -&amp;gt; 后面为 lambda 函数的返回类型，如 -&amp;gt; int、-&amp;gt; string等。一般情况下，编译器推出 lambda 函数的返回值，所以这部分可以省略不写。 { /* … */ }: {} 内为函数主体，和普通函数一样。 定义函数指针一般用 auto 或 std::function&amp;lt;return_type(parameters_type)&amp;gt; 用一个 vector 对另一个 vector 排序，把 comp 条件设置为另一个 vector 即可 " }, { "title": "C++ Primer Plus v6", "url": "/posts/C++-primer-plus-v6/", "categories": "Tutorial, C++", "tags": "book, c++", "date": "2022-07-07 09:00:00 +0800", "snippet": "C++ Primer Plus v6 书本即课后习题解答下载链接：链接: https://pan.baidu.com/s/1MiDc2DLKCue9HDVXG9xUiw?pwd=hsmm 提取码: hsmm前言《C++ Primer》和《C++ Primer Plus》都是公认的 C++ 语言的好书，虽然它们的名字相似，但实际上它们是不同的书。笔者虽然没有同时读过两者，但是在前期选择的时候也查过这两本书的区别。   C++ Primer Plus C++ Primer 本质 偏向实践 偏向持续性学习 作者 作者 Prata, S. 是大学教授，是个学术性作家，写的书比较通俗易懂 两位作者都是拥有丰富的开发精力，是实践性作家，写的书比较深入 内容 内容简单详细，层层递进 内容偏向实战，可以对实操给出引导和建议 至于选择哪一本阅读，就看读者自己的安排了。笔者的建议是先阅读《C++ Primer Plus》，夯实基础的知识点，然后在实践中去读《C++ Primer》。这篇笔记针对的是《C++ Primer Plus》第六版，第六版相对于第五版增加了一些 C++11 特性。第一章 预备知识 本章介绍：(1) Bjarne Stroustrup 如何通过在 C 语言的基础上添加对面向对象编程的支持，来创造 C++ 编程语言；(2) 面向过程语言(如 C 语言)与面向对象语言(如 C++ )之间的区别；(3) 创建 C++ 程序的技巧和当前几种 C++ 编译器使用的方法。C++ 是最重要的语言之一，它在 C 语言的基础上： 继承了 C 语言高效、简洁、快速和可移植性的传统。 为了应付日渐复杂的编程任务，增加了面向对象的特性。 提供了另一种全新的编程方法——泛型编程。1.1 C++ 简介C++融合了3种不同的编程方式： C 语言代表的过程性语言 类代表的面向对象语言 C++ 模版支持的范型编程1.2 C++ 简史随着计算机性能的增长，更大更复杂的程序应运而生，这些程序在程序管理和维护方面带来了新的问题。在20世纪70年代， C 和 Pascal 这样的语言引领人们进入了结构化编程时代。除了提供结构化编程工具外， C 还能生成简洁、快速运行的程序，并提供了处理硬件问题的能力，如管理通信端口和磁盘驱动器。这些因素使C 语言成为 20 世纪 80 年代占统治地位的编程语言。与此同时，一种新的编程模式正在快速成长：面向对象编程 OOP 。 SmallTalk 和 C++ 语言具备这种功能。1.2.1 C 语言操作系统是能够管理计算机资源、处理计算机与用户之间交互的一组程序。传统上，程序员使用汇编语言完成设计要求。由于汇编语言时低级 (low-level) 语言，直接操作硬件，因此当这些程序需要移植到另一种计算机上时，必须使用不同的汇编语言重新编写程序。然而， UNIX 操作系统是为了在不同的计算机上工作而设计的，这需要一种高级语言。高级 (high-level) 语言致力于解决问题，而不针对特定的硬件。一种被称为编译器的特殊程序将高级语言翻译成特定计算机的内部语言，这相当于在程序和硬件隔开。 UNIX 设计者 Ritchie 希望有一种语言能将低级语言的效率、硬件访问能力和高级语言的通用性、可移植性融合在一起，于是他在旧语言的基础上开发了 C 语言。1.2.2 C 语言编程原理一般来说，计算机语言要处理两个概念——数据和算法。 数据是程序使用和处理的信息 算法是程序使用的方法为了理解 C++ 在 C 语言的基础上移植的新编程理念，我们需要先了解 C 语言的旧理念： C 语言是过程性语言。过程性 (procedural) 语言强调的是编程的算法方面。过程化编程首先要确定计算机应采取的操作，然后使用编程语言来实现这些操作。后来发展了结构化编程 (structured programming) 解决了“意大利面条式编程”问题，让程序更加有序。例如，结构化编程将分支（决定接下来应执行哪个指令）限制为一小组行为良好的结构。 自顶向下 (top-down) 的设计。也叫分治法，将大任务不断分成小的任务，知道每个任务成为一个小型的、易编写的模块。 C 语言鼓励程序员开发程序单元（函数）来表示各个任务模块。1.2.3 面向对象编程 (OOP)OOP 强调的是数据，其理念是设计与问题的本质特性相对应的数据格式。在 C++ 中，类是一种规范，对象是根据这种规范构造的特定数据结构。可以理解为，类规定了事物的基本特征，对象则是一个个实体。通常，类规定了可使用哪些数据来表示对象以及可以对这些数据执行哪些操作，即数据和方法。OOP 程序设计方法首先设计类，它们准确地表示了程序要处理的东西。从低级组织（如类）到高级组织（如程序）的处理过程叫做自下向上 (bottom-up) 的编程。OOP 完成了以下工作： 将数据和方法合并为类定义 创建可重用的代码 信息隐藏可以保护数据，使其免遭不适当的访问 多态能够为运算符和函数创建多个定义，通过编程上下文来确定使用哪个定义 继承能够使用旧类派生出新类1.2.4 C++ 和泛型编程范型编程与 OOP 的目标相同，即使重用代码和抽象通用概念的技术更简单。不过两者是有区别的： OOP 强调编程的数据方便，常用于管理大型项目 泛型编程强调的是独立于特定数据类型，提供了执行常见任务的工具1.2.5 C++ 的起源与 C 语言一样， C++ 也是在贝尔实验室诞生的， Bjarne Stroustrup 于 20 世纪 80 年代在这里开发出了这种语言。他选择 C 作为基础是因为 C 语言简洁、适合系统编程、使用广泛且与 UNIX 操作系统联系紧密。 C++ 是 C 语言的超集，这意味着任何有效的 C 程序都是有效的 C++ 程序。它们之间有些细微的差异，但无足轻重。C++程序可以使用已有的 C 软件库（库是编程模块的集合，可以从程序中调用它们）。C++ 融合了 OOP 、泛型编程和传统的过程性方法，这表明 C++ 强调的是实用价值，而不是意识形态方法，这也是该语言获得成功的原因之一。 C 部分则赋予了 C++ 语言紧密联系硬件的能力 OOP 部分赋予了 C++ 语言将问题所涉及的概念联系起来的能力 在C++获得一定程度的成功后，Stroustrup才添加了模板，这使得进行泛型编程成为可能。1.3 可移植性和标准可移植性指：如果在不修改代码的情况下，重新编译程序后，程序将运行良好，则该程序是可移植的。在可移植性方面有两个障碍：(1) 硬件特定的程序是不可移植的；(2) 不同系统的 C++ 实现并不一定兼容。为了解决这一问题，联合组织 ANSI/ISO 1998 年制定出了一个国际标准，该标准常被称为C++98，它不仅描述了已有的 C++ 特性，还对该语言进行了扩展，添加了异常、运行阶段类型识别 (RTTI) 、模板和标准模板库(STL)。其后的 C++03 没有改变语言特性，因此我们使用 C++98 表示C++98/C++2003。 C++ 在不断地发展，于 2011 年 8 月推出了 C++11 。 C++11 新增了众多特性，同时消除了不一致性。1.4 程序创建的技巧从 4.3 版起， g++ 要求编译源代码文件时使用标记 -std=c++0x ：g++ -std=c++11 xxx.cpp1.4.1 创建源代码文件给源文件命名时，必须使用正确的后缀，将文件标识为 C++ 文件。后缀由一个句点和一个或多个字符组成，这些字符被称作扩展名。即文件命名格式： 文件名.后缀名 。源代码文件的扩展名： C++实现 源代码文件的扩展名 UNIX C、cc、cxx、c GNU C++ C、cc、cxx、cpp、c++ Digital Mars cpp、cxx Borland C++ cpp Watcom cpp Microsoft Visual C++ cpp、cxx、cc Freestyle CodeWarrior cp、cpp、cc、cxx、c++ UNIX 区分大小写， c 对应 C 程序， C 对应 C++ 程序。1.4.2 编译和链接最开始实现 C++ 的时候，使用了一个 C++ 到 C 的编译器程序，叫做 cfront ，这种方法简化了向 C 的领域引入 C++ 的过程。随着C++的日渐普及，越来越多的实现转向创建 C++ 编译器，直接将 C++ 源代码生成目标代码。1. UNIX 编译和链接CC spiffy.C –&amp;gt; 产生 spiffy.o –&amp;gt; 编译器自动将目标代码文件传递给系统链接程序，该程序将代码与库代码结合起来，生成一个可执行文件 a.out如果只使用一个源文件，链接程序将自动删除目标代码文件。程序也可以包含多个文件，此时列出全部文件来编译程序： ` CC my.C precious.C ，如果只修改了 my.C 文件，则可以单独编译修改的文件，并与其他文件链接起来： CC my.C precious.o`编译时可能需要显示地指定一些库。2. Linux 编译和链接Linux 系统中最常用的编译器是 g++ ，这是来自 Free Software Foundation 的 GNU C++ 编译器。它的工作方式类似于 UNIX 编译器，只是将 CC 变为 g++ 命令。3. Windows 命令行编译器Cygwin 和 MinGW 都包含编译器 GNU C++ ，且可免费下载。4. Windows编译器当前，最流行是 Microsoft Visual C++ 2010 。通常，必须为程序创建一个项目，并将组成程序的一个或多个文件添加到该项目中。必须确定的非常重要的一点是，需要创建的是什么类型的程序。本书的教程是通用的，应选择包含字样“控制台”、“字符模式”或“DOS可执行文件”等选项。编译器可能让您选择要生成调试版还是发布版。调试版包含额外的代码，这会增大程序、降低执行速度，但可提供详细的调试信息。如果程序违反了语言规则，编译器将生成错误消息，指出存在问题的行。遗憾的是，如果不熟悉语言，将难以理解这些消息的含义。有时，真正的问题可能在标识行之前；有时，一个错误可能引发一连串的错误消息。一般的守则是： 改正错误时，应首先改正第一个错误。如果在标识为有错误的那一行上找不到错误，请查看前一行。 有时，编译器在不完全地构建程序后将出现混乱，它显示无法改正的、无意义的错误消息。在这种情况下，可以选择 Build All ，重新编译整个程序，以清除这些错误消息。遗憾的是，这种情况和那些更常见的情况（即错误消息只是看上去无意义，实际上有意义）很难区 分。程序执行完毕后，有些 IDE 将关闭该窗口，而有些 IDE 不关闭。为查看输出，必须在程序的最后加上一些代码：cin.get(); // 让程序等待，直到按下了 Enter 键cin.get(); // 可能存在残留的未处理字符，如最后一次输入的 Enter 键，使上一行失效return 0;5. Macintosh 上的 C++Apple 随操作系统 Mac OS X 提供了开发框架 Xcode第 2 章 开始学习 C++ 本章介绍：(1) main 函数扮演的角色；(2) C++ 程序语句；(3) 程序输入输出；(4) 创建使用变量；(5) 函数。C++ 对大小写敏感。" }, { "title": "Understanding LSTM Networks", "url": "/posts/Understanding-LSTM-Networks/", "categories": "Tutorial, RNN", "tags": "lstm, ml, rnn", "date": "2022-06-29 12:00:00 +0800", "snippet": "Understanding LSTM Networks https://colah.github.io/posts/2015-08-Understanding-LSTMs/Recurrent Neural Networks人的思维具有持续性，我们依据对之前的词的理解来理解下一个词。传统的神经网络不具备这样的能力，这似乎是一个主要缺点。RNNs 就是为了解决这一问题而诞生的，它们是内部带有循环的网络，允许信息持续存在。在上图中，一块神经网络 $A$ 查看某个输入 $x_t$ 并输出一个值 $h_t$ 。 循环允许信息从网络的一个步骤传递到下一个步骤。这么看着可能很神秘，但我们展开后， RNN 其实和普通的神经网络相同。循环神经网络可以被认为是同一网络的多个副本，每个副本都将消息传递给后继者。这种链状性质表明循环神经网络与序列和列表密切相关。 它们是用于此类数据的神经网络的自然架构。事实上确实是这样。 RNNs 被广泛用于 speech recognition, language modeling, translation, image captioning ……感兴趣的可以观看 Andrej Karpathy 的优秀博文《循环神经网络的不合理有效性》。LSTMs 就是一种特殊的 RNN ，在多种任务上表现良好。The Problem of Long-Term DependenciesRNNs 的诱人之处在于它们也许能够将以前的信息与当前的任务联系起来，但事实是这样吗？不一定。Case 1 ：预测句子“the clouds are in the sky.”中的最后一个单词。在这种情况下，相关信息与所需位置之间的差距很小，RNN 可以学习使用过去的信息。Case 2 ：预测句子“I grew up in France… I speak fluent French.”中的最后一个词。 RNNs 能够根据上下文推测这里应该是一种语言，但要确定是哪种语言，需要在非常靠前的 France 。不幸的是，随着 gap 的增大， RNNs 没有办法再连接起信息。理论上， RNNs 应该具有处理 long-term dependency 的能力。遗憾的是，在实际中， RNNs 似乎不具备这种能力。 Hochreiter (1991) [German] 和 Bengio 等人 (1994) 深入探讨了这个问题。幸运的是， LSTMs 没有这个问题！LSTMLong Short Term Memory networks (LSTMs) ，一种特殊的 RNN ，能够学习 long-term dependencies ，由 Hochreiter &amp;amp; Schmidhuber (1997) 提出。所有循环神经网络都具有神经网络的重复模块链的形式。在标准 RNNs 中，重复模块结构简单，如 tanh 层。LSTMs 拥有四层神经网络，以特殊的方式交互。LSTMs 核心思想LSTM 的关键是单元状态，即贯穿图表顶部的水平线。它直接沿着整个链条运行，只有一些较小的线性相互作用。 信息很容易沿着它不变地流动。LSTM 确实有能力将信息删除或添加到细胞状态，由称为门的结构小心调节。门，顾名思义，放行或阻止信息通过。它由一个 sigmoid 和元素乘法构成。 sigmoid 的输出范围 0-1 ，意味着对每个组件应该放行多少。Step-by-Step LSTM Walk Through想要了解 LTSM 的机制，需要了解三扇门。Forget gateForget gate 决定单元状态中要丢掉的部分。输入 $h_{t-1}$ 和 $x_t$ ，通过 sigmoid 生成每一位的分数 (0-1) 。Input gateInput gate 决定什么新的信息需要被存储起来。这分成两步： sigmoid 对输入生成分数 (0-1) ，然后 tanh 生成候选的状态值。此时，我们就可以更新单元状态了。把每个分数乘上对应的数值，然后相加作为新的单元状态。Output gate输出基于单元状态，但需要经过修改。对输入 $h_{t-1}$ 和 $x_t$ 应用 sigmoid 生成分数，然后对单元状态应用 tanh 规范到 $[-1,1]$ ，两者相乘。Variants on Long Short Term MemoryPeephole connections ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdfPeephole connections 让所有门能够看见单元状态。当然，可以选择一部分 peephole connections 。Coupled forget and input gatesCoupled forget and input gates 同时决定遗忘和学习的内容。我们只会忘记何时要输入一些东西。 只有当我们忘记旧的东西时，我们才会向状态输入新的值。GRU http://arxiv.org/pdf/1406.1078v3.pdf它将 forget gate 和 input gate 组合成一个 update gate 。 它还合并了单元格状态和隐藏状态，并进行了一些其他更改。最终的模型更加简单，也更流行。这些变体中哪个最好？ 差异重要吗？ Greff 等人 (2015) 对流行的变体进行了很好的比较，发现它们都差不多。 Jozefowicz 等人 (2015) 测试了超过一万个 RNN 架构，发现其中一些在某些任务上比 LSTM 效果更好。ConclusionLSTM 是我们可以使用 RNN 完成的一大步。很自然地想知道：还有一大步吗？研究人员的普遍看法是：“是的！还有下一步，要注意了！”这个想法是让 RNN 的每一步都从更大的信息集合中挑选要查看的信息。例如，如果您使用 RNN 创建描述图像的标题，它可能会选择图像的一部分来查看它输出的每个单词。事实上，Xu 等人 (2015) 正是这样做的——如果你想探索注意力，这可能是一个有趣的起点！使用注意力已经产生了许多非常令人兴奋的结果，而且似乎还有更多的结果即将到来……注意力并不是 RNN 研究中唯一令人兴奋的主题。例如，Kalchbrenner 等人 (2015) 的 Grid LSTM 似乎非常有前途。在生成模型中使用 RNN 的工作——例如 Gregor 等人 (2015)、Chung 等人 (2015) 或 Bayer &amp;amp; Osendorfer (2015)——似乎也很有趣。过去几年对于循环神经网络来说是一个激动人心的时期，而未来的神经网络承诺只会更是如此！如果觉得本教程不错或对您有用，请前往项目地址 https://raw.githubusercontent.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，Github主页：传送门" }, { "title": "Transformers are Graph Neural Networks", "url": "/posts/Transformers-are-Graph-Neural-Networks/", "categories": "Tutorial, GNN", "tags": "transformer, ml, gnn", "date": "2022-06-28 10:50:00 +0800", "snippet": "Transformers are Graph Neural Networks https://thegradient.pub/transformers-are-graph-neural-networks/Transformer 的出现推动了整个 NLP 领域。这篇博客旨在建立 GNNs 和 Transformers 之间的联系。首先，两者都是为了完成“表征学习”（representation learning）。NLP 表示学习从高层次上，所有神经网络架构都将输入数据的表示构建为向量/嵌入，这些向量/嵌入对有关数据的有用的统计和语义信息进行编码。对于 NLP ，传统上使用 RNNs 以顺序方式构建句子中每个单词的表示，即 one word at a time 。直觉上， RNNs 像一个传送带，从左到右地处理句子，最终得到每个单词的隐藏特征，传递给之后的任务。Transformers 一开始被用于机器翻译，后来逐渐取代主流 NLP 中的RNNs 。它完全抛弃了循环，转而采用注意力机制区分其他所有单词的重要性，然后根据重要性加权求和所有单词线性变换后的特征。分解 Transformer这一节我们用数学表达式解释 Transformer 。第 $l$ 层到第 $l+1$ 层将句子 $S$ 中第 $i$ 个单词的隐藏特征 $h$ 更新如下：\\(h_i^{l+1} = \\text{Attention} \\left( Q^lh_i^l, K^lh_j^l, V^lh_j^l \\right)\\)即\\(h_i^{l+1} = \\sum_{j \\in S} w_{ij} \\left( V^l h_j^l \\right)\\\\\\text{where } w_{ij} = \\text{softmax}_i \\left( Q^lh_i^l \\cdot K^lh_j^l \\right)\\)其中 $j \\in S$ 表示句子中的单词， $Q^l$ ， $K^l$ ， $V^l$ 是可学习的线性变换权重。注意力机制并行地对句子中的每一个词进行计算，获得更新的特征。这也是 Transformers 相对 RNNs 的加分项。输入单词特征 $h_i^l$ 和句子中剩余的单词 ${h_j^l~\\forall j \\in S}$ ，我们通过点积计算 $(i,j)$ 对的注意力权重 $w_{ij}$ ，然后对所有 $j$ 应用 softmax ，最后加权求和所有 ${h_i^\\prime}$ 。这一步骤对每个单词同时进行。多头注意力让这种简单的点积注意力机制发挥作用被证明是很棘手的。可学习权重的错误随机初始化会破坏训练过程的稳定性。我们可以通过并行执行多个注意力“头”并连接结果来克服这个问题（每个头现在都有单独的可学习权重）：\\(h_i^{l+1} = \\text{Concat } (\\text{head}_1, \\dots, \\text{head}_K) O^l\\\\\\text{head}_k = \\text{Attention} \\left( Q^{k,l}h_i^l, K^{k,l}h_j^l, V^{k,l}h_j^l \\right)\\)其中 $Q^{k,l}h_i^l$ ， $K^{k,l}h_j^l$ ， $V^{k,l}h_j^l$ 是第 k 个注意力头可学习的权重， $O^l$ 是一个向下投影，来匹配跨层的 $h_i^{l+1}$ 和 $h_i^l$ 的维度。多头允许多头必要地 hedge its bets ，从不同角度观察前一层的隐藏特征。尺度问题推动最终 Transformer 架构的一个关键问题是，在注意力机制之后的单词特征可能处于不同的尺度或量级。这可能是因为一些词具有非常集中或者分散的注意力全中，或是多个注意力头拼接后的特征范围很大。按照传统的 ML 智慧，在流程中添加规范化层似乎是合理的。Transformers 中有三种规范方法： (1) LN ，在特征级别规范化并学习仿射变换。 (2) 对点积除以特征维度的平方根。 (3) 具有特殊结构的按位置 2 层 MLP 。多头注意力之后，作者用可学习的权重将 $h_i^{l+1}$ 映射到一个极其高的维度，然后经过 ReLU 非线性处理，再映射回原来的维度并进行正则化：\\(h_i^{l+1} = \\text{LN}(\\text{MLP}(\\text{LN}(h_i^{l+1})))\\)(3) 可能有点难以理解。根据 Jannes Muenchmeyer 的说法，前馈子层确保 Transformer 是一个通用逼近器。 因此，投影到非常高维空间、应用非线性并重新投影到原始维度允许模型表示比在隐藏层中保持相同维度更多的函数。Transformer 层的最终图片如下所示：图中省略了多头注意力子层和前馈子层的 residual connections 。Transformer 架构也非常适合非常深的网络，使 NLP 社区能够在模型参数和数据方面进行扩展。GNN 构建图的表示GNNs 或 GCNs 通过 neighborhood aggregation (or message passing) 构建图数据中的节点和边的表示。Neighborhood aggregation (or message passing) 中每个节点通过聚合自身邻居特征来更新自己的特征，以表示它周围的局部图结构。堆积多个 GNN 层允许节点的特征在整个图中传播，即从邻居传播到邻居的邻居，以此类推。最常见地， GNNs 在 $l$ 层更新节点 $i$ 的隐藏特征 $h$ 如下：非线性转换节点自身特征，再加上邻居聚合特征。\\(h_i^{l+1} = \\sigma \\left( U^lh_i^l + \\sum_{j \\in \\mathcal N(i)} \\left( V^lh_j^l \\right) \\right)\\)其中 $U^l$ ， $V^l$ 是 GNN 层可学习的权重矩阵， $\\sigma$ 是非线性函数。上图中， $\\mathcal N(😆) = { 😘, 😎, 😜, 🤩 }$ 。公式 (5) 中的求和可以被其他输入大小不变的聚合函数替换，如 mean/max ，或者注意力机制。如果我们把聚合函数替换为注意力机制，并采用多个并行的头进行 neighborhood aggregation 我们就得到了 GAT 。增加正则化和前馈 MLP ， voila ，就是 Graph Transformer ！句子是全连接的单词图于是我们可以用 GNN 来构建每个单词的特征，然后我们可以使用它来执行 NLP 任务。这就是 Transformer 在做的事情：具有多头注意力的 GNNs 进行 neighborhood aggregation 。只是 Transformer 同时处理句子中的所有单词，而 GNN 只处理一阶邻居。重要的是，各种针对特定问题的技巧——例如位置编码、因果/屏蔽聚合、学习率计划和广泛的预训练——对于 Transformer 的成功至关重要，但在 GNN 社区中却很少出现。 同时，从 GNN 的角度看待 Transformers 可以启发我们摆脱架构中的许多花里胡哨 (bells and whistles) 。思考句子是全连通图吗？在统计 NLP 和 ML 之前，像 Noam Chomsky 这样的语言学家专注于开发语言结构的形式理论，例如句法树/图。 Tree LSTMs 已经尝试过这一点，但也许 Transformers/GNNs 是更好的架构，可以将语言理论和统计 NLP 两个世界结合在一起？ 例如，MILA 和斯坦福大学最近的一项工作探索了使用语法树来增强预训练的 Transformer，例如 BERT [Sachan et al., 2020]。长距离依赖全连接图的另一个问题是它们使学习单词之间非常长期的依赖关系变得困难，因为边数随节点数呈二次方关系。随着 $n$ 的增加，事情逐渐不可控。NLP 社区对长序列和依赖问题的看法很有趣：使注意力机制在输入大小方面变得稀疏或自适应，在每一层中添加递归或压缩，以及使用局部敏感散列来进行有效注意力都是有希望的新想法，以更好地实现 Transformer 。看到 GNN 社区的想法融入其中会很有趣，例如，用于句子图稀疏化的二进制分区似乎是另一种令人兴奋的方法。 BP-Transformers 递归地将句子分成两部分，直到它们可以从句子标记中构造出分层二叉树。 这种结构归纳偏差有助于模型以高效记忆的方式处理更长的文本序列。Transformer 学习语法吗Transformer 最基本的开始是通过赋予单词对注意力，可以学习到类似于任务特定的语法。不同的头可能在寻找不同的语法性质。在图方面，通过在全图上使用 GNN，我们能否从 GNN 在每一层执行邻域聚合的方式中恢复最重要的边——以及它们可能包含的内容？ 我还不太相信这种观点。为什么多头注意力？为什么注意力？拥有多个注意力头可以改善学习并克服糟糕的随机初始化。例如，论文表明，在训练后可以“修剪”或移除 Transformer 头部，而不会对性能产生重大影响。多头 neighborhood aggregation 机制被证明很有效： GAT 使用多头注意力机制， MoNet 使用多个高斯核聚合特征。尽管设计用于稳定注意力机制，多头技巧能否成为提升额外模型性能的标准？此外，如果我们不必计算句子中每个单词对之间的成对兼容性，这对 Transformers 来说不是很好吗？另外， Transformer 能从完全放弃注意力中受益吗？Yann Dauphin 和合作者最近的工作提出了另一种 ConvNet 架构。 Transformers 最终也可能会做类似于 ConvNets 的事情！为什么很难训练 Transformers ？阅读新的 Transformer 论文让我觉得在确定最佳学习率计划、预热策略和衰减设置时，训练这些模型需要一些类似于黑魔法的东西。 这可能只是因为模型如此庞大，所研究的 NLP 任务如此具有挑战性。最后，我们真的需要多个昂贵的成对注意力、过度参数化的 MLP 子层和复杂的学习计划吗？ 我们真的需要具有大量碳足迹的大型模型吗？ 对手头的任务具有良好归纳偏差的架构不应该更容易训练吗？如果觉得本教程不错或对您有用，请前往项目地址 https://raw.githubusercontent.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，Github主页：传送门" }, { "title": "2022 Summer Schedule", "url": "/posts/Summer-Schedule/", "categories": "Diary", "tags": "schedule", "date": "2022-06-20 00:00:00 +0800", "snippet": "2022 Summer Schedule转眼间，我就要毕业了。大学四年，我积攒了很多想做但一直没有机会做的事，趁着这个无忧无虑的暑假，抓紧把它们捡起来，弥补一下大学的遗憾吧！ 自觉心是进步之母，自贱心是堕落之源，故自觉心不可无，自贱心不可有。 ——邹韬奋1. Research 整理论文阅读形成笔记 收集各种论文的数据集 ==多分类模型== 细粒度检测论文 ==爬虫框架== NNI2. Reinforcement Learning 自学RL书籍 http://t.zoukankan.com/jiangkejie-p-10844682.html，训练小游戏3. Sequence Prediction Model 数据集 阅读论文 模型4. Literature Cultivation" }, { "title": "Common and free tools related to PPT", "url": "/posts/PPT-tools/", "categories": "Tutorial, PPT", "tags": "ppt, tools", "date": "2022-04-11 16:40:00 +0800", "snippet": "PPT 制作常用免费工具【模板库】 演示星球：www.pop-ppt.com 微软 OfficePLUS：www.officeplus.cn【图片库】 免费商用 Unsplash：www.unsplash.com 免抠图透明素材 pngpix：www.pngpix.com 高清人、物PNG素材 MOOSE：https://igoutu.cn/photos【在线编辑】 人工智能绘画AutoDraw：www.autodraw.com 流体背景Fluid Simulation：paveldogreat.github.io/WebGL-Fluid-Simulation 纹理背景RUSSFUSS：russfuss.com 液态渐变星球 Nebula Artefact：https://alteredqualia.com/xg/examples/nebula_artefact.html 抽象背景Bg-Painter：bg-painter.com 渐变色 Mesh Gradient：meshgradient.com 在线作图（流程图、架构图、思维导图等）ProcessOn：www.processon.com 镝数图表：dycharts.com 花火数图（数据短视频）：hanabi.cn 在线编辑图片：iloveimg.com/zh-cn 免费在线抠图：fococlipping.com 免费样机生成器 Free Mockup Generator：mockups.pixeltrue.com18.在线文本格式转换 ACONVERT：aconvert.com参考资料：https://www.bilibili.com/video/BV17S4y1N7Ei如果觉得本教程不错或对您有用，请前往项目地址 https://raw.githubusercontent.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，Github主页：传送门" }, { "title": "Mathematical principles behind GCN", "url": "/posts/Mathematical-principles-behind-GCN/", "categories": "Tutorial, GNN", "tags": "maths, ml, gcn", "date": "2022-04-06 20:12:00 +0800", "snippet": "GCN 背后的数学原理一、定义GNN 的更新公式为\\(H^{(l+1)} = f(A, H^{(l)})\\)即根据当前的隐藏状态，根据与其他节点的连接关系，进行某种映射，得到下一步隐藏状态。所有的 GNN 网络其实都是在设计 $f$ 。而 GCN 的 $f$ 定义如下\\(H^{(l+1)} = \\sigma(\\hat D^{-\\frac12} \\hat A \\hat D^{-\\frac12} H^{(l)} \\theta)\\)这里的 GCN 考虑的是无向简单图（无向、无自环、无重边）。$A$ 代表邻接矩阵， $D$ 代表度矩阵， $\\hat A$ 代表添加了自环后的邻接矩阵，即 $\\hat A = A + I$ ， $\\hat D$ 代表添加了自环后的度矩阵， $\\hat D = D + I$ 。 $\\hat D^{-\\frac12} \\hat A \\hat D^{-\\frac12}$ 是 $\\hat A$ 的对称归一化矩阵。二、基础知识1. 图理论依据线性代数研究与图相关的矩阵的性质。首先复习线性代数的一些知识： 特征值和特征向量：若 $A \\vec x = \\lambda \\vec x$ ，且 $\\vec x \\ne \\vec 0$ ，那么 $\\vec x$ 称为 $A$ 的一个特征向量， $\\lambda$ 是 $A$ 的一个特征值。 定理：如果一个矩阵是实对称阵，那么它一定有 $n$ 个特征值，并且这 $n$ 个特征值对应着 $n$ 个互相正交的特征向量，其中 $n$ 代表矩阵维度。数学表达如下：\\[A = U \\Lambda U^T\\\\UU^T = I\\\\\\Lambda = diag(\\lambda_1, \\lambda_2, \\dots, \\lambda_n)\\\\\\] 半正定矩阵：所有特征值都大于等于 $0$ 二次型：给定一个矩阵 $A$ ，向量 $x$ 对于矩阵 $A$ 的二次型为 $\\vec x^T A \\vec x$ Rayleigh 熵：一个向量关于 $A$ 的二次型和它关于 $I$ 的二次型的比值，即 $\\frac{\\vec x^T A \\vec x}{\\vec x^T \\vec x}$ ，它与矩阵的特征值有着密切的联系。假设 $\\vec x$ 是 $A$ 的特征向量，则可以证明 Rayleigh 熵等于矩阵的特征值。证明如下：\\[\\frac{\\vec x^T A \\vec x}{\\vec x^T \\vec x} = \\frac{\\vec x^T \\lambda \\vec x}{\\vec x^T \\vec x} = \\frac{\\lambda (\\vec x^T \\vec x)}{\\vec x^T \\vec x} = \\lambda\\] 然后我们研究和 GCN 相关的最重要的两个矩阵 $L$ 和 $L_{sym}$ 。图的拉普拉斯矩阵定义为 $L = D - A$ ，其对称归一化矩阵为 $L_{sym} = D^{-\\frac12} L D^{-\\frac12}$ 。这两个矩阵都是实对称矩阵，因此它们都有 $n$ 个特征值和 $n$ 个正交的特征向量，且都为半正定矩阵。证明如下：\\(\\begin{aligned}&amp;amp;若要证明 L 为半正定阵，则只要证明 \\forall \\vec x, \\frac{\\vec x^T L \\vec x}{\\vec x^T \\vec x} \\ge 0 ，则当 \\vec x 为 L 的特征向量时，有 \\lambda \\ge 0\\\\&amp;amp;又 \\vec x^T \\vec x \\gt 0 ，故只需证明 \\vec x^T L \\vec x \\ge 0\\\\&amp;amp;构造 G_{(i,j)} = \\begin{bmatrix}\\ddots &amp;amp;&amp;amp;&amp;amp;&amp;amp;\\\\&amp;amp;1&amp;amp;\\cdots&amp;amp;-1&amp;amp;\\\\&amp;amp;\\vdots&amp;amp;\\ddots&amp;amp;\\vdots&amp;amp;\\\\&amp;amp;-1&amp;amp;\\cdots&amp;amp;1&amp;amp;\\\\&amp;amp;&amp;amp;&amp;amp;&amp;amp;\\ddots\\\\\\end{bmatrix}，则 L = \\sum_{(i,j) \\in E} G_{(i,j)}\\\\&amp;amp;研究 \\vec x^T G_{(i,j)} \\vec x = \\vec x^T \\begin{bmatrix}\\vdots \\\\ x_i-x_j \\\\ \\vdots \\\\ x_j-x_i \\\\ \\vdots \\\\\\end{bmatrix}= (x_i-x_j)^2\\\\&amp;amp;故 \\vec x^T L \\vec x = \\vec x^T (\\sum_{(i,j) \\in E} G_{(i,j)}) \\vec x = \\sum_{(i,j) \\in E} (\\vec x^T G_{(i,j)} \\vec x) = \\sum_{(i,j) \\in E}(x_i-x_j)^2 \\ge 0\\\\&amp;amp;结论成立\\\\\\end{aligned}\\)对于 $L_{sym}$ ，证明如下：\\[\\begin{aligned}&amp;amp;\\vec x^T L_{sym} \\vec x = \\vec x^T D^{-\\frac12} L D^{-\\frac12} \\vec x = (\\vec x^T D^{-\\frac12}) L (D^{-\\frac12} \\vec x)\\\\&amp;amp;依据之前的结论\\\\&amp;amp;\\vec x^T L_{sym} \\vec x = \\sum_{(i,j) \\in E}(\\frac{x_i}{\\sqrt d_i}-\\frac{x_j}{\\sqrt d_j})^2 \\ge 0\\\\\\end{aligned}\\]这仅仅说明了 $L_{sym}$ 特征值是非负数，但其实我们可以证明更准确的一个范围 $[0,2]$ 。证明如下：\\(\\begin{aligned}&amp;amp;构造 G_{(i,j)}^\\prime = \\begin{bmatrix}\\ddots &amp;amp;&amp;amp;&amp;amp;&amp;amp;\\\\&amp;amp;1&amp;amp;\\cdots&amp;amp;1&amp;amp;\\\\&amp;amp;\\vdots&amp;amp;\\ddots&amp;amp;\\vdots&amp;amp;\\\\&amp;amp;1&amp;amp;\\cdots&amp;amp;1&amp;amp;\\\\&amp;amp;&amp;amp;&amp;amp;&amp;amp;\\ddots\\\\\\end{bmatrix}，则 \\vec x^T G_{(i,j)}^\\prime \\vec x = (x_i+x_j)^2\\\\&amp;amp;定义 L^\\prime = D + A = \\sum_{(i,j) \\in E} G_{(i,j)}^\\prime，\\\\&amp;amp;有 \\vec x^T L^\\prime \\vec x = \\sum_{(i,j) \\in E} (x_i+x_j)^2\\\\&amp;amp;又 L_{sym}^\\prime = D^{-\\frac12} L^\\prime D^{-\\frac12}，有 \\vec x^T L_{sym}^\\prime \\vec x = \\sum_{(i,j) \\in E}(\\frac{x_i}{\\sqrt d_i}+\\frac{x_j}{\\sqrt d_j})^2 \\ge 0\\\\&amp;amp;由于 L_{sym}^\\prime = I + D^{-\\frac12} A D^{-\\frac12}，代入上面的不等式得到\\\\&amp;amp;\\vec x^T L_{sym}^\\prime \\vec x = \\vec x^T (I + D^{-\\frac12} A D^{-\\frac12}) \\vec x = \\vec x^T \\vec x + \\vec x^T D^{-\\frac12} A D^{-\\frac12} \\vec x \\ge 0\\\\&amp;amp;进一步变换可得 2 \\vec x^T \\vec x \\ge \\vec x^T (I - D^{-\\frac12} A D^{-\\frac12}) \\vec x ，有\\\\&amp;amp;2 \\vec x^T \\vec x \\ge \\vec x^T L_{sym} \\vec x ，即 \\frac{\\vec x^T L_{sym} \\vec x}{\\vec x^T \\vec x} \\le 2\\\\\\end{aligned}\\)2. 傅立叶变换什么是傅立叶变换？傅立叶变换就是从另一个域研究问题。例如，声波在时域是一个复杂的波形，根据傅立叶变换，任何函数都可以表达为一系列的正弦波，因此将声波转换到频域，表现为在不同频率下不同振幅的正弦波。此时我们就很容易区分男声和女声（假设女声频率普遍高于男声），而这在时域上是不容易操作的。这里推荐一篇讲解傅立叶变换的教程。举个例子，假设我们有两个多项式需要相乘 $f(x) = a_0 + a_1x + \\cdots + a_nx^n$ ， $g(x) = b_0 + b_1x + \\cdots + b_nx^n$ 。简单的暴力方法嵌套遍历两组系数，复杂度是 $O(n^2)$ ，而通过 FFT ，一个 $n$ 次多项式可以由 $n+1$ 个点确定： $f(x) \\Leftrightarrow (x_1, f(x_1)), \\dots, (x_n, f(x_n))$ ， $g(x) \\Leftrightarrow (x_1, g(x_1)), \\dots, (x_n, g(x_n))$ 。此时，计算两个多项式就是 $n$ 个点相乘，复杂度 $O(n)$ ，而这种变换的复杂度为 $O(n \\log n)$ ，所以最终算法的复杂度为 $O(n \\log n)$ ，效率提升。什么是图上的傅立叶变换，又为什么需要？因为不同于图像（image），图（graph）是一个非欧氏空间，节点的邻居数量不固定，我们无法确定 kernel 的形状，因此在空间域做图的卷积是非常困的。在图上进行傅立叶变换，就是将图变换到一个更容易进行卷积的域中。我们看看 $Lx$ 做了什么。 $x$ 的每一行都可以看作是一个节点的 feature ，可以看出这种乘法实现了和邻居特征的聚合。由于 $L$ 是一个实对称、半正定阵，因此 $Lx = U \\Lambda U^T x$ ，其中 $U$ 和 $U^T$ 都是正交阵。而一个向量乘以一个正交阵，就是一种基底变换。因此 $U \\Lambda U^T x$ 表示先将 $x$ 变换基底表示，然后在不同维度上进行放缩，然后再变换回原来的坐标系。但实际上对拉普拉斯矩阵进行特征分解需要 $O(n^2)$ 的复杂度。GCN 所做的就是对带特征分解的傅立叶变换进行限制，寻找一种不需要特征分解、复杂度与边的数量成线性关系的方法。三、图卷积公式推导首先需要定义图上的卷积操作。假设我们有一个关于图的邻接矩阵的函数 $F(A) \\mapsto L~or~L_{sym}$ ，输入是图的邻接矩阵，输出是一种关于图的性质比较好的矩阵，例如 $L~or~L_{sym}$ ，只要它满足实对称阵都还算不错。我们定义 $F(A) = U \\Lambda U^T$ 。图上的卷积操作 $g_\\theta * x$ 就可以定义为 $U g_{\\theta}(\\Lambda) U^T x$ ，其中限定 $g_{\\theta}(\\lambda)$ 是一个多项式函数 $g_{\\theta}(\\Lambda) = \\theta_0 \\Lambda^0 + \\theta_1 \\Lambda^1 + \\cdots + \\theta_n \\Lambda^n+ \\cdots$ ，这样的好处是 $U g_{\\theta}(\\Lambda) U^T = g_{\\theta}(U \\Lambda U^T) = g_\\theta(F(A))$ ，就不需要再对 $A$ 做特征分解了。证明如下：\\(\\begin{aligned}&amp;amp;(U \\Lambda U^T)^k = U \\Lambda U^T \\cdots U \\Lambda U^T = U \\Lambda^k U^T\\\\&amp;amp;U g_{\\theta}(\\Lambda) U^T = U \\sum_k(\\theta_k \\Lambda^k) U^T = \\sum_k(\\theta_k (U \\Lambda^k U^T)) = g_{\\theta}(U \\Lambda U^T)\\\\\\end{aligned}\\)但在实际操作中，我们并不是用系数的形式拟合多项式的，因为随着 $n$ 的变大这种方法存在梯度消失和梯度爆炸的问题。事实上使用切比雪夫多项式 $\\Gamma_n(x) = 2\\Gamma_{n-1}(x) - \\Gamma_{n-2}(x),~\\Gamma_0(x) = 1, \\Gamma_1(x) = x$ ，它存在一个非常好的性质 $\\Gamma_n(\\cos \\theta) = \\cos(n\\theta)$ ，即不论 $n$ 多大，其数值上都有一个稳定的摆动趋势。但它的缺点是要求自变量的取值范围为 $[-1,1]$ ，即 $\\lambda \\in [-1,1]$ 。为了满足这个性质，只需要将 $L_{sym}$ 减去 $I$ 即可，所以最终选择 $F(A) = L_{sym}-I$ 。因此\\[\\begin{aligned}g_\\theta * x&amp;amp;= U (\\sum_{k=0}^K \\theta_k \\Gamma_k(\\Lambda)) U^T x\\\\&amp;amp;= \\sum_{k=0}^K \\theta_k U \\Gamma_k(\\Lambda) U^T x\\\\&amp;amp;= \\sum_{k=0}^K \\theta_k \\Gamma_k(U \\Lambda U^T) x\\\\&amp;amp;= \\sum_{k=0}^K \\theta_k \\Gamma_k(L_{sym}-I) x\\\\\\end{aligned}\\]但实际上这个运算的复杂度还是很高，需要计算矩阵的 $k$ 次方。因此 GCN 的实际做法是使用一阶近似\\[\\begin{aligned}g_\\theta * x&amp;amp;\\approx \\theta_0 \\Gamma_0(L_{sym}-I)x + \\theta_1 \\Gamma_1(L_{sym}-I)x\\\\&amp;amp;= \\theta_0 x + \\theta_1 (L_{sym}-I)x\\\\&amp;amp;= \\theta_0 x + \\theta_1 (I-D^{-\\frac12} A D^{-\\frac12}-I)x\\\\&amp;amp;= \\theta_0 x + \\theta_1 D^{-\\frac12} A D^{-\\frac12}x\\\\\\end{aligned}\\]在 GCN 中还应用了一些正则化，令 $\\theta_1 = -\\theta_0$ ，有 $g_\\theta * x = \\theta_0 (I + D^{-\\frac12} A D^{-\\frac12})x$ ，则 $\\theta_0$ 也可以省略。其次使用 renormalize ，将 $I$ 移入，得到 $g_\\theta * x = D^{-\\frac12} \\hat A D^{-\\frac12}x$ 。至于原因，只是因为它的效果更好。四、参考资料 https://www.bilibili.com/video/BV1Vw411R7Fj如果觉得本教程不错或对您有用，请前往项目地址 https://raw.githubusercontent.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，Github主页：传送门" }, { "title": "Common Metrics in Machine Learning", "url": "/posts/Common-Metrics-in-Machine-Learning/", "categories": "Course, Machine Learning", "tags": "metrics, ml", "date": "2022-04-06 20:12:00 +0800", "snippet": "ML 中的常用指标目录： 分类评估（ TP 、 FP 、 TN 、 FN 、 Precision 、 Recall 、 F-score 、 TPR 、 FPR 、 TNR 、 FNR 、 ROC 、 AUC 、 Accuracy ） k 折交叉验证（ k-fold cross-validation ）一、分类评估TP（True Positive）：预测结果为正类，实际上就是正类FP（False Positive）：预测结果为正类，实际上是反类FN（False negative）：预测结果为反类，实际上是正类TN（True negative）：预测结果为反类，实际上就是反类Precision、Recall、F-scorePrecision（精确度）可以理解为预测结果为正类中有多少真实结果是正类的：\\(Precision = \\cfrac{TP}{TP+FP}\\)Recall（召回率）可以理解为真实结果为正类中有多少被预测成正类：\\(Recall = \\cfrac{TP}{TP+FN}\\)F-score（F 值）又称作 F1-measure ，是综合考虑 Precision 和 Recall 的指标：\\(F-score = 2 * \\cfrac{Precision*Recall}{Precision+Recall}\\)TPR、FPR、TNR、FNRTPR（True Positive Rate）可以理解为所有正类中，有多少被预测成正类（正类预测正确），即召回率：\\(TPR = \\cfrac{TP}{TP+FN}\\)FPR（False Positive Rate）可以理解为所有反类中，有多少被预测成正类（正类预测错误）：\\(FPR = \\cfrac{FP}{FP+TN}\\)TNR（True Negative Rate）可以理解为所有反类中，有多少被预测成反类（反类预测正确）：\\(TNR = \\cfrac{TN}{FP+TN}\\)FNR（False Negative Rate）可以理解为所有正类中，有多少被预测成反类（反类预测错误）：\\(FNR = \\cfrac{FN}{TP+TN}\\)ROC ，以 FPR 为横坐标， TPR 为纵坐标，称作 ROC 曲线：ROC 曲线又称作“受试者工作特性曲线”，很明显，越靠近左上角的点，效果越好。AUC（Area Under Curve）定义为 ROC曲线下的面积 ，很明显，这个值越大越好。 如何绘制 ROC 曲线？ # -*- coding: utf-8 -*-import numpy as np ############计算ROC需要的库函数#############from sklearn.model_selection import cross_validatefrom sklearn import metricsfrom sklearn import svmimport matplotlib.pyplot as plt #############计算fpr,tpr####################y是一个一维数组（样本的真实分类），数组值表示类别（一共有两类，1和2），人工标注，属于测试集的真实分类##score即各个样本属于正例的概率；是网络的输出；首先用训练集训练网络，然后利用测试集的数据产生的##fpr, tpr是ROC的横纵坐标##thresholds是截断阈值y = np.array([1, 1, 2, 2])scores = np.array([0.1, 0.4, 0.35, 0.8])fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2) #############画图##################plt.title(&#39;ROC&#39;)plt.xlabel(&#39;False Positive Rate&#39;)plt.ylabel(&#39;True Positive Rate&#39;)plt.plot(fpr, tpr,&#39;--*b&#39;,label=&quot;tuli&quot;)plt.legend()plt.show() AccuracyAccuracy（准确率）可以理解为所有实验中，分类正确的个数：\\(Accuracy = \\cfrac{TP+TN}{TP+FP+TN+FN}\\)二、 k 折交叉验证将原始数据集划分为训练集/测试集，是为了避免追求高准确率而在训练集上产生过拟合，从而使得模型在样本外的数据上也能得到高的准确率。但是，划分出训练集/测试集的不同会使得模型的准确率产生明显的变化。为了消除这一变化因素，我们可以创建一系列训练集/测试集，计算模型在每个测试集上的准确率，然后计算平均值。这就是 K-fold cross-validation 的本质。K-fold cross-validation的步骤： 将原始数据集划分为相等的K部分（“折”） 将第 1 部分作为测试集，其余作为训练集 训练模型，计算模型在测试集上的准确率 每次用不同的部分作为测试集，重复步骤 2 和 3 K 次 将平均准确率作为最终的模型准确率用 sklearn 模拟 5-fold cross-validation：from sklearn.cross_validation import KFoldkf = KFold(25, n_folds=5, shuffle=False)# 打印每个训练集和测试集print(&#39;{} {:^61} {}&#39;.format(&#39;Iteration&#39;, &#39;Training set observations&#39;, &#39;Testing set observations&#39;))for iteration, data in enumerate(kf, start=1): print(&#39;{:^9} {} {:^25}&#39;.format(iteration, str(data[0]), str(data[1])))对比 cross-validation 和 train/test split 可以发现： cross-validation 对于样本外数据有更高的准确率 cross-validation 更有效的发挥样本的作用K-fold cross-validation 可以用于参数调优以及模型和特征选择，如图。可能的改进措施： 重复利用不同的随机分组数据进行交叉验证 降低交叉验证单一方案的方差来提高样本外的预测准确率 将原始数据中的一部分数据设置为 “hold-out set”，在其余部分进行 CV 的整个过程，但模型最终准确率为模型在 hold-out set 上的准确率，因为 hold-out set 相当于样本外的数据" }, { "title": "GNN", "url": "/posts/GNN-into-Distrill/", "categories": "Tutorial, GNN", "tags": "gnn, graph", "date": "2022-03-29 10:20:00 +0800", "snippet": "GNN https://distill.pub/2021/gnn-intro/一、什么是图图 (graph) 是表示实体 (entities) 间的一些关系。实体就是顶点 (nodes) ，关系就是边 (edges) 。现在定义如下标记：顶点 V 、边 E 、全局 U ，这些标记所蕴含的信息就叫 attribute 。图一般分为两类：有向图和无向图。例如，微信上两个人互为朋友，这种关系是没有方向的，但在 B 站上你关注了主播，主播却没有关注你，这种关系就是有方向的。那么数据是如何表示成图的？ 图片 首先观察我们熟悉的图像。假定有一张 $244\\times244\\times3$ 的图像，将其看成一个图（非图像），那么每个像素就是一个顶点，像素间的邻接关系就是边。 中间的矩阵叫做邻接矩阵 $\\mathbf A$ (adjacency matrix) ，它的行和列都是顶点。\\(\\begin{cases}a_{ij} = 1 &amp;amp; if ~ v_i\\text{ is connected with } v_j\\\\a_{ij} = 0 &amp;amp; otherwise\\end{cases}\\)邻接矩阵通常是很大且稀疏的矩阵。 文本 文本可以看作是一个序列，可以将其中的每一个词作为顶点，一个词和下一个词时间有一个有向边。 分子图 每一个原子表示成图里的一个点，原子间的化学键表示成一条边。例如咖啡因： 社交网络 以下是《奥塞德》所有任务的交互图。任何人物如果同时出现在一个场景中，就会在他们之间连一条边。 引用图 文章之间的引用关系被表示为有向边。 实际中我们碰到的图的平均大小如下：在我们把数据表示为图之后，我们看看可以在这些图上定义那些问题。主要有三大类问题：图级别 (graph-level) 的、顶点级别 (node-level) 的和边级别 (edge-level) 的。 图级别的任务：判断整个图的性质。 比如下图中哪个图含有两个环。 顶点级别的任务：判断节点在图中的角色。 比如通过两个跆拳道老师和学生打过比赛的图，判断某个学生属于哪个老师管辖。 边级别的任务 比如对于一张图片，先进行语义分割，将人物和背景提取出后，判断任务之间是什么关系，即学习顶点之间边的属性。 那么将图用到机器学习上有哪些挑战呢？神经网络使用图的一个最核心的问题是如何表示图，使得它与神经网络是兼容的。一个图上有四种信息： 顶点的属性 边的属性 全局信息 连接性前面三个都可以用一个向量来表示，但表示连接性更为复杂。使用邻接矩阵虽然可以达到效果，但是它会非常大，而其中存在的边却不多。或许我们可以使用稀疏矩阵解决存放的问题，但是稀疏矩阵的高效运算尤其是如何在 GPU 上高效运算是一个很难的问题。另一个问题是对于邻接矩阵，交换任意的行和列都不会产生影响，因此神经网络需要能够处理这些看上去完全不同却代表同一张图的邻接矩阵。假设有四个顶点和四条边，以下是所有可能的邻接矩阵。如果我们既想高效存储，又想不受存储顺序的影响，可以采用顶点属性、边属性、全局属性都采用标量/向量来表示，边的关系采用邻接列表的形式，元素 $i$ 表示第 $i$ 条边 $e_i = (v_s, v_e)$ ，表示连接的两个节点。那么给定这种输入的形式，神经网络应该如何处理？二、图神经网络 (Graph Neural Networks)GNN 是一个对图上的所有属性（包括顶点、边和全局的上下文 (global-context) ）进行的可以优化的变换，这个变换能够保持图的对称信息，即改变节点的排序后，结果不变。接下来我们使用信息传递网络框架 (“message passing neural network” framework) 搭建 GNN 。GNN 的输入是图，输出也是图，它会变换节点、边、全局的属性嵌入 (embeddings) ，但不会改变图的连接性。1. 最简单的 GNN对于顶点、边、全局向量，我们分别构造一个多层感知机 (MLP) ，其输入大小和输出大小一致。这三个 MLP 就组成了 GNN 的一个层。经过这一层，图的属性将被更新，但是图的结果不发生变化。由于 MLP 是每个向量独自作用的，它不会考虑顺序，因此顶点排序的改变不会改变结果。接下来考虑最后一层的输出如何得到我们要的预测值。假设我们想对顶点做预测，这其实和一般的 NN 没有区别。比如之前提到的学生归属哪个老师的问题，我们在之后加入一个输出维度为 2 的全连接层，再加上一个 softmax ，就可以完成任务。这里所有顶点嵌入共享一个全连接层的参数。我们将问题稍微复杂化一些。假设我们还是想要分类顶点，但是每个顶点没有嵌入向量。此时我们会用到一个技术 —— 汇聚 (pooling) 。我们会利用与它有关的边和全局信息来生成它的嵌入向量，这里假设所有属性向量的长度相同，如果不同我们还需要先进行投影变换。然后我们就可以用新得到的向量预测。以下分别是没有顶点属性和没有边属性进行预测的例子。因此，不管缺少哪一类属性，都可以通过汇聚操作的到想要的属性值。于是，我们得到了一个最简单的 GNN 模型。给定一个输入的图，首先进入一系列的 GNN 层，每个层里有 3 个 MLP ，对应不同的属性，输出会得到结构不变、属性已经发生变化的一个图。然后根据需要对哪一个属性做预测，添加对应的输出层完成预测，其中如果缺失信息就加入合适的汇聚层。这个模型会有很大的局限性，主要在于 MLP 的位置没有使用图结构信息，每个顶点进入 MLP 时仅考虑自身信息。接下来我们考虑如何改进，放入图的信息，要用到的技术是之前提到过的信息传递。我们将某个顶点的向量和邻居节点的向量相加，得到汇聚的向量，然后对这个向量进行更新 $f$ 。这一步骤类似于卷积操作，唯一不同的是所有邻居顶点的权重都为 $1$ 。当这种层叠加时，顶点的感受野增大，融合的不仅是邻居的特征。我们规定符号 $\\rho_{_{V_n \\to V_n}}$ 表示顶点和 1 近邻的信息传递过程。当某种属性缺失时，我们之前在最后从别的属性汇聚过来弥补这个属性。在中间层我们也可以通过信息传递完成更新。注意这种信息传递的先后顺序会导致结果的不同，目前没有研究证明优劣。 先顶点后边学习 先边后顶点学习 交替更新 (Weave Layer) ：node to node (linear), edge to edge (linear), node to edge (edge layer), edge to node (node layer) 。上面我们讲述了顶点和边之间的信息交换，接下来我们看一下全局信息是怎么做的。首先为什么要有全局信息？在没有全局信息的情况下，顶点或边的视图只有邻居，当图很大且稀疏时，两个很远的点需要通过很多次更新才能交互。解决方法就是使用图的全局表示 $U$ ，也称为 master node 或 context vector 。这个虚拟的顶点与所有的顶点和边相连，这在图上想象会非常抽象。因为它与所有的顶点和边相连，因此在做顶点或边信息传递时，这个顶点的信息也是会考虑的。此时，所有的三类属性都学到了对应的向量，并进行过了消息传递。因此我们可以在池化期间通过调节我们感兴趣的属性相对于其余属性的信息来利用它们。一种可能的方式是将向量 concat 起来，另一种可能的方式是通过线性映射将不同属性向量映射到相同的空间或应用特征调制层 (feature-wise modulation layer) 。三、实验这一部分需要在浏览器上自行实验，我们看一下作者关于模型超参数选择的解释。先来看看模型大小（参数数量）和表现（AUC）之间的关系。当模型参数变多时， AUC 的上限是增加的，但是如果模型超参数设置得不好，参数增多也不会有更好的效果。固定某种向量的长度，变换其他的参数，观察模型的表现。这里使用了箱线图 (box plot) ，其中横线表示中值， bar 是 25% - 75% 的数据，最高/低的点是最大/小值。我们会希望中值越高越好， bar 也不要太长（太敏感）。从图中看来，维度越大，效果稍微好一点，但不是很明显。接下来观察不同的层数对精度的影响。 $x$ 轴是学习参数的个数， $y$ 轴是测试精度。可以看出，层数越少，学习参数越少，从左图看不出精度的差别。但在箱线图中，随着层数的增加，精度也在增加。接下来观察不同聚合操作的影响。三者几乎没有什么区别。最后观察需要在哪些属性上传递信息。绿色表示不聚合任何信息，也就是我们之前讨论的最简单的 GNN ，效果是最差的。随着不断加入各种信息传递，模型效果越来越好。可以看出 GNN 对超参数还是比较敏感的，可以调节的参数有：层数、嵌入向量大小、汇聚操作类型、如何进行信息传递。四、GNN 相关1. 其他类型的图 mutigraphs 定点之间有多种类型的边 hierarchical graphs 图是分层的，一些顶点是一个子图。不同的图结构在神经网络如何进行信息汇聚产生一定的影响。 2. 如何对图进行采样 (Sampling) 和 Batching之前我们讲过，假设有很多层 GNN ，最后一层的顶点可以看到很广的范围，在连通性足够的情况下，可能会看到整个图的信息。在计算梯度时，我们需要把所有的中间变量存储下来，这可能导致最后的计算代价时无法承受的。因此，我们需要对图进行采样，即我们把图拆封成子图，在子图上进行信息汇聚。有几种采样的方法： Random node sampling ：随机采样一些点，找出这些点的邻居，在这些子图上进行计算。通过控制每次采样多少个点，避免图过大，能够存入内存。 Random walk sampling ：从某一个顶点，随机找到它的一条边，找到下一个顶点，通过规定最多随机走多少步，获得一个子图。 Random walk with nerghborhood ：随机游走后找出所有顶点的邻居。 Diffusion Sampling ：选择一个节点，找出它的 k 阶邻，即进行宽度遍历，取出子图。具体哪种方法有效还是取决于数据集。跟采样相关的问题是进行 batching 。我们不希望对每一个顶点逐步更新，其计算量太小，不利于并行。但是每个顶点的邻居数量是不一样的，如何合并成一个规整的张量是一个有挑战性的问题。3. Inductive biases任何神经网络都基于一些假设。比如，CNN 假设空间平移不变性， RNN 假设时间平移不变性。 GNN 的假设是保持了图的对称性。4. 不同的汇聚操作其实 sum 、 mean 、 max 没有一种是非常理想的。5. GCN 作为子图的函数近似GCN 如果有 k 个层，每个层看 1 阶邻，最后每一个顶点看到的是一个 k-step 的子图，即这个顶点的表示就是这个子图的 embedding 。6. 可以将点和边对偶 (Dual)根据图论，讲一个图的点变成边、边变成点，图的邻接关系不变。7. 图卷积作为矩阵乘法、矩阵乘法作为图上的游走在图上进行卷积或者随机游走等价于在邻接矩阵上进行矩阵乘法。图卷积作为矩阵乘法也是如何高效实现 GCN 的关键。8. 图注意力网络 (Graph Attention Networks)卷积对每个邻居有个权重，但卷积的权重是和位置相关的，但这对于图是无用的，因为图的邻居个数和顺序不固定。一种做法是用注意力机制的方法，权重取决于两个顶点向量之间的关系。具体看 Transformer 中的原理。9. 图的可解释性10. 生成图如何对图的拓扑结构进行有效的建模五、结论图表是一种强大而丰富的结构化数据类型，其优势和挑战与图像和文本截然不同。 在本文中，我们概述了研究人员在构建基于神经网络的图形处理模型方面提出的一些里程碑。 我们已经介绍了使用这些架构时必须做出的一些重要设计选择，希望 GNN 游乐场可以直观地了解这些设计选择的经验结果是什么。 近年来 GNN 的成功为解决各种新问题创造了绝佳机会，我们很高兴看到该领域将带来什么。六、回顾作者先介绍了什么是图，用向量表示图的属性（顶点、边、全局），然后介绍了现实生活中的数据如何表示成图，如何对图做预测，以及机器学习算法用到图上的时候有什么挑战。接下来作者开始介绍 GNN 。 GNN 就是对属性做变化，而不改变图的结构，并设计了一个简单的例子。当属性有缺失时，可以使用聚合 (pooling) 的操作。然后作者介绍了我们日常使用中真正意义上的 GNN ，通过每一层将信息不断传递，每个顶点可以看到邻接顶点、相连边、全局的信息。 GNN 能够对图的结构进行有效的发掘。然后就是一个实际的 GNN 模型实验。接下来他讨论了一些有关的拓展问题。尤其关注作者的精美的图。如果觉得本教程不错或对您有用，请前往项目地址 https://raw.githubusercontent.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，Github主页：传送门" }, { "title": "Transformer", "url": "/posts/Transformer/", "categories": "Tutorial, AI Component", "tags": "transformer, attention", "date": "2022-03-29 10:10:00 +0800", "snippet": "Transformer https://arxiv.org/abs/1706.03762一、摘要主流的序列转录模型主要依赖于复杂的循环或者卷积神经网络，其中包含编码器 (encoder) 和解码器 (decoder) 。在最好的模型中也会在编码器和解码器之间使用注意力机制。这篇文章提出一个新的简单的架构 —— Transformer ，这个模型仅仅依赖于注意力机制，而没有使用循环或者卷积。两个在机器翻译上的实验显示这个模型在机器性能上特别好，可以有更高的并行度和需要更少的时间训练。二、结论在这篇工作中，作者提出了 Tramsformer ，这是第一个完全基于注意力机制的序列转录模型，将广泛用于编码器-解码器架构的循环层替换为了 multi-head self-attention 。对于翻译任务， Transformer 可以比其他架构快很多，且在实际数据小效果好。这种基于注意力的模型可以被用于除文本以外的数据上，比如图片、语音、视频，使得生成 (generation) 不那么序列化也是研究的目标之一。【如果机器学习代码开源，最好放在摘要的最后一句话】三、导言当时 2017 年最主流的时序模型是 RNN ，如 LSTM (long short-tern memory) 和 GRU (gated recurrent neural networks) 。其中有两个最主流的模型：语言模型 (language model) 和编码器-解码器架构 (encoder-decoder architectures) （输出的结构花比较多时）。RNN 的计算特点是沿序列不断处理，对 $t$ 个输入，会根据前一个隐藏状态 $h_{t-1}$ 和第 $t$ 个输入计算当前隐藏状态 $h_t$ 。但这种处理模型有两个问题：第 $t$ 个输入必须等待前 $t-1$ 个输入都计算完成后才能开始计算，这导致计算无法并行；同时由于计算是逐步完成的，可能会导致时序早期的记忆信息在后期丢失。在这之前 attention 已经被成功用在编码器和解码器中，主要用在如何将编码器的信息有效地传递给解码器。四、相关工作一些工作关注如何使用卷积神经网络替换循环循环神经网络来减少时序的计算。一个问题是用卷积神经网络对一些比较长的序列难以建模，因为卷积每次看的是一个非常小的窗口，只能通过叠加层数的方法使它们交互。如果使用 Transformer 模型里的注意力机制，一层就能够看到所有的序列。但卷积的一个好处是可以做多个输出通道，可以识别不一样的模式，为了达到这个效果，作者提出了多头注意力机制 (multi-head attention) 。自注意力机制其实在之前的一些工作都有提到。End-to-end memory network 不是用序列比对递归而是基于循环注意力机制，在简单语言问答和语言模型上表现良好。Transfomer 是第一个只使用注意力机制来做编码器和解码器的模型。五、模型架构在众多序列模型中比较好的是编码器和解码器的架构，编码器将输入 $(x_1, \\dots , x_n)$ 表示成 $\\mathbf z = (z_1, \\dots, z_n)$ ，其中 $z_t$ 是 $x_t$ 的向量表示。解码器拿到编码器的输出 $\\mathbf z$ 生成一个长为 $m$ 的序列 $(y_1, \\dots, y_m)$ ，其中 $n$ 和 $m$ 可以不等，和编码器不同，解码过程是一个个进行的。每一步都是自回归 (auto-regression) （过去时刻的输出也是当前时刻的输入）。Transformer 遵循这种整体架构，对编码器和解码器使用堆叠的自注意和逐点、完全连接的层。左侧是编码器，右侧是解码器。左侧灰框就是一个 transformer block ，里面只使用了一些注意力层、残差块和前馈神经网络。然后编码器的输出会作为解码器的输入，但在此之前会有一个掩码多头注意力机制。最后输出进入输出层，进行 softmax 。1. 编码器和解码器堆栈编码器：采用 6 个一样的层，每层有两个子层：multi-head self-attention mechanism 和 MLP 。对每个子层采用一个残差连接，最后使用层正则化 (layer normalization) ，即子层的输出是 $\\text{LayerNorm}(x+\\text{Sublayer}(x))$ 。由于残差块要求输入和输出大小一致，为了简化问题，规定所有输出的大小 $d_{model}$ 为 512 。LayerNorm vs BatchNorm。考虑二维输入，每一行是一个样本 (batch) ，每一列是一个特征 (feature) 。 BatchNorm 是每一个 batch 中将一列（即一种特征）的均值变成 0 ，方差变成 1 。在预测时使用的是全部数据的均值和方差。 BatchNorm 有两个参数 $\\lambda$ 和 $\\beta$ ，可以将均值和方差缩放到指定值。 LayerNorm 则对每行（即每个样本）做正则化（均值为 0 ，方差为 1 ）。而 RNN 输入的是 3D 数据（每个样本是一个句子，每个句子有很多词，每个词是一个向量）。此时，行还是 batch ，列是序列长度 $n$ ，深度是 feature $d$ 。两者依然是切法不一样， BN 是按照 feature 切， LN 是按照 batch 切。在实际使用中， LN 使用的更多一点，因为在序列模型中，每个样本的长度可能会发生变化， BN 的结果的抖动幅度会比较大。而 LN 是每个样本自己算均值和方差，也不需要存储全局的均值和方差，更加稳定。在变长的应用中一般不使用 BatchNorm 。解码器：采用 6 个相同的层，每个层含有前面提到的两个子层和一个针对编码器输出的 multi-head attention 子层。同样使用了残差连接和 LN 。对解码器做的是自回归，即当前输出的输入集是前面时刻的输出，它在做预测的时候是不能看到之后那些时刻的输出。但在注意力机制中，每次能够看到完整的输入，所以在解码器训练的时候，为了避免在预测第 $t$ 个时刻的输出的时候看到 $t$ 时刻以后的那些输入，作者通过一个带掩码的注意力机制，保证训练和预测的时候行为是一致的。2. 注意力层注意力函数是一个将 query 和一些 key-value 对映射成输出的一个函数，其中 query 、 keys 、 values 都是向量。输出是 value 的一个加权和，所以输出的维度和 value 的维度是一致的。对于每一个 value 的权重，是根据 key 和对应 value 的相似度 (compatibility function) 计算得到的。其中注意力函数有很多方法。接下来介绍 Transformer 用到的注意力。2.1 Scaled Dot-Product Attention输入的 queries 和 keys 是等长的 $d_k$ ， values 的维度是 $d_v$ 。对每一个 query 和 key 进行内积，再除以 $\\sqrt{d_k}$ ，再用 softmax 得到权重。这样所有的权重的和为 $1$ 。然后将这些权重作用在 values 上得到输出。实际计算过程中需要并行计算，将不同的 query 写成一个 $n \\times d_k$ 的矩阵 $Q$ ， keys 写成一个 $m \\times d_k$ 的矩阵 $K$ ， values 写成一个 $m \\times d_v$ 的矩阵 $V$ ：\\(\\text{Attention}(Q, K, V) = \\text{softmax}(\\cfrac{QK^T}{\\sqrt{d_k}})V\\)那么这个注意力机制和其他的有什么不同？一般有两种注意力机制：加性注意力机制 (additive attention) 和点积注意力机制 (dot-product attention) 。除以 $\\sqrt{d_k}$ 的原因是当向量长度比较长时点积的结果会相对比较大，之间的相对差距也会变大，最大值会更加靠近于 $1$ ，值向两端靠拢。此时梯度比较小，不利于反向传播。然后需要看如何 mask 。假设 query 和 key 等长，且在时间上对应。之前的计算步骤一样的，只是在计算输出之前不要用到未来的东西。具体做法是 $t$ 时刻将点积结果中 $t$ 及其之后的值改为一个负的非常大的数，如 $-1e^{10}$ ，这样 softmax 之后这些权重都会变成 $0$ 。2.2 Multi-Head Attention与其使用单一的注意力函数，不如将整个 query、 key 、 value 投影到低纬 $h$ 次，再做 h 次的注意力函数。连接 (concat) 每个函数的输出，再投影回来，得到最终的输出。这么做的原因是 dot-product attention 中几乎没有可以学习的参数，但是有时我们希望可以识别不同的模式。有点类似于卷积网络中的多输出通道。\\(\\text{MultiHead}(Q,K,V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h)W^O\\\\\\text{where head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\\\\\\)其中 $W_i^Q \\in \\mathbb R^{d_\\text{model} \\times d_k}$ ， $W_i^K \\in \\mathbb R^{d_\\text{model} \\times d_k}$ ， $W_i^V \\in \\mathbb R^{d_\\text{model} \\times d_v}$ ， $W^O \\in \\mathbb R^{hd_v \\times d_\\text{model}}$ 。在实际过程中 $h=8$ 。由于残差连接的存在，规定投影的维度 $d_k = d_v = d_\\text{model}/h = 64$ 。2.3 注意力在模型中的应用Transformer 将 multi-head attention 用于三种途径： 编码器注意力：假设句子长度为 $n$ ，编码器的输入是 $n \\times d$ 的向量。输入复制分成了 3 个，表示同样的东西既作为 key ，也作为 value ，还作为 query 。所以也叫做自注意力机制。编码器输出的大小和输入相同。不考虑多头和投影时，输出实际上是输入的加权和。权重来自于自己和其他所有向量的相似度的 softmax ，它和自己的相似度肯定是最大的。如果考虑多头的话，我们会学习 h 个不同的距离空间，使得结果不太一样。 解码器注意力 1 ：和上面一样的自注意力，只是有了 mask 。 解码器注意力 2 ：不再是自注意力。 key 和 value 来自于编码器的输出， query 来自解码器下一个 attention 的输入。对编码器的输入，根据解码器第一个子层的输出选出来。即解码器根据不同的输入，去解码器的输出里面挑选最感兴趣的东西。3. Position-wise Feed-Forward Attention其实本质就是一个单隐藏层 MLP ，对每个词使用一个相同的 MLP 。\\(FFN(x) = max(0, xW_1+b_1)W_2+b_2\\)$x$ 的维度是 $512$ ， $W_1$ 将维度扩大到 $2048$ ， $W_2$ 将维度投影回 $512$ 。如果使用 pytorch 实现，其实就是两个线性层放在一起，不需要改任何参数，因为 pytorch 对于 3D 输入默认在最后一个维度做计算。之前提到的 attention 起到的作用其实是将序列中的信息汇聚 (Aggregation) 。由于此时的结果已经有整个序列的感兴趣信息，因此 MLP 也就可以分开做了。RNN 其实和 Transformer 相同，都是使用一个 MLP 来做语义空间的转换，不一样的是如何传递序列的信息： RNN 将上一个时刻的输出并入下一个时刻的输入，但在 Transformer 中通过一个 attention 层拿到整个序列的全局信息，然后用 MLP 进行语义转换。关注点都在于如何有效地使用序列的信息。4. Embeddings 和 Softmax输入是一个个 token ，需要映射成向量。 Embedding 就是给定任何一个 token ，学习一个长为 $d$ 的向量表示。在编码器输入、解码器输入和 softmax 之前都有一个 embedding ，它们共享相同的参数来简化训练。在每个嵌入层将权重乘以 $\\sqrt{d_{model}}$ 。因为在学习 embedding 时会希望减小向量的 L2 Norm ，这样维度增大会导致权重减小。但是之后由于需要加入 positional Encoding ，这个不会随着向量的长度而改变大小。5. Positional Encodingattention 是不包含时序信息的，输出是 value 的一个加权和，权重是 query 和 key 之间的距离，和序列信息无关。这导致顺序变化但值不会变化。在 Transformer 中将位置 $i$ 加到输入中。\\(PE(pos, 2i) = \\sin(pos/10000^{2i/d_\\text{model}})\\\\PE(pos, 2i+1) = \\cos(pos/10000^{2i/d_\\text{model}})\\\\\\)大概的思路是一个数字用一定长度 $512$ 的向量来表示，值是用周期不一样的 $\\sin$ 和 $\\cos$ 计算得到的。对结果放大 $\\sqrt{d_k}$ 倍。六、为什么要自注意力作者比较了四种不一样的层：自注意力 (self-attention) 、循环层 (recurrent) 、卷积层 (convolutional) 、受限的自注意力层 (self-attention (restricted)) 。首先比较了计算复杂度，越低越好、顺序的计算（下一步计算必须要等前面多少步计算完成），越少越好、信息从一个数据点走到另一个数据点要走多远，越短越好。首先看自注意力层， $n$ 是序列的长度， $d$ 是向量的长度。复杂度是 $O(n^2 \\cdot d)$ ，矩阵乘法的并行度很高，为 $O(1)$ ，一个 query 会和所有的 key 做运算，输出也是所有 value 的加权和，所以传输的长度是 $O(1)$ 。然后看一下循环层，如果序列长度为 $n$ ，就一个个做运算，每个里面计算$n \\times d$ 乘以 $d \\times ？$ 的 $W$ 矩阵，根据矩阵的并行计算，最小的并行单元的计算复杂度是 $d^2$ ，所以总的计算复杂度是 $n \\cdot d^2$ 。但是由于一步步做运算，当前时刻的计算需要等待前面时刻的结果，在并行性上只有 $O(n)$ ，而且最初点的历史信息需要走过 $n$ 步才能传递过去，所以传递的长度是 $O(1)$ ，所以 RNN 不善于处理特别长的序列。然后看下卷积层，在序列上采用的是 $1d$ 卷积，卷积核大小 $1 \\times k$ ，输入输出的通道数为 $d$ ，所以计算复杂度是 $k \\cdot n \\cdot d^2$ 。但是卷积操作的并行度很高，为 $O(1)$ ，另外每个 token 一次只能看到一个 kernel 大小的窗口，在距离 $k$ 以内一次就可以完成信息传递，所以传输的长度是 $O(\\log_k(n))$ 。最后看看受限的自注意力层。 query 只和最近的 $r$ 个邻居做运算，这样减少了计算复杂度 $n^2 \\cdot d$ ，但也增加了传输的长度 $O(n/r)$ 。实际上 attention 对整个模型的假设更少，导致需要更多的数据和更大的模型才能训练出和 RNN 、 CNN 相同的效果，因此现在基于 transformer 的模型非常大和贵。七、实验1. 训练数据集和 batchingWMT 2014 英语-德语数据集，其中含有 450 万个语句对，采用 bpe 编码，有共享的 37000 个 token 。共享的好处是不需要两个字典，编码器和解码器的 embedding 可以使用同一个。以及 WMT 2014 英语-法语数据集。2. 硬件和 schedule使用 8 个 P100 的 GPU 。小模型，一步 0.4 s，训练 100000 步，12 个小时。大模型，一步 1 s，训练 300000 步，3.5 天。3. 优化器学习率：\\(lrate = d_\\text{model}^{-0.5} \\cdot \\min(step\\_num^{-0.5}, step\\_num \\cdot warmup\\_steps^{-1.5})\\)4. 正则化Residual Dropout：每一个子层，在输出上，进入残差连接和 LN 之前，使用 dropout ；在 embeddings 和 pe 求和之前也用了 dropout ， dropout 率是 0.1 。Label Smoothing：将 0 和 1 适当靠里，这会增加模型的不可信度，但会增加精度和 BLUE 。八、结果九、评论这篇文章写作非常简洁，也没有用太多技巧。写作时最好适当减少不重要的内容，讲清楚故事，为什么要做这件事，以及设计的理念。Transformer 已经在各种领域都有进展。标题依然说只需要 attention ，但实际上 Transformer 中的残差块和 MLP 缺一不可。attention 不会对数据的顺序做建模，却能够超过 RNN ，现在研究认为它使用了一个更广泛的归纳偏置，使得它能处理一些更一般化的信息。这也就是为什么 attention 并没有做任何空间上的假设却能超过 CNN ，但是它的代价是因为假设更加一般，对数据抓取信息的能力变差，所以需要更多的数据、更大的模型才能训练出需要的效果。如果觉得本教程不错或对您有用，请前往项目地址 https://raw.githubusercontent.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，Github主页：传送门" }, { "title": "Config ccache", "url": "/posts/Config-ccache/", "categories": "Tutorial, ccache", "tags": "install, c/c++, ccache", "date": "2021-11-03 21:15:00 +0800", "snippet": "Ccache这篇博客介绍一个小工具 ccache ，可以提高再次编译的速度。其原理是通过吧项目的源文件用 ccache 编译器编译，然后缓存编译生成的信息，从而在下一次编译时，利用这个缓存加快编译的速度，目前支持的语言有 C 、 C++ 、 Objective-C 、 Objective-C++ ，如果找不到 ccache 编译器，还是会选择系统默认的编译器来编译源文件。接下来讲述 ccache 的利用过程。一、安装这里介绍 Ubuntu 的安装方法。首先通过 apt 安装：sudo apt install ccache安装完后我们不能直接使用，需要先进行配置:sudo gedit ~/.bashrc在新打开的文档末尾回车，添加如下语句，注意 &amp;lt;username&amp;gt; 要改成你的用户名。export CCACHE_DIR=&quot;/home/&amp;lt;username&amp;gt;/.ccache&quot;export CC=&quot;ccache gcc&quot;export CXX=&quot;ccache g++&quot;export PATH=&quot;$PATH:/usr/lib/ccache&quot;Ctrl+S 或点击 Save 按钮保存，然后需要更新 .bashrc 使其生效。source ~/.bashrc我们可以根据硬盘空间设置 ccache 允许使用的最大缓存空间， &amp;lt;xx&amp;gt; 修改为数字：ccache -M &amp;lt;xx&amp;gt;G二、使用1. CMake对于采用 CMake 的应用，只需要将以下的代码加入到命令 project() 行以后即可：find_program(CCACHE_PROGRAM ccache)if (CCACHE_PROGRAM) set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE &quot;${CCACHE_PROGRAM}&quot;)endif ()add_compile_definitions(PROJECT_DIR=&quot;${PROJECT_SOURCE_DIR}&quot;)2. Xcode参考参考教程：ccache - 让Xcode编译速度飞起来。如果觉得本教程不错或对您有用，请前往项目地址 https://raw.githubusercontent.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！三、参考教程 ubuntu配置ccache ccache - 让Xcode编译速度飞起来作者：Harry-hhj，Github主页：传送门" }, { "title": "RM 教程 6 —— 特征点，双目相机与光流", "url": "/posts/RM-Tutorial-6-Stereo/", "categories": "Course, RM", "tags": "getting started, robomaster, computer vision", "date": "2021-10-29 10:00:00 +0800", "snippet": "RM 教程 6 —— 特征点，双目相机与光流 机械是肉体， 电控是大脑， 视觉是灵魂特征点给你两张从不同视角拍摄同一物体的图片，一个常见的任务便是找到该物体在两张图片中对应的像素位置。解决这一问题的方式通常是特征点。特征点通常是一些角点，边缘点，在这些地方通常有较高的像素梯度，使得我们可以十分轻松地通过局部算子的响应来找到这些点。角点检测的算法比较著名的是Harris算法，具体在本教程内不展开。同时，为了进行匹配，我们必须用定量的方式来描述这些角点，使得我们能够仅仅比较这些定量描述向量的距离，便可得知两个特征点之间的相似程度。从而，我们便得到了特征点的两大重要概念，Keypoint关键点和Descriptor描述子。ORB-FAST这里将以ORB-FAST特征点举例，来讲解特征点检测算法。FAST-N也是一种角点检测算法，它遍历每一个像素点，比较以点为中心半径为3的圆上的各个点像素值与中心点的像素值，若周围有连续N个点的像素值不落在中心点像素值的（设定好阈值的）邻域内，便称该点为一个角点，或者说特征点。我们通常使用FAST-12，这个算法有一个加速，即先检测1，5，9，13这四点，若这四点有三个及以上不落于邻域内，则才可能为一个角点。当然以上算法可能形成大量角点，通常采用Harris响应值（详见Harris算法）来做非极大值抑制（NMS），即某一邻域内只保留响应最大的那个角点。以上算法我们可以在多尺度下完成，并通过计算灰度质心来获得关键点的方向信息，这样获得的特征点便具有了尺度和方向不变性，相比原先的FAST特征点更加鲁棒。此外，我们通过特征点的方向，对图像进行旋转，然后在点周围随机取128对点（p,q）,我们的描述子便可表征为一个128维向量。各对点对应向量的各个维度，当p点的灰度值大于q时对应维度的值便为1，反之为0。故而，值得注意的一点便是我们比较ORB的描述子时采用Hamming距离（即异或运算）而非欧式距离。下面便是实践环节，本教程的实践均基于唐欣阳学姐前部长在上个赛季布置的作业，即进行一个图像全景拼接的过程。我们对以下的两张在不同视角用同一相机拍摄的对于同一场景图片的进行特征点生成与匹配代码如下读入图片并转化为灰度图int main(int argc,char** argv){ namedWindow(&quot;show&quot;,WINDOW_NORMAL); resizeWindow(&quot;show&quot;,800,600); // read two images Mat img1 = imread(&quot;../stereo-data/0_orig.jpg&quot;); Mat img2 = imread(&quot;../stereo-data/1_orig.jpg&quot;); // using gray image to compute Mat gray1,gray2; cvtColor(img1,gray1,COLOR_BGR2GRAY); cvtColor(img2,gray2,COLOR_BGR2GRAY);创建ORB特征点检测器，opencv提供其为一个智能指针对象，create函数具体参数较为复杂，如有兴趣可自行查看文档和阅读ORB相关资料以了解更多其原理。当然在这之前n_features还是可以调调参的，默认为500个点。 //create orb detector Ptr&amp;lt;ORB&amp;gt; orb = ORB::create();检测关键点 // create the container of Key points vector&amp;lt;KeyPoint&amp;gt; feature_points1,feature_points2; // do Orient_FAST detect Keypoint orb-&amp;gt;detect(gray1,feature_points1); orb-&amp;gt;detect(gray2,feature_points2);根据关键点计算描述子，描述子用Mat矩阵存储，你会发现这是一个$500\\times 32$的矩阵，其中元素均为uchar类型即128bit，存储上述的128维特征向量，通过位运算大大提高了计算速度。 // compute the descriptors Mat descriptor1,descriptor2; orb-&amp;gt;compute(gray1,feature_points1,descriptor1); orb-&amp;gt;compute(gray2,feature_points2,descriptor2);进行暴力匹配，使用Hamming距离 //do matching //create Matcher BFMatcher matcher(NORM_HAMMING); //O(N^2) vector&amp;lt;DMatch&amp;gt; pairs; matcher.match(descriptor1,descriptor2,pairs); printf(&quot;DMatch contains the matched points like (%d in img1,%d in img2) their distance is %.3f (in Hamming Norm).\\n&quot; ,pairs[0].queryIdx,pairs[0].trainIdx,pairs[0].distance);显示匹配结果 //draw the matched pairs and show Mat canvas; drawMatches(img1,feature_points1,img2,feature_points2,pairs,canvas); imshow(&quot;show&quot;,canvas); waitKey(0);通过筛选，选择距离较小的匹配点，作为较好（good）匹配，通常我们会使用较好匹配作后续处理 //You can also filter the match to generate vector&amp;lt;DMatch&amp;gt; good; double min_dist = 100000; // compute the minimum of the distance for(const DMatch&amp;amp;m:pairs) { if(m.distance &amp;lt; min_dist) min_dist = m.distance; } // filter for(const DMatch&amp;amp;m:pairs) { if(m.distance &amp;lt; max(min_dist*2,30.)) { good.push_back(m); } } drawMatches(img1,feature_points1,img2,feature_points2,good,canvas); imwrite(&quot;../good_match.jpg&quot;,canvas); imshow(&quot;show&quot;,canvas); waitKey(0);较好匹配的效果如下画出特征点，你可以看到特征点的方向以及描述子的大小 // draw the keypoint drawKeypoints(img1,feature_points1,canvas,Scalar::all(-1),DrawMatchesFlags::DRAW_RICH_KEYPOINTS); imwrite(&quot;../keypoints.jpg&quot;,canvas); imshow(&quot;show&quot;,canvas); waitKey(0); return 0;}将上述代码封装为函数，供后续算法使用除了ORB特征点，还有SIFT特征点等，他们的使用与ORB类似，就不展开了。2D图像的匹配 在比赛中，我们的车辆是运动的，我们是否有办法知道相邻图像之间相机拍摄角度的位姿变化呢？这样的话，我们也能确定车辆的位置变化。、 上面全景匹配问题，我们如何将一张图片的像素点转换到另外一个视角下的样子，以完成匹配呢？ 两张图片的匹配，是一个单目匹配问题。在这里，我们不知道两个视角之间的位姿关系。而在双目视觉中，我们知道两个视角之间的位姿关系，这将在后面描述。下面介绍一些重要概念。对极约束对极约束是一个非常漂亮的公式，下面来一起推出它！首先，如图所示，p1,p2是一对已经匹配好的对应点，即它们在空间中对应同一物体P我们称向量$\\vec{e_1p_1}$ $\\vec{e_2p_2}$ 所在的直线为极线，$O_1PO_2$为极平面，$O_1O_2$为基线，这张我们后面还会用到在上两节课中，我们知道了这些公式\\(z_1p_1 = z_1 \\left[ \\begin{matrix}u_1\\\\v_1\\\\1\\end{matrix}\\right] = KP_1\\\\z_2p_2 = z_2 \\left[ \\begin{matrix}u_2\\\\v_2\\\\1\\end{matrix}\\right] = KP_2\\\\P_2 = RP_1+t\\)其中$R,t$为视角1到视角2的位姿变化，未知。设归一化相机坐标系下，有\\(x_1 = K^{-1}\\left[ \\begin{matrix}u_1\\\\v_1\\\\1\\end{matrix}\\right] \\\\x_2 = K^{-1}\\left[ \\begin{matrix}u_2\\\\v_2\\\\1\\end{matrix}\\right]\\)下面的等式被称为up to scale等式，即两边在任意一边乘上一个非零常数后相等如$2 = 1$就是一个up to scale等式则有下面式子，等式两边差深度因子\\(P_1 = K^{-1}\\left[ \\begin{matrix}u_1\\\\v_1\\\\1\\end{matrix}\\right] = x_1\\\\P_2 = RP_1+t = K^{-1}\\left[ \\begin{matrix}u_2\\\\v_2\\\\1\\end{matrix}\\right] = x_2\\)即\\(x_2 = Rx_1+t\\\\t\\times x_2 = t\\times(Rx_1+t) = t\\times Rx_1 + t\\times t\\)显然 $t\\times t = 0$我们试着两边对$x_2$做内积，这是因为大学物理或者高等数学告诉我们，$t\\times x_2$是垂直于$x_2$的\\(x_2^T(t\\times x_2) = x_2^T(t\\times Rx_1) \\\\0 = x_2^T(t\\times Rx_1)\\)根据up to scale的定义，我们知道下面这个式子在正常等式下也成立\\(x_2^T(t\\times Rx_1) = 0\\)这里补充一个概念\\(\\left[ \\begin{matrix}a_1\\\\a_2\\\\a_3\\end{matrix}\\right]\\times \\left[ \\begin{matrix}b_1\\\\b_2\\\\b_3\\end{matrix}\\right] =\\left| \\begin{matrix}\\vec{i}&amp;amp;\\vec{j}&amp;amp;\\vec{k}\\\\a_1&amp;amp;a_2&amp;amp;a_3\\\\b_1&amp;amp;b_2&amp;amp;b_3\\end{matrix}\\right|=\\left[\\begin{matrix}0&amp;amp;-a_3&amp;amp;a_2\\\\a_3&amp;amp;0&amp;amp;-a_1\\\\-a_2&amp;amp;a_1&amp;amp;0\\end{matrix}\\right]\\left[\\begin{matrix}b_1\\\\b_2\\\\b_3\\end{matrix}\\right] = a^{\\ \\hat{}}\\ b\\)则\\(x_2^Tt^{\\ \\hat{}}Rx_1 = 0\\)该式便称为对极约束,当然像素值的对极约束为\\(p_2^T{K^{-1}}^Tt^{\\ \\hat{}}RK^{-1}p_1 = 0\\)可以改写为\\(x_2^TEx_1 = 0\\\\p_2^TFp_1 = 0\\)$E$称为essential matrix本质矩阵，来源其尺度不变性，即对$\\forall\\alpha\\in \\mathbb{R} , \\alpha E$仍然为一个可行的本质矩阵，这在于平移向量$t$的尺度，在这里也表现出了单目的尺度不确定性$F$称为fundamental matrix基础矩阵，可以从$E$导出，在于你有没有完成上上周的相机标定任务,由于$K$一般已知，且$E$形式更为简单，我们通常估计$E$利用我们匹配的特征点对，可以列出多个对极约束方程\\({x_2^i}^TEx_1^i = 0\\\\E = \\left[\\begin{matrix}e_1&amp;amp;e_2&amp;amp;e_3\\\\e_4&amp;amp;e_5&amp;amp;e_6\\\\e_7&amp;amp;e_8&amp;amp;e_9\\end{matrix}\\right] \\rightarrow e = \\left[\\begin{matrix}e_1\\\\e_2\\\\e_3\\\\e_4\\\\e_5\\\\e_6\\\\e_7\\\\e_8\\\\e_9\\end{matrix}\\right]\\)实际上可改写为一个线性方程组,我们用至少8组特征点构造一个$8\\times 9$的$A$矩阵，实际求解会用RANSAC方式来优选匹配，排除误匹配\\(Ae = 0\\) RANSAC简介 RANSAC，随机采样一致性算法，是一种迭代算法，其本质思路是对数据集随机采样出数个子集，在这些子集上对原问题进行估计，并计算估计指标（比如MSE等），若指标低于设定阈值，则采纳该子集，将其元素作为inlier（内点），每次迭代，我们在随机采样的各个子集中选择最优子集，即内点最多的一个子集，以其评估的参数作为该次迭代的结果，然后根据迭代停止条件（如迭代最大次数，设定迭代停止阈值等）选择继续迭代还是停止返回结果。解线性方程求解$E$,由于$E = t^{\\ \\hat{}}R$, 对$E$做SVD分解，便能求解$R$和$t$,同时$E$的特征值的约束使得我们能够求出$E$的形式。这里详细过程涉及矩阵论知识就不展开了，opencv已经帮我们封装好了。这些都是一些数学，虽然美，但是也比较烦，我们还是来看看怎么实际操作。读入相机内参int main(int argc,char** argv){ // camera matrix FileStorage params(&quot;../camera.yaml&quot;,FileStorage::READ); Mat K = params[&quot;K&quot;].mat();找特征点，已经封装成函数，输入图片，输出较好匹配的对应点集 Mat img1 = imread(&quot;../stereo-data/0_orig.jpg&quot;); Mat img2 = imread(&quot;../stereo-data/1_orig.jpg&quot;); vector&amp;lt;Point2f&amp;gt; left_pts; vector&amp;lt;Point2f&amp;gt; right_pts; find_match(img1,img2,left_pts,right_pts);解本质矩阵，使用RANSAC方法 // find the Essential Matrix using RANSAC Mat E = findEssentialMat(left_pts,right_pts,K,RANSAC); cout&amp;lt;&amp;lt;&quot;Essential Matrix is \\n&quot;&amp;lt;&amp;lt;E&amp;lt;&amp;lt;endl;最后分解E，得到R和t,这里输入对应点为了代入排除矩阵分解时的多解，值得注意的是，解得的平移向量t是归一化过的，我们并不知道它的单位，即其具有尺度不确定性，这也是单目估计的弱点所在。 Mat R,t; recoverPose(E,left_pts,right_pts,K,R,t); cout&amp;lt;&amp;lt;&quot;R is \\n&quot;&amp;lt;&amp;lt;R&amp;lt;&amp;lt;endl; cout&amp;lt;&amp;lt;&quot;t (unknown unit) is \\n&quot;&amp;lt;&amp;lt;t&amp;lt;&amp;lt;endl; return 0;}这里尺度不确定性可以通过补充深度信息来解决，从而实现通过反投影方式来进行图像拼接，不过在此之前，我们先来介绍一下另外一种进行直接二维映射的图像拼接方式。实际上，此处估计出的相机运动信息通常不恢复其尺度至常见单位，而是基于初始化来固定尺度，通常做法有将初始化时所有特征点深度设为1（比如对着一面墙来初始化），或者就像这样将平移向量$t$归一化，但这样后续计算会不稳定。单应矩阵回顾此式,注意该式为up to scale\\(P_1 = K^{-1}\\left[ \\begin{matrix}u_1\\\\v_1\\\\1\\end{matrix}\\right] = x_1\\\\RP_1+t = K^{-1}\\left[ \\begin{matrix}u_2\\\\v_2\\\\1\\end{matrix}\\right] = x_2\\)假定所有的特征点落在同一平面上，则有\\(n^TP_1+d = 0\\\\-\\frac{n^TP_1}{d} = 1\\)则\\(p_2 = K(RP_1-\\frac{n^TP_1}{d}t) = K（R-\\frac{t}{d}n^T）P_1 = K（R-\\frac{t}{d}n^T）K^{-1}p_1 = Hp_1\\)其中$p1,p2$均为像素点（可以在去畸变后再进行特征点匹配，本教程例子均不考虑畸变）这样只需求出单应矩阵$H$便可，实际上$H$是一个透视变换矩阵，这你们在上节课学过那么有\\(H = \\left[ \\begin{matrix}h_{11}&amp;amp;h_{12}&amp;amp;h_{13}\\\\h_{21}&amp;amp;h_{22}&amp;amp;h_{23}\\\\h_{31}&amp;amp;h_{32}&amp;amp;h_{33}\\end{matrix}\\right]\\)则有\\(\\left[ \\begin{matrix}u_2\\\\v_2\\\\1\\end{matrix}\\right]= \\left[ \\begin{matrix}h_{11}&amp;amp;h_{12}&amp;amp;h_{13}\\\\h_{21}&amp;amp;h_{22}&amp;amp;h_{23}\\\\h_{31}&amp;amp;h_{32}&amp;amp;h_{33}\\end{matrix}\\right]\\left[ \\begin{matrix}u_1\\\\v_1\\\\1\\end{matrix}\\right]\\)则有两对约束\\(u_2 = \\frac{h_{11}u_1+h_{12}v_1+h_{13}}{h_{31}u_1+h_{32}v_1+h_{33}}\\\\v_2 = \\frac{h_{21}u_1+h_{22}v_1+h_{23}}{h_{31}u_1+h_{32}v_1+h_{33}}\\)通过这两对约束，基于四对匹配特征点，我们同样可以获得$8\\times 9$矩阵$A$\\(A\\left[ \\begin{matrix}h_{11}\\\\h_{12}\\\\h_{13}\\\\h_{21}\\\\h_{22}\\\\h_{23}\\\\h_{31}\\\\h_{32}\\\\h_{33}\\end{matrix}\\right] = b\\) 解得$H$，并且也可通过矩阵分解来获得$R$和$t$,详细过程略过下面同样是实践环节，在本环节，我们将进行图像拼接，在这里我们假设所有点在同一平面，这样效果可能不好，但值得一试。(由于opencv没有提供api进行$H$的分解计算，想了解从$H$得到$R$和$t$可参考opencv_$version$/samples/cpp/tutorial_code/features2D/Homography/pose_from_homography.cpp例程）求解$H$单应矩阵的函数,和上面求解$E$类似void find_Trans_H(const Mat &amp;amp;img1,const Mat &amp;amp;img2,Mat&amp;amp; H){ vector&amp;lt;Point2f&amp;gt; lpt,rpt; find_match(img1,img2,lpt,rpt); H = findHomography(lpt,rpt,RANSAC);}进行图像拼接的函数。对于图像透视变换后其投影位置在原图像外，一个比较简单的解决方法是增大展示的画布大小，这样便需要对原图像进行一定平移使其展示在画布中心。若对原图像进行了平移，那么投影的图像其投影位置也要进行平移，可以用如下函数\\(u_2 + \\delta u = \\frac{(h_{11}+\\delta u \\cdot h_{31})u_1+(h_{12}+\\delta u \\cdot h_{32})v_1+(h_{13}+\\delta u \\cdot h_{33})}{h_{31}u_1+h_{32}v_1+h_{33}}\\\\v_2+\\delta v = \\frac{(h_{21}+\\delta v \\cdot h_{31})u_1+(h_{22}+\\delta v \\cdot h_{32})v_1+(h_{23}+\\delta v \\cdot h_{33})}{h_{31}u_1+h_{32}v_1+h_{33}}\\)通过改动$H$,我们在基于warpPerspective函数进行变换的时候能对投影位置进行相应的平移。void process_Stitch(const Mat&amp;amp; img1,const Mat&amp;amp; img2,const Mat &amp;amp;img3,const Mat&amp;amp; H1,const Mat&amp;amp; H2){ namedWindow(&quot;show&quot;,WINDOW_NORMAL); resizeWindow(&quot;show&quot;,800,600); Mat canvas; /*process img1 and img2 , i.e., middle and right*/ /* adjust the H*/ Mat H = H1.clone(); for(int i = 0;i&amp;lt;3;++i) { H.at&amp;lt;double&amp;gt;(0,i) += H.at&amp;lt;double&amp;gt;(2,i)*double(img1.cols); H.at&amp;lt;double&amp;gt;(1,i) += H.at&amp;lt;double&amp;gt;(2,i)*double(img1.rows); } warpPerspective(img2,canvas,H,Size(3*img2.cols,3*img2.rows)); /*process img1 and img3 , i.e., middle and left*/ H = H2.clone(); for(int i = 0;i&amp;lt;3;++i) { H.at&amp;lt;double&amp;gt;(0,i) += H.at&amp;lt;double&amp;gt;(2,i)*double(img1.cols); H.at&amp;lt;double&amp;gt;(1,i) += H.at&amp;lt;double&amp;gt;(2,i)*double(img1.rows); } Mat canvas2; warpPerspective(img3,canvas2,H,Size(3*img2.cols,3*img2.rows)); add(canvas,canvas2,canvas); /*move the origin image to center*/ img1.convertTo(canvas(Rect(img1.cols,img1.rows,img1.cols,img1.rows)),CV_8UC3); imshow(&quot;show&quot;,canvas); imwrite(&quot;../stitch.jpg&quot;,canvas); waitKey();}main函数过程int main(int argc,char** argv){ // camera matrix FileStorage params(&quot;../camera.yaml&quot;,FileStorage::READ); Mat K = params[&quot;K&quot;].mat(); // camera matrix Mat img1 = imread(&quot;../stereo-data/0_orig.jpg&quot;); Mat img2 = imread(&quot;../stereo-data/1_orig.jpg&quot;); Mat H1,H2; Mat img3 = imread(&quot;../stereo-data/2_orig.jpg&quot;); find_Trans_H(img2,img1,H1);/*img2 project to img1*/ find_Trans_H(img3,img1,H2);/*img3 project to img1*/ process_Stitch(img1,img2,img3,H1,H2);}效果，拼接痕迹是难免的，这里我们主要学习$H$矩阵的运用，若想进一步详细了解图像拼接可参考《计算机视觉：算法与运用》思考若给出了图像对应的深度图，那么便可知道图像各点的坐标值，那么便可通过重投影的方式进行图像拼接，不妨以此来验证$E$转移矩阵的估计效果。 下面的方法,是一种恢复尺度的方式，在单目slam中，我们将各个特征点深度设为1来初始化尺度，也要估计缩放尺度。若想了解更为复杂但可靠的算法，可参考《Least-Squares Estimation of Transmation Parameters Between Two Point Patterns》下面便为基于上面基于本质矩阵$E$单目估计相机运动方法，根据深度图来计算平移向量$t$的尺度。void find_use_E(const Mat &amp;amp;img1,const Mat&amp;amp; depth1,const Mat&amp;amp; img2,const Mat&amp;amp; depth2,const Mat&amp;amp; K,Mat&amp;amp; R,Mat&amp;amp; t){ vector&amp;lt;Point2f&amp;gt; left_pts; vector&amp;lt;Point2f&amp;gt; right_pts; find_match(img2,img1,left_pts,right_pts); // find the Essential Matrix using RANSAC Mat E = findEssentialMat(left_pts,right_pts,K,RANSAC); recoverPose(E,left_pts,right_pts,K,R,t);在这时，$t$为归一化值，并不对应实际尺度，但我们知道$t_0 = \\alpha t$，一个常见的思路便是通过最小二乘法来求解$\\alpha$值，即\\(\\min_\\alpha \\sum_i \\frac{1}{2}||RP_i^i+\\alpha t -P_2^i||^2\\)这显然是一个无约束凸优化问题，通过求导求得$\\alpha$闭式解\\(\\sum_i(RP_1^i+\\alpha t+P_2^i)^Tt = 0\\\\\\alpha^* = \\frac{1}{N\\cdot ||t||^2}\\sum_{i=1}^N(P_2^i-RP_1^i)^Tt\\) /*using alpha formula*/ double alpha = 0; vector&amp;lt;Point2f&amp;gt; crpt,clpt; /* to norm camera coordination*/ undistortPoints(left_pts,clpt,K,noArray()); undistortPoints(right_pts,crpt,K,noArray()); int N = 0; for(int i=0;i&amp;lt;right_pts.size();++i) { Mat x1 = Mat(1,3,CV_64F); x1.at&amp;lt;double&amp;gt;(0,0) = clpt[i].x; x1.at&amp;lt;double&amp;gt;(0,1) = clpt[i].y; x1.at&amp;lt;double&amp;gt;(0,2) = 1; Mat x2 = Mat(3,1,CV_64F); x2.at&amp;lt;double&amp;gt;(0,0) = crpt[i].x; x2.at&amp;lt;double&amp;gt;(1,0) = crpt[i].y; x2.at&amp;lt;double&amp;gt;(2,0) = 1; Mat error = x1*E*x2; /*这里通过对极约束式子的值来排除一些外点(outlier)*/ if(abs(error.at&amp;lt;double&amp;gt;(0,0))&amp;lt;MIN_ERROR) { Mat result = ((depth1.at&amp;lt;float&amp;gt;(right_pts[i].y,right_pts[i].x)*x2) - R*(depth2.at&amp;lt;float&amp;gt;(left_pts[i].y,left_pts[i].x)*x1).t()).t()*t; alpha += result.at&amp;lt;double&amp;gt;(0,0); ++N; } } alpha = alpha/N/t.dot(t); t = alpha*t;下面即为计算反投影误差 vector&amp;lt;Point2f&amp;gt; cp2; undistortPoints(left_pts,cp2,K,noArray()); vector&amp;lt;Point3f&amp;gt; cp2_; /*reproject to 3D*/ for(int i=0;i&amp;lt;left_pts.size();++i) { float d = depth2.at&amp;lt;float&amp;gt;(left_pts[i].y,left_pts[i].x); cp2[i]*=d; cp2_.emplace_back(cp2[i].x,cp2[i].y,d); } Mat rvec; Rodrigues(R,rvec); vector&amp;lt;Point2f&amp;gt; check; projectPoints(cp2_,rvec,t,K,noArray(),check); double error = 0; for(int i = 0;i&amp;lt;check.size();++i) { error += norm((check[i]-right_pts[i])); } error /= check.size(); printf(&quot;E error is %.3f\\n&quot;,error);}此外，我们根据特征点来做PNP，与用$E$求解的做对比void find_PnP(const Mat&amp;amp; img1,const Mat&amp;amp; depth1,const Mat&amp;amp; img2,const Mat&amp;amp; depth2,const Mat&amp;amp; K,Mat &amp;amp;rvec,Mat &amp;amp;tvec){ vector&amp;lt;Point2f&amp;gt; lpt,rpt; find_match(img1,img2,lpt,rpt); vector&amp;lt;Point2f&amp;gt; cp2; undistortPoints(rpt,cp2,K,noArray()); vector&amp;lt;Point3f&amp;gt; cp2_;对第二张图片视角，根据深度图计算其相机坐标系坐标(作为世界坐标)，然后对对应点做SolvePnPRansac,做Ransac的原因是匹配可能有外点（outlier）然后计算重投影误差 /*reproject to 3D*/ for(int i=0;i&amp;lt;rpt.size();++i) { float d = depth2.at&amp;lt;float&amp;gt;(int(rpt[i].y),int(rpt[i].x)); cp2[i]*=d; cp2_.emplace_back(cp2[i].x,cp2[i].y,d); } solvePnPRansac(cp2_,lpt,K,noArray(),rvec,tvec);/*from img2 to img1*/ vector&amp;lt;Point2f&amp;gt; check; projectPoints(cp2_,rvec,tvec,K,noArray(),check); double error = 0; for(int i = 0;i&amp;lt;check.size();++i) { error += norm((check[i]-lpt[i])); } error/=check.size(); printf(&quot;pnp error is %.3f\\n&quot;,error);}结果,PnP的效果较好，但对于$E$矩阵估计我们使用了较为基本的估计算法，也达到了不错的恢复尺度的效果pnp error is 10.423E error is 14.169下面便利用两种方法估计的位姿进行重投影void process_Stitch_project(const Mat &amp;amp;img1,const Mat&amp;amp; depth1,const Mat&amp;amp; img2,const Mat&amp;amp; depth2,const Mat&amp;amp; K,const Mat&amp;amp; R,const Mat&amp;amp; tvec,char* mask){ char title[50]; sprintf(title,&quot;project_%s&quot;,mask); namedWindow(title,WINDOW_NORMAL); resizeWindow(title,800,600); /* from img2 to img1*/ Mat rvec; Rodrigues(R,rvec); vector&amp;lt;Point2f&amp;gt; ip2; vector&amp;lt;Point2f&amp;gt; cp2_norm;/*x0,y0 on normal camera coordination*/ vector&amp;lt;Point3f&amp;gt; cp2;以下为计算第二张图片各点在第二个相机坐标系下的坐标值，经历了转换到归一化相机坐标系再乘上深度值的过程 for(int i = 0;i&amp;lt;img2.rows;++i) for(int j = 0;j&amp;lt;img2.cols;++j) ip2.emplace_back(j,i); undistortPoints(ip2,cp2_norm,K,noArray()); for(int i = 0;i&amp;lt;img2.rows;++i) for(int j = 0;j&amp;lt;img2.cols;++j) { float d = depth2.at&amp;lt;float&amp;gt;(i,j); cp2.emplace_back(cp2_norm[i*img2.cols+j].x*d,cp2_norm[i*img2.cols+j].y*d,d); }根据输入的从第二个相机坐标系到第一个相机坐标系的变换关系进行重投影 vector&amp;lt;Point2f&amp;gt; project_ps2; projectPoints(cp2,rvec,tvec,K,noArray(),project_ps2); Mat canvas = Mat::zeros(3*img1.rows,3*img1.cols,CV_8UC3);进行重投影RGB信息，将重投影点对应的原来图像位置的RGB值复制到新投影位置img1.convertTo(canvas(Rect(img1.cols,img1.rows,img1.cols,img1.rows)),CV_8UC3); for(int i = 0;i&amp;lt;img2.rows;++i) { for(int j = 0;j&amp;lt;img2.cols;++j) { canvas.at&amp;lt;Vec3b&amp;gt;(cvRound(project_ps2[i*img2.cols+j].y)+img1.rows,cvRound(project_ps2[i*img2.cols+j].x)+img1.cols) = img2.at&amp;lt;Vec3b&amp;gt;(i,j); } } imshow(title,canvas); waitKey(); sprintf(title,&quot;../project_%s.jpg&quot;,mask); imwrite(title,canvas);}下面是效果，由于重投影图片过暗，该效果是重投影像素RGB值均乘2的效果PnP估计效果E估计效果双目视觉双目视觉的基本模型和极线约束是相同的，只不过在双目视觉中，两个相机之间的位姿关系是已知的（标定出来）。我们先来看一下双目相机如何标定。更为详细的标定，可参考opencv_$version$/samples/cpp/stereo_calib.cpp先如同单目标定，读入图片，找角点#define N 21#define quad 69#define H 6#define W 9int main(int argc,char** argv){ namedWindow(&quot;check&quot;,WINDOW_NORMAL); resizeWindow(&quot;check&quot;,800,600); // read the single camera param FileStorage camera(&quot;../stereo.yaml&quot;,FileStorage::READ); Mat K_0 = camera[&quot;K_0&quot;].mat(); Mat C_0 = camera[&quot;C_0&quot;].mat(); Mat K_1 = camera[&quot;K_1&quot;].mat(); Mat C_1 = camera[&quot;C_1&quot;].mat(); //read the calibrate data char filename[50]; vector&amp;lt;Mat&amp;gt; left_im,right_im; vector&amp;lt;vector&amp;lt;Point2f&amp;gt;&amp;gt; corners_vec_left,corners_vec_right; sprintf(filename,&quot;../left/%d_l.jpg&quot;,1); Mat tmp = imread(filename); /* img Size*/ Size im_size(tmp.cols,tmp.rows); /*generate object points*/ vector&amp;lt;vector&amp;lt;Point3f&amp;gt;&amp;gt; object; for(int i = 1;i&amp;lt;=N;++i) { if(i==12)continue; /* 12 not exist*/ Mat img; vector&amp;lt;Point2f&amp;gt; corners; sprintf(filename,&quot;../left/%d_l.jpg&quot;,i); img = imread(filename); Mat gray; cvtColor(img,gray,COLOR_BGR2GRAY); left_im.push_back(img.clone()); findChessboardCorners(gray,Size(W,H),corners); find4QuadCornerSubpix(gray,corners,Size(5,5)); drawChessboardCorners(img,Size(W,H),corners,true); corners_vec_left.push_back(corners); imshow(&quot;check&quot;,img); waitKey(10); sprintf(filename,&quot;../right/%d_r.jpg&quot;,i); img = imread(filename); cvtColor(img,gray,COLOR_BGR2GRAY); right_im.push_back(img.clone()); findChessboardCorners(gray,Size(W,H),corners); find4QuadCornerSubpix(gray,corners,Size(5,5)); drawChessboardCorners(img,Size(W,H),corners,true); corners_vec_right.push_back(corners); imshow(&quot;check&quot;,img); waitKey(10); vector&amp;lt;Point3f&amp;gt; object_per_im; /* rows to cols*/ for(int j = 0;j&amp;lt;H;++j)for(int k = 0;k&amp;lt;W;++k)object_per_im.emplace_back(k*quad,j*quad,0); object.push_back(object_per_im); }然后进行双目标定,这里得到参数我们都很熟悉，$R,t,E,F$都在我们上面的讲解中出现，实际上你还可以用对极约束来验证这一过程。 Mat R,t,E,F; double rms = stereoCalibrate(object,corners_vec_left,corners_vec_right,K_0,C_0,K_1,C_1,im_size,R,t,E,F); cout&amp;lt;&amp;lt;&quot;rms is &quot;&amp;lt;&amp;lt;rms&amp;lt;&amp;lt;endl;然后我们要做双目立体矫正，这是一个比较复杂的过程，但下面的图片十分清晰地解释了该过程stereoRectify函数输出了$R_1,R_2,P_1,P_2,Q$来自官方文档的解析$R_1$Output 3x3 rectification transform (rotation matrix) for the first camera. This matrix brings points given in the unrectified first camera&#39;s coordinate system to points in the rectified first camera&#39;s coordinate system. In more technical terms, it performs a change of basis from the unrectified first camera&#39;s coordinate system to the rectified first camera&#39;s coordinate system. 实际上就是左相机未矫正坐标系旋转到矫正坐标系的旋转矩阵，如上图，$R2$同理$P_1$Output 3x4 projection matrix in the new (rectified) coordinate systems for the first camera, i.e. it projects points given in the rectified first camera coordinate system into the rectified first camera&#39;s image. 实际上就是一个$3\\times 4$矩阵，矫正（rectified）相机坐标系投影到矫正左像素平面的变换矩阵（外参+内参）,$P_2$是矫正（rectified）相机坐标系投影到矫正右像素平面的变换矩阵。$$P_1 = \\left[ \\begin{matrix}f&amp;amp; 0 &amp;amp; c_x &amp;amp; 0\\0 &amp;amp; f&amp;amp; c_y &amp;amp; 0\\0&amp;amp; 0&amp;amp; 1 &amp;amp; 0\\end{matrix}\\right]\\P_2 = \\left[ \\begin{matrix}f&amp;amp; 0 &amp;amp; c_x &amp;amp; T_x\\cdot f\\0 &amp;amp; f&amp;amp; c_y &amp;amp; 0\\0&amp;amp; 0&amp;amp; 1 &amp;amp; 0\\end{matrix}\\right] = \\left[ \\begin{matrix}f&amp;amp; 0 &amp;amp; c_x \\0 &amp;amp; f&amp;amp; c_y \\0&amp;amp; 0&amp;amp; 1\\end{matrix}\\right]\\left[ \\begin{matrix}1&amp;amp; 0 &amp;amp; 0 &amp;amp; T_x\\0 &amp;amp; 1&amp;amp; 0 &amp;amp; 0\\0&amp;amp; 0&amp;amp; 1 &amp;amp; 0\\end{matrix}\\right]$$以上为横向双目（Horizontal stereo）的模型，$T_x\\cdot f$是X轴向平移，从上面图可以看出，两个旋转矫正后的平面之间是有X轴向位移的。 $P$矩阵的前三列是旋转矫正后的新的相机内参。$Q$Output 4×4 disparity-to-depth mapping matrix (see reprojectImageTo3D). 顾名思义，从视差到深度映射矩阵，在reprojectImageTo3D这个函数我们暂时不会介绍，在进行稠密深度估计中，我们会得到视差图，通过该函数我们将视差图变换为深度图。 Mat R1,P1,R2,P2,Q; stereoRectify(K_0,C_0,K_1,C_1,im_size,R,t,R1,R2,P1,P2,Q); FileStorage fs; fs.open(&quot;../extrinsics.yml&quot;, FileStorage::WRITE); fs &amp;lt;&amp;lt; &quot;R&quot; &amp;lt;&amp;lt; R &amp;lt;&amp;lt; &quot;T&quot; &amp;lt;&amp;lt; t &amp;lt;&amp;lt; &quot;E&quot;&amp;lt;&amp;lt;E&amp;lt;&amp;lt;&quot;F&quot;&amp;lt;&amp;lt;F&amp;lt;&amp;lt;&quot;R1&quot; &amp;lt;&amp;lt; R1 &amp;lt;&amp;lt; &quot;R2&quot; &amp;lt;&amp;lt; R2 &amp;lt;&amp;lt; &quot;P1&quot; &amp;lt;&amp;lt; P1 &amp;lt;&amp;lt; &quot;P2&quot; &amp;lt;&amp;lt; P2 &amp;lt;&amp;lt; &quot;Q&quot; &amp;lt;&amp;lt; Q; fs.release(); Mat map1_l,map2_l;我们通过initUndistortRectifyMap计算两个相机坐标系之间的映射，并对每一张标定图片进行极线矫正，并查看效果 initUndistortRectifyMap(K_0,C_0,R1,P1,im_size,CV_16SC2,map1_l,map2_l); Mat map1_r,map2_r; initUndistortRectifyMap(K_1,C_1,R2,P2,im_size,CV_16SC2,map1_r,map2_r); for(int i = 0;i&amp;lt;left_im.size();++i) { Mat r1,r2; remap(left_im[i],r1,map1_l,map2_l,INTER_AREA); remap(right_im[i],r2,map1_r,map2_r,INTER_AREA); Mat canvas = Mat(left_im[0].rows,left_im[0].cols*2,CV_8UC3); r1.convertTo(canvas(Rect(0,0,im_size.width,im_size.height)),CV_8UC3); r2.convertTo(canvas(Rect(im_size.width,0,im_size.width,im_size.height)),CV_8UC3); for(int j = 0;j&amp;lt;32;++j)line(canvas,Point(0,j*canvas.rows/33+10), Point(canvas.cols-1,j*canvas.rows/33+10),Scalar(0,255,0),2); imshow(&quot;check&quot;,canvas); if(i == 0)imwrite(&quot;../ref.jpg&quot;,canvas); waitKey(); } return 0;}以上是极线矫正后的样子，可见大部分对应点都落在了同一条直线上。双目中另一个比较重要的概念是三角测量，其原理十分简单，对于极线矫正后的两个归一化相机平面，有\\(\\frac{z-f}{z} = \\frac{b-x_L+x_R}{b}\\\\\\frac{f}{z} = \\frac{x_L-x_R}{b}=\\frac{d}{b}\\\\z =\\frac{f\\cdot b}{d}\\)最后一个公式即为三角测量公式，请牢记于心。其中$d$称为视差，$b$称为基线。实际上在opencv中，上述公式一般用于估计稠密深度图中，视差图到深度图的转换。而在直接的三角测量函数，一般使用如下公式\\(z_1 x_1 = z_2Rx_2+t\\\\x_1\\times z_1 x_1 = 0=z_2x_1\\times Rx_2 + x_1\\times t\\\\z_2(x_1^{\\ \\hat{}} Rx_2) = -x_1^{\\ \\hat{}} t\\)考虑到噪声，我们应该求解该式的最小二乘解来得到$z_2$,求得$z_2$自然也容易得到$z_1$。上述公式都说明了在三角测量中需要用到齐次相机坐标。在opencv中的三角测量函数是triangulatePoints projMatr1 3x4 从世界坐标系到第一个相机的变换矩阵（通常我们使得第一个相机为世界坐标系，则该项为单位阵去除最后一行） projMatr2 3x4 从世界坐标系到第二个相机的变换矩阵(若使用上述方案，则该项为[R,t]，则双目相机标定中, $R,t$均为从左相机到右相机的变换) projPoints1 第一张图片中点在归一化相机平面上的坐标，建议用vector&amp;lt;Point2f&amp;gt;，该函数不接受double类型 projPoints2 第二张图片中点在归一化相机平面上的坐标，建议用vector&amp;lt;Point2f&amp;gt;，该函数不接受double类型 points4D 输出，一般用Mat接受，是一个4xN矩阵，每一列为一个输出的在世界坐标系下的点 需要除以第四位来归一化 这个函数的使用作为作业的一部分，这里给出一部分作业代码用作该函数使用样例 /*create translation Matrix*/ Mat T1 = Mat::eye(3,4,CV_64F); Mat T2 = Mat(3,4,CV_64F); R.convertTo(T2(Rect(0,0,3,3)),CV_64F); T.convertTo(T2(Rect(3,0,1,3)),CV_64F); /* 变换到归一化相机坐标系*/ vector&amp;lt;Point2f&amp;gt; undistort_lpts,undistort_rpts; undistortPoints(lpts,undistort_lpts,K_0,C_0); undistortPoints(rpts,undistort_rpts,K_1,C_1); Mat results; triangulatePoints(T1,T2,undistort_lpts,undistort_rpts,results); /* results is a 4*N matrix*/ for(int i = 0;i&amp;lt;results.cols;++i) { float D = results.at&amp;lt;float&amp;gt;(3,i); /* 通过归一化，得到第一个相机坐标系下各点坐标*/ Point3f p_3d(results.at&amp;lt;float&amp;gt;(0,i)/D,results.at&amp;lt;float&amp;gt;(1,i)/D,results.at&amp;lt;float&amp;gt;(2,i)/D); }作业给出一对由双目相机拍摄的视频，在视频开始时在左目相机中选择一个ROI框，然后估计该ROI中心点在每一帧的实时深度(左相机坐标系下z轴值）。Hint 这个作业里，你需要用到特征点匹配，但不一定要用到极线搜索的知识,我们建议直接对框中区域内部图像计算特征点，然后对另外一目图像全局寻找特征点，通过暴力匹配或者FLANN匹配的方式来匹配特征点。当你找到匹配的较好特征点后，进行三角测量测距，并对所有特征点的深度（即z坐标）进行平均，然后输出深度在视频里。 两个相机之间的位姿关系可以通过上述的双目标定得到，在给出的数据中，提供了标定好的外参，基于此，你甚至可以通过对极约束来排除误匹配的特征点来得到较好的匹配点 你也可以学习计算稠密深度图来直接得到稠密的深度信息，OpenCV提供这样的检测器，实际上它就用到了极线搜索的方法作业效果示例：Application 做完了这个项目，你应该对于双目立体视觉系统有了了解，在比赛中，双目系统可以用在雷达系统，以及哨兵反导等项目中。 这里简单介绍一下极线搜索 仍然是这张图片，在大部分情况下，我们很难知道$P_r$的位置，但是通过极线矫正，我们知道它一定在$P_l$所在的极线上，那么我们只要搜索这条极线便可。三角测量的局限我们在使用双目系统进行测距时，应该注意到 较大的基线长度，会使得在同样的匹配误差下，相对的深度误差较小 同样的基线长度，目标距离越远，在同样的匹配误差下，相对的深度误差就会越大由于我们并不能使用很长基线的双目系统（特别是在车上），故而双目系统一般用在较近距离（如10m内）的测距，较远距离将会带来难以接受的误差。光流光流根据了灰度不变假设，即对于连续两帧图片，若定义$I(x,y,t)$为$t$时刻下$(x,y)$位置的像素的灰度（gray-level），则有假设\\(I(x,y,t) = I(x+\\delta x,y+\\delta y,t+\\delta t)\\)对右边项进行泰勒展开一阶项\\(I(x,y,t) \\approx I(x,y,t) + \\frac{\\part I}{\\part x}\\delta x+ \\frac{\\part I}{\\part y}\\delta y+\\frac{\\part I}{\\part t}\\delta t\\\\\\frac{\\part I}{\\part x}\\frac{\\delta x}{\\delta t}+\\frac{\\part I}{\\part y}\\frac{\\delta y}{\\delta t} = -\\frac{\\part I}{\\part t}\\\\\\left[\\begin{matrix}\\frac{\\part I}{\\part x}&amp;amp;\\frac{\\part I}{\\part y}\\end{matrix}\\right]\\left[\\begin{matrix}\\frac{\\delta x}{\\delta t}\\\\\\frac{\\delta y}{\\delta t}\\end{matrix}\\right] = -\\frac{\\part I}{\\part t}\\)若我们取相邻帧，$\\delta t = 1$，则有\\(\\left[\\begin{matrix}\\frac{\\part I}{\\part x}&amp;amp;\\frac{\\part I}{\\part y}\\end{matrix}\\right]\\left[\\begin{matrix}\\delta x\\\\\\delta y\\end{matrix}\\right] = -\\frac{\\part I}{\\part t}\\)类似上面的做法，我们假设一个$w \\times w$的方格内像素具有相同的运动，则可得一个线性方程组，解线性方程便可得得到像素运动。下面便是实践时间，我们来看一个视频上各个特征点根据光流法追踪的效果。int main(int argc,char** argv){ if(argc &amp;lt; 3){cerr&amp;lt;&amp;lt;&quot;input infile and outfile!&quot;&amp;lt;&amp;lt;endl;return -1;} namedWindow(&quot;show&quot;,WINDOW_NORMAL); resizeWindow(&quot;show&quot;,800,600); VideoCapture cap(argv[1]); if(!cap.isOpened()) {cerr &amp;lt;&amp;lt; &quot;no such file!&quot;&amp;lt;&amp;lt;endl; cap.release(); return -1;} Ptr&amp;lt;ORB&amp;gt; orb = ORB::create(1700); bool flag; Mat frame; flag = cap.read(frame); VideoWriter writer(argv[2],VideoWriter::fourcc(&#39;m&#39;,&#39;p&#39;,&#39;4&#39;,&#39;v&#39;),10.,Size(frame.cols,frame.rows));用orb计算特征点，这里只需要计算特征点，而不需要计算描述子 Mat gray; cvtColor(frame,gray,COLOR_BGR2GRAY); // create the container of Key points vector&amp;lt;KeyPoint&amp;gt; feature_points; // do Orient_FAST detect Keypoint orb-&amp;gt;detect(gray,feature_points); vector&amp;lt;Point2f&amp;gt; prev_pts,now_pts; for(const KeyPoint&amp;amp; p : feature_points) { prev_pts.push_back(p.pt); }calcOPticalFLowPyrLK利用LK光流算法计算光流，其中参数，prev是上一帧图像，frame是这一帧图像，都是彩色图像输入，prev_pts是上帧预计算的点，now_pts是这一帧输出的点，status存储了now_pts中该点是否为正确估计，error存储了正确的点估计的误差 Mat prev; vector&amp;lt;float&amp;gt; error; /* error of each found corresponding points*/ vector&amp;lt;unsigned char&amp;gt; status; /* to show whether the corresponding point in the next frame is found or not.*/ while(true) { prev = frame.clone(); flag = cap.read(frame); if(!flag)break; calcOpticalFlowPyrLK(prev,frame,prev_pts,now_pts,status,error); Mat canvas = frame.clone(); int i=0; int iter = 0; for(auto p:prev_pts) { /* prev pt*/ circle(canvas,Point2i(cvRound(p.x),cvRound(p.y)),2,Scalar(0,255,0),-1); if(status[i++]==0) { now_pts.erase(now_pts.begin()+iter); continue; } int x = cvRound(now_pts[iter].x); int y = cvRound(now_pts[iter].y); circle(canvas,Point2i(x,y), 2,Scalar(0,0,255),-1); line(canvas,Point2i(cvRound(p.x),cvRound(p.y)), Point2i(cvRound(now_pts[iter].x),cvRound(now_pts[iter].y)), Scalar(0,255,0)); ++iter; } if(now_pts.size()==0) break; char count[50]; sprintf(count,&quot;reserve from %d to %d&quot;,int(prev_pts.size()),int(now_pts.size())); putText(canvas,count,Point(100,100),FONT_HERSHEY_COMPLEX,1,Scalar(0,255,0)); prev_pts.clear(); prev_pts = now_pts; imshow(&quot;show&quot;,canvas); writer.write(canvas); waitKey(80); } writer.release(); cap.release();}进阶读物 真实场景下双目立体视觉匹配 该博客对基于opencv传统双目视觉做了进一步的讲解和实践，并涉及到利用opencv工具建立稠密深度图，并进行深度补全，若对该方面感兴趣，可在本讲基础上对该博客代码进行实践。 《视觉slam十四讲：从理论到实践》第9讲：实践，设计前端 基于该讲与前面所学，你已经对于一个相机的模型有了充分的认识，并且如何建模与估计相机的运动也有了了解，很显然，你已经具备了制作一个视觉里程计的基本知识，这将是一个复杂系统，使得你用到前面所学的各种知识如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！Acknowledgement 本教程大部分参考自《视觉slam十四讲》 图片大部分来自CSDN，博客园等 少数摘自OpenCV文档，OpenCV文档yyds作者：郑煜，github主页：传送门" }, { "title": "Unreal Engine 4 课程目录", "url": "/posts/Unreal-Engine-Tutorial-Catalogue/", "categories": "Course, Unreal Engine", "tags": "catalog", "date": "2021-10-21 23:59:00 +0800", "snippet": "Unreal Engine Catalogue一、课程简介本课程以动手实践为主，在实践中理解相关原理，以能够实战进行项目为首要目标，不要求知识的系统性学习。Unreal介绍。。。二、课程教程 如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "RM 教程 5 —— 单目视觉", "url": "/posts/RM-Tutorial-5-Monocular-Vision/", "categories": "Course, RM", "tags": "getting started, robomaster, computer vision", "date": "2021-10-15 21:30:00 +0800", "snippet": "RM 教程 5 —— 单目视觉 机械是肉体， 电控是大脑， 视觉是灵魂一、仿射变换与透视变换0. 再谈其次坐标系在上一讲中，我们提到了齐次坐标系。对于二维平面上的点 $(x, y)$ ， 我们常常将它写成为 $(x, y, 1)^T$ ，这是一个典型的齐次坐标。同样的，在三维空间中，我们有坐标 $(x, y, z, 1)^T$ ，这也是一个齐次坐标形式。显然，对于齐次坐标和非齐次坐标，我们可以简单地通过删除最后一个坐标 $1$ 来实现他们之间的转换。但这样看来，齐次坐标的表述仍然非常奇怪，因为它多了一个莫名其妙的限制，就是最后一个坐标数值一定为 $1$ 。那么一个坐标三元组 $(x, y, 2)^T$ 是否也有自己的意义呢?对此，我们规定对于任何非零值 $k$ ， $(kx, ky, k)^T$ 表示二维坐标中的同一个点，也就是说，当两个三元组相差一个公共倍数时，他们是等价的，也被成为坐标三元组中的等价类。现在问题有出现了，在上面的定义中，我们规定 $k \\ne 0$ ，那么当 $k = 0$ 时， 坐标三元组 $(x, y, 0)^T$ 是否有它的意义?由于 $(x/0, y/0)^T$ 得到的应该是一个在无穷远方的点，因此我们称它为无穷远点。在二维空间中， 无穷远点形成无穷远直线。在三维中，他们形成无穷远平面。1. 线性变换在谈仿射变换之前，我们先要复习一下线性变换。线性变换从几何直观有三个要点： 变换前是直线的，变换后依然是直线 直线比例保持不变 变换前是原点的，变换后依然是原点线性变换是通过矩阵乘法来实现的。1. 仿射变换仿射变换是一种特殊的坐标变换，在仿射变换下，形状的两个平行性和体积比保持不变。如果从无穷远直线的角度理解仿射变换，那么：假设在空间 $s$ 下直线 $l$ 为无穷远直线，当经过仿射变换 $A$ 后得到直线 $l’$ ， $l’$ 仍然为仿射变换后的空间 $s’$ 中的无穷远直线。仿射变换的公式为：\\(\\begin{bmatrix}x&#39;\\\\y&#39;\\\\1\\\\\\end{bmatrix}=\\begin{bmatrix}\\mathbf A &amp;amp; \\mathbf t\\\\\\mathbf 0^T &amp;amp; 1\\\\\\end{bmatrix}\\begin{bmatrix}x\\\\y\\\\1\\\\\\end{bmatrix}\\)如果上述的表达方式太过数学化，我们可以用直观的方式帮助你理解仿射变换：对于仿射变换的感性理解就是，将输入图像想象为一个大的矩形橡胶片，然后通过在角上的推或拉变形来制作不同样子的平行四边形。简单来说，“仿射变换”就是：“线性变换”+“平移”。仿射变换的不变性： 线共点、点共线的关系不变 平行关系 中点 在一条直线上的几段线段的比例关系仿射变换会改变： 线段长度 夹角角度对于二维空间中的仿射变换，他有透视变换 $6$ 个自由度（参数）， 对于三维空间中的仿射变换，他有 $12$ 个自由度。补充知识仿射变换可以通过一系列的原子变换的复合来实现，包括：平移（Translation）、缩放（Scale）、翻转（Flip）、旋转（Rotation）和剪切（Shear）。理解这些特殊的变换对你理解仿射变换有一些帮助。我们介绍一下几种常见的特殊的仿射变换：平移变换 Translation平移变换是一种“刚体变换”，不会产生形变的理想物体。变换矩阵为：\\(\\begin{bmatrix}1 &amp;amp; 0 &amp;amp; t_x\\\\0 &amp;amp; 1 &amp;amp; t_y\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\)缩放变换 Scale将每一点的横坐标放大（缩小）至 $s_x$ 倍，纵坐标放大（缩小）至 $s_y$ 倍。变换矩阵为：\\(\\begin{bmatrix}s_x &amp;amp; 0 &amp;amp; 0\\\\0 &amp;amp; s_y &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\)剪切变换 Shear相当于一个横向剪切与一个纵向剪切的复合。变换矩阵为： \\(\\begin{bmatrix}1 &amp;amp; sh_x &amp;amp; 0\\\\sh_y &amp;amp; 1 &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}=\\begin{bmatrix}1 &amp;amp; 0 &amp;amp; 0\\\\sh_y &amp;amp; 1 &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\begin{bmatrix}1 &amp;amp; sh_x &amp;amp; 0\\\\0 &amp;amp; 1 &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\)旋转变换 Rotation目标图形围绕原点顺时针旋转 $\\theta$ 弧度。变换矩阵为： \\(\\begin{bmatrix}\\cos(\\theta) &amp;amp; -\\sin(\\theta) &amp;amp; 0\\\\\\sin(\\theta) &amp;amp; \\cos(\\theta) &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\)组合旋转变换，目标图形以 $(x, y)$ 为轴心顺时针旋转 $\\theta$ 弧度，相当于两次平移变换与一次原点旋转变换的复合：先移动到中心节点，然后旋转，然后再移动回去。变换矩阵为： \\(\\begin{bmatrix}\\cos(\\theta) &amp;amp; -\\sin(\\theta) &amp;amp; y-x\\cos(\\theta)+y\\sin(\\theta)\\\\\\sin(\\theta) &amp;amp; \\cos(\\theta) &amp;amp; y-x\\sin(\\theta)-y\\cos(\\theta)\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}=\\begin{bmatrix}1 &amp;amp; 0 &amp;amp; -x\\\\0 &amp;amp; 1 &amp;amp; -y\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\begin{bmatrix}\\cos(\\theta) &amp;amp; -\\sin(\\theta) &amp;amp; 0\\\\\\sin(\\theta) &amp;amp; \\cos(\\theta) &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\begin{bmatrix}1 &amp;amp; 0 &amp;amp; x\\\\0 &amp;amp; 1 &amp;amp; y\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\)这个转换矩阵也可以下面这样描述。一些常用转换矩阵如下：2. 透视变换仿射变换可以理解为透视变换的特殊形式。透视变换也叫投影变换。我们在仿射变换中提到，通过仿射变换，原图像中的无穷远线不变。与之相反，通过透视变换，原来的无穷远线不再是无穷远线。也就是说，对于一点 $(x, y, 0)^T$ ，它经过透视变换之后的坐标最后一元不再为零。透视变换不再保证平行性。在二维空间中，空间变换的一般形式公式如下：\\(\\begin{bmatrix}x&#39;\\\\y&#39;\\\\k&#39;\\\\\\end{bmatrix}=\\begin{bmatrix}a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\\\a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\\\a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\\\\\end{bmatrix}\\begin{bmatrix}x\\\\y\\\\k\\\\\\end{bmatrix}\\)如果想通过这样的一个变换使得变换结果中的 $k’ \\ne 0$ ，那么就必须满足 $a_{31}x + a_{32}y \\ne 0$ 。于是，我们自然而然地得到了透视变换的一般形式：\\(\\begin{bmatrix}x&#39;\\\\y&#39;\\\\k&#39;\\\\\\end{bmatrix}=\\begin{bmatrix}\\mathbf A &amp;amp; \\mathbf t\\\\\\mathbf a^T &amp;amp; v\\\\\\end{bmatrix}\\begin{bmatrix}x\\\\y\\\\k\\\\\\end{bmatrix}\\)如果想要感性地理解透视变换，那么你可以想想从不同角度看同一个物体的效果。例如下图就是一个透视变换的示意图：通过透视变换，我们可以转换原图的视角。例如下图中，我们就将车道从平视图转换为俯视图：下图中我们将车牌从侧视图转换为正视图：对于二维空间中的透视变换，它有 $8$ 个自由度，对于三维空间中的透视变换，它有 $15$ 个自由度。3. OpenCV中的仿射变换和透视变换在应用层面，仿射变换是图像基于 $3$ 个固定顶点的变换，如图所示：图中红点即为固定顶点，在变换先后固定顶点的像素值不变，图像整体则根据变换规则进行变换。同理，透视变换是图像基于 $4$ 个固定顶点的变换，如图所示：在OpenCV中，仿射变换和透视变换均有封装好的函数。仿射变换的函数是：void cv::warpAffine(InputArray src, OutputArray dst, InputArray M, Size dsize, int flags=INTER_LINEAR, int borderMode=BORDER_CONSTANT, const Scalar&amp;amp; borderValue=Scalar())参数： InputArray src：输入变换前图像 OutputArray dst：输出变换后图像，需要初始化一个空矩阵用来保存结果，不用设定矩阵尺寸 InputArray M：变换矩阵，用另一个函数 getAffineTransform() 计算 Size dsize：设置输出图像大小 int flags=INTER_LINEAR：设置插值方式，默认方式为线性插值生成仿射变换矩阵函数是 getAffineTransform()：cv::Mat cv::getAffineTransform(const Point2f* src, const Point2f* dst)参数： const Point2f* src：原图的 3 个固定顶点 const Point2f* dst：目标图像的 3 个固定顶点 注意，顶点数组长度超过 3 个，则会自动以前 3 个为变换顶点；数组可用 Point2f[] 或 Point2f* 表示 透视变换的函数是：void warpPerspective(InputArray src, OutputArray dst, InputArray M, Size dsize, int flags=INTER_LINEAR, int borderMode=BORDER_CONSTANT, const Scalar&amp;amp; borderValue=Scalar())参数与 warpAffine() 一致。生成透视变换矩阵函数是 getPerspectiveTransform()：cv::Mat cv::getPerspectiveTransform(InputArray src, InputArray dst, int solveMethod = DECOMP_LU)参数： 透视变换顶点为 4 个桌上有一张扑克牌，我们希望可以从正视的角度观察它。运行以下示例代码观察程序效果：二、Eigen1. 简介Eigen 是C++语言里的一个开源模版库，支持线性代数运算、矩阵和矢量运算、数值分析及其相关的算法。可以将它类比为 python 中的 numpy 。注意如果想要发挥出 Eigen 的作用，编译时一定要打开 gcc/g++ 编译优化 -O3 。Eigen 能算得快和它的设计思路有关，涵盖了算法加速的几个方法。第一，Eigen 使用 Lazy Evaluation 的方法。这个方法的好处是： 把所有能优化的步骤放在编译时去优化。让计算本身尽可能放在最后做，减少内存访问。例如下面一段代码： Eigen::MatrixXd Jacobian_i = Eigen::MatrixXd::Random(10, 10);Eigen::MatrixXd Jacobian_j = Eigen::MatrixXd::Random(10, 10);Eigen::MatrixXd Hessian = Eigen::MatrixXd::Zero(10, 10);Hessian += Jacobian_i.transpose() * Jacobian_j; 实际运行时，在 operator+=() 才真正去做内存读取和计算，而前面的步骤知识更新 flag 。具体见 Eigen/src/Core/EigenBase.h 。 不生成中间变量，减少内存搬运次数，而 Eigen 为了防止矩阵覆盖自己，对矩阵-矩阵乘法会生成一个中间变量。如果我们知道等式左右两边没有相同的项，则可以通知Eigen去取消中间变量。 第二，改变内存的分配方式。使用Eigen时应该尽可能用静态内存代替动态内存。 Eigen::MatrixXd 是如下的缩写：typedef MatrixXd Matrix&amp;lt;double, Dynamic, Dynamic, ColMajor&amp;gt;MatrixBase 第二和第三个选项是行列的长度，有一项是 Dynamic 就会用动态内存分配。所以已知矩阵大小时应尽可能声明大小，比如 Matrix&amp;lt;double, 10, 10&amp;gt; 。如果内存在整个程序中大小会变，但知道最大可能的大小，都可以告知 Eigen ， Eigen 同样会选择用静态内存。Eigen::Matrix&amp;lt;double, Eigen::Dynamic, Eigen::Dynamic, Eigen::ColMajor, 10, 10&amp;gt; Jacobian_i;Eigen::Matrix&amp;lt;double, Eigen::Dynamic, Eigen::Dynamic, Eigen::ColMajor, 10, 10&amp;gt; Jacobian_j;Eigen::Matrix&amp;lt;double, Eigen::Dynamic, Eigen::Dynamic, Eigen::ColMajor, 10, 10&amp;gt; Hessian = Eigen::Matrix&amp;lt;double, 10, 10&amp;gt;::Zero();Hessian += Jacobian_i.transpose() * Jacobian_j;静态内存分配不但让我们节省了 new/delete 的开销，还给 Eigen 内部继续优化提供了可能。 Eigen 内置 Single-Instruction-Multiple-Data （SIMD）指令集，对稠密矩阵有很好的优化，如果能触发 CPU SIMD 的指令，能收获成倍的计算效率。第三，矩阵自身的性质。如果矩阵本身有自身的性质，都可以通知 Eigen ，让 Eigen 用对应的加速方式。比如正定矩阵可以只用上三角进行计算，并且在求解时使用 Eigen::LLT 这样又快又数值稳定的解法等。2. 安装 Eigen终端 apt 命令安装：sudo apt-get install libeigen3-devEigen 只包含头文件，因此它不需要实现编译（只需要使用 #include ），指定好 Eigen 的头文件路径，编译项目即可。Eigen 头文件的默认安装位置是 /usr/include/eigen3 。3. Eigen 库的模块及其头文件为了应对不同的需求， Eigen 库被分为多个功能模块，每个模块都有自己相对应的头文件，以供调用。 其中， Dense 模块整合了绝大部分的模块，而 Eigen 模块更是整合了所有模块。4. 使用方法（1）构造Eigen::Matrix&amp;lt;double, 3, 3&amp;gt; A; // Fixed rows and cols. Same as Matrix3d.Eigen::Matrix&amp;lt;double, 3, Eigen::Dynamic&amp;gt; B; // Fixed rows, dynamic cols.Eigen::Matrix&amp;lt;double, Eigen::Dynamic, Eigen::Dynamic&amp;gt; C; // Full dynamic. Same as MatrixXd.Eigen::Matrix&amp;lt;double, 3, 3, Eigen::RowMajor&amp;gt; E; // Row major; default is column-major.有一些宏定义可以简短代码：typedef Eigen::Matrix&amp;lt;int, 3, 3&amp;gt; Eigen::Matrix2itypedef Eigen::Matrix&amp;lt;int, Eigen::Dynamic, 3&amp;gt; Eigen::MatrixX3itypedef Eigen::Matrix&amp;lt;int, 3, Eigen::Dynamic&amp;gt; Eigen::Matrix3Xi（2）特殊矩阵生成 实例 代码 零矩阵 Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Zero() 一矩阵 Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Ones() 单位矩阵 Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Identity() 常量矩阵 Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Constant(a) 随机矩阵 Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Random() 线性空间向量 Eigen::Vector3i::LinSpaced(a, b) （3）随机访问Eigen 有重载 () 运算符提供随机访问的功能。下面是一段例程：Eigen::MatrixXd m(2,2);m(0,0) = 3;m(1,0) = 2.5;m(0,1) = -1;m(1,1) = m(1, 0) + m(0, 1);std::cout &amp;lt;&amp;lt; &quot;Here is the matrix m:\\n&quot; &amp;lt;&amp;lt; m &amp;lt;&amp;lt; std::endl;Eigen::VectorXd v(2);v(0) = 4;v(1) = v(0) - 1;std::cout &amp;lt;&amp;lt; &quot;Here is the vector v:\\n&quot; &amp;lt;&amp;lt; v &amp;lt;&amp;lt; std::endl;（4）赋值利用重载 &amp;lt;&amp;lt; 运算符或 = 运算符完成赋值。下面是一段例程：Eigen::Matrix3f m;m &amp;lt;&amp;lt; 1, 2, 3, 4, 5, 6, 7, 8, 9;std::cout &amp;lt;&amp;lt; m &amp;lt;&amp;lt; std::endl;（5）改变矩阵大小只能作用于大小没有通过模版确定的矩阵，即设置为 Eigen::Dynamic 的维度。 resize(rows, cols) ：可能改变矩阵数据的存储顺序。 conservativeResize(rows, cols)：不会改变矩阵数据的内存分布，因此如果新生成的大小不能覆盖原来的数据，会造成数据丢失。可以减少赋值操作。下面是一段例程：Eigen::Matrix&amp;lt;int, Eigen::Dynamic, Eigen::Dynamic&amp;gt; m = Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Identity();m.resize(1, 9);（6）特殊 函数 作用 返回 transpose 转置 Matrix eval 返回矩阵的数值 Matrix transposeInPlace 自身进行转置 void inverse 取逆 Matrix 需要注意的是，由于 Eigen 使用 Lazy Evaluation，因此 mat = mat.transpose() 是不合法的。（7）单矩阵运算 函数 作用 mat.sum() 返回元素的和 mat.prod() 返回元素的乘积和 mat.maxCoeff() 返回最大元素 mat.minCoeff() 返回最小元素 mat.trace() 返回矩阵的迹 （8）子阵运算block 运算的功能是截取矩阵中的部分元素。 mat.block(i,j,p,q)：动态大小的 block 运算 mat.block&amp;lt;p,q&amp;gt;(i,j)：确定大小的 block 运算Eigen::Matrix&amp;lt;int, 3, 3, 0&amp;gt; matrix_1;matrix_1.block&amp;lt;2, 2&amp;gt;(0, 0) &amp;lt;&amp;lt; Eigen::Matrix2i::Ones();matrix_1.block&amp;lt;2, 1&amp;gt;(0, 2) &amp;lt;&amp;lt; Eigen::Vector2i::Random();matrix_1.block&amp;lt;1, 3&amp;gt;(2, 0) &amp;lt;&amp;lt; 2, 3, 4;std::cout &amp;lt;&amp;lt; matrix_1 &amp;lt;&amp;lt; std::endl; 函数 作用 mat.topLeftCorner(rows, cols) 取左上角的 block mat.topRightCorner(rows, cols) 取右上角的 block mat.bottomLeftCorner(rows, cols) 取左下角的 block mat.bottemRightCorner(rows, cols) 取右下角的 block mat.topRows(rows) 取上方 k 行 mat.bottomRows(rows) 取下方 k 行 mat.leftCols(cols) 取左侧 k 行 mat.rightCols(cols) 取右方 k 行 mat.cols(j) 取第 j 行 mat.rows(i) 取第 i 行 （9）广播将一个矩阵的一个大小为 $1$ 或缺失的维度重复补全后和另一个矩阵进行计算。例如，一个矩阵 A 维度为 $(3,3)$ ，另一个矩阵B维度为 $(3,1)$ 。那么运算 $A+B$ 中就发生了广播，矩阵 A 的维度被补全为 $(3,3)$ 后和 B 进行运算。下面是一段例程：Eigen::MatrixXf mat(2,4);Eigen::VectorXf v(2);mat &amp;lt;&amp;lt; 1, 2, 6, 9, 3, 1, 7, 2;v &amp;lt;&amp;lt; 0, 1;mat.colwise() += v;std::cout &amp;lt;&amp;lt; mat &amp;lt;&amp;lt; std::endl;三、PnPPnP 常用于单目测距和姿态解算。如果场景的三维结构已知，利用多个控制点在三维场景中的坐标及其在图像中的透视投影坐标即可求解出摄像机坐标系与表示三维场景结构的世界坐标系之间的绝对位姿关系，包括绝对平移向量 $t$ 以及旋转矩阵 $R$ ，该类求解方法统称为 N 点透视位姿求解（ Perspective-N-Point ， PNP 问题）。这里的控制点是指准确知道三维空间坐标位置，同时也知道对应图像平面坐标的点。对于透视投影来说，要使得 PNP 问题有确定解，需要至少三组控制点。在解决任何 PnP 问题之前，我们都需要准确地标定出相机的内参矩阵和畸变矩阵，标定的质量会影响最后外参矩阵（旋转矩阵+平移矩阵）的精度。这一部分在之前的教程中已经教过了。1. P3P 问题P3P 需要利用给定的 3 个点的几何关系。输入数据为 3 对 3D-2D 匹配点。记 3D 点为 A 、 B 、 C ， 2D 点为 a 、 b 、 c 。其中，小写字母代表点的为对应大写字母代表的点在相机成像平面上的投影。此外， P3P 还需要使用一对验证点，从可能的解中选出正确的那一个（验证点记为 D-d ），相机的光心为 O 。请注意，我们知道的是 ABC 三个点在世界坐标系中的坐标，而不是在相机坐标系中的坐标。由图可得，显然有如下相似三角形的关系：\\(\\begin{cases}\\triangle Oab \\sim \\triangle OAB \\\\\\triangle Obc \\sim \\triangle OBC \\\\\\triangle Oac \\sim \\triangle OAC \\\\\\end{cases}\\)采用余弦定理，有\\(\\begin{cases}OA^2 + OB^2 - 2 \\cdot OA \\cdot OB \\cos&amp;lt;a, b&amp;gt; = AB^2 \\\\OB^2 + OC^2 - 2 \\cdot OB \\cdot OC \\cos&amp;lt;b, c&amp;gt; = BC^2 \\\\OA^2 + OC^2 - 2 \\cdot OA \\cdot OC \\cos&amp;lt;a, c&amp;gt; = AC^2 \\\\\\end{cases}\\)左右两边同时除以 $OC^2$ ，令 $x = \\cfrac{OA}{OC}, y = \\cfrac{OB}{OC}$ ，有\\(\\begin{cases}x^2 + y^2 - 2xy \\cos&amp;lt;a, b&amp;gt; = \\cfrac{AB^2}{OC^2} \\\\y^2 + 1^2 + 2y \\cos&amp;lt;b, c&amp;gt; = \\cfrac{BC^2}{OC^2} \\\\x^2 + 1^2 + 2x \\cos&amp;lt;a, c&amp;gt; = \\cfrac{AC^2}{OC^2} \\\\\\end{cases}\\)再令 $u = \\cfrac{AB^2}{OC^2}, v = \\cfrac{BC^2}{AB^2}, w = \\cfrac{AC^2}{AB^2}$ ，有\\(\\begin{cases}x^2 + y^2 - 2xy \\cos&amp;lt;a, b&amp;gt; -v = 0 \\\\y^2 + 1^2 + 2y \\cos&amp;lt;b, c&amp;gt; - uv = 0 \\\\x^2 + 1^2 + 2x \\cos&amp;lt;a, c&amp;gt; - wv = 0 \\\\\\end{cases}\\)将第一个等式带入后面两个，得：\\(\\begin{cases}(1-u)y^2 - ux^2 - y \\cos&amp;lt;b, c&amp;gt; + 2uxy \\cos&amp;lt;a, b&amp;gt; + 1 = 0 \\\\(1-w)x^2 - wy^2 - x \\cos&amp;lt;a, c&amp;gt; + 2wxy \\cos&amp;lt;a, b&amp;gt; + 1 = 0 \\\\\\end{cases}\\)2D 点的图像坐标已知， 3 个余弦角已知。 3D 点的坐标已知，只有 xy 未知。可以采用吴消元法来解上述方程。该方法最多可以获得 4 个解，但可以通过第四个点，来获得最可能的解。进一步地， EPnP （需要 4 对不共面的点）、 UPnP 等则是利用更多的信息来迭代，对相机的位姿进行优化，以尽可能消除噪声的影响。至于进一步的运算这里就不推倒了，难度有点大，感兴趣的可以看这篇博客。2. PnP 问题PnP 和 P3P 问题类似，但是它有足够的信息确定一组解。 PnP 算法通过至少四个点的约束，求出世界坐标系到相机坐标系的旋转矩阵和平移向量。\\(\\begin{bmatrix}u\\\\v\\\\1\\\\\\end{bmatrix}=\\mathbf K\\begin{bmatrix}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\\\\\end{bmatrix}\\begin{bmatrix}\\mathbf R &amp;amp; \\mathbf T \\\\\\mathbf 0^T &amp;amp; 1 \\\\\\end{bmatrix}\\begin{bmatrix}X_w\\\\Y_w\\\\Z_w\\\\1\\\\\\end{bmatrix}\\)3. OpenCV 中的 solvePnp()声明如下：void solvePnP(InputArray objectPoints, InputArray imagePoints, InputArray cameraMatrix, InputArray distCoeffs, OutputArray rvec, OutputArray tvec, bool useExtrinsicGuess=false, int flags=CV_ITERATIVE)参数： objectPoints ：视觉坐标系中的点 imagePoints ：像素坐标系中的点 cameraMatrix ：相机内参 disCoeffs ：相机畸变矩阵 rvec ：求出来的旋转向量 tvec ：求出来的平移向量 useExtrinsicGuess：是否输出平移矩阵和旋转矩阵，默认为 false flags ：选择算法 SOLVEPNP _ITERATIVE SOLVEPNP _P3P SOLVEPNP _EPNP SOLVEPNP _DLS SOLVEPNP _UPNP 如何用这函数来实现测距呢？我们只需要把世界坐标系的原点设置在我们感兴趣的点就可以了，那么函数返回的平移向量的的模长就是相机和那个点的距离。例如TODO4. 旋转角度、旋转向量与旋转矩阵我们再补充一下旋转矩阵和旋转响向量之间的转换关系。三维空间中的旋转矩阵有 $9$ 个量，而三维空间中的旋转只有 $3$ 个自由度，因此我们很自然地想到， 是否可以用更少的量描述一个三维运动。事实上，对于坐标系的旋转，任意旋转都可以用一个旋转轴和一个旋转角来刻画。于是，我们可以使用一个方向与旋转轴垂直、长度等于旋转角的向量描述旋转运动，这个向量成为旋转向量。通过这样的方式，我们就可以只通过一个三维的旋转向量和一个三维的平移向量描述三维空间中刚体的运动。旋转矩阵和旋转向量是可以互相转化的，有旋转向量推导旋转矩阵的公式也被成为罗德里格斯公式：\\(\\theta \\leftarrow \\norm{\\vec{r}}\\\\\\vec{r} \\leftarrow \\vec{r}/\\theta\\\\R(\\vec{n}, \\theta) = \\cos(\\theta) \\mathbf I + (1-\\cos \\theta)\\vec{r}\\vec{r}^T + \\sin(\\theta) \\begin{bmatrix}0 &amp;amp; -r_z &amp;amp; r_y \\\\r_z &amp;amp; 0 &amp;amp; -r_x \\\\-r_y &amp;amp; r_x &amp;amp; 0 \\\\\\end{bmatrix}\\)其中，旋转向量的长度（模）表示绕轴逆时针旋转的角度（弧度）， $\\theta$ 表示旋转角度， $\\mathbf{I}$ 表示单位矩阵，最后一个矩阵表示 $\\vec r$ 的反对称矩阵。旋转角 $\\theta$ 也可以由公式\\(\\theta = \\arccos(\\cfrac{tr(R)-1}{2})\\)计算得到。OpenCV 中的旋转向量和旋转矩阵转换的函数是int cvRodrigues2( const CvMat* src, CvMat* dst, CvMat* jacobian=0 );参数： src：为输入的旋转向量（ $3\\times1$ 或者 $1\\times3$ ）或者旋转矩阵（ $3\\times3$ ）。该参数向量表示其旋转的角度，用向量长度表示。 dst：为输出的旋转矩阵（ $3\\times3$ ）或者旋转向量（ $3\\times1$ 或者 $1\\times3$ ）。 jacobian：为可选的输出雅可比矩阵（ $3\\times9$ 或者 $9\\times3$ ），是输入与输出数组的偏导数。例子如下：cv::Mat r = (cv::Mat_&amp;lt;float&amp;gt;(3,1) &amp;lt;&amp;lt; -2.100418, -2.167796, 0.273330);cv::Mat R(cv::Size(3,3), CV_16FC1);cv::Rodrigues(r, R);std::cout &amp;lt;&amp;lt; &quot;r=&quot; &amp;lt;&amp;lt; r &amp;lt;&amp;lt; std::endl;std::cout &amp;lt;&amp;lt; &quot;R=&quot; &amp;lt;&amp;lt; R &amp;lt;&amp;lt; std::endl;程序结果：5. 欧拉角和四元数（1）欧拉角上图是一个示意图。欧拉角定义如下： 绕物体的 z 轴旋转，得到偏航角 yaw 绕旋转之后的 y 轴旋转，得到俯仰角 pitch 绕旋转之后的 x 轴旋转，得到滚转角 roll如果选用的轴的旋转顺序不同，则欧拉角不同。上述的欧拉角为 $rpy$ 欧拉角，以 $z$ 轴， $y$ 轴， $x$ 轴顺序旋转，是比较常用的一种。下面举个例子（来自参考资料 5 ）。这里，我把三个 Gimbal 环用不同的颜色做了标记，底部三个轴向， RGB 分别对应 XYZ 。 假设现在这个陀螺仪被放在一艘船上，船头的方向沿着 +Z 轴，也就是蓝色右前方。现在假设，船体发生了摇晃，是沿着前方进行旋转的摇晃，也就是桶滚。由于转子和旋转轴具有较大的惯性，只要没有直接施加扭矩，就会保持原有的姿态。由于上图中绿色的活动的连接头处是可以灵活转动的，此时将发生相对旋转，从而出现以下的情形：再次假设，船体发生了pitch摇晃，也就是俯仰。同样，由于存在相应方向的可以相对旋转的连接头（红色连接头），转子和旋转轴将仍然保持平衡，如下图：最后假设，船体发生了yaw摇晃，也就是偏航，此时船体在发生水平旋转。相对旋转发生在蓝色连接头。如下图：最终，在船体发生 Pitch 、 Yaw 、 Roll 的情况下，陀螺仪都可以通过自身的调节，而让转子和旋转轴保持平衡。但是欧拉角有一个致命的问题导致死锁，称为万向节死锁。（2）万向节死锁现在看起来，这个陀螺仪一切正常，在船体发生任意方向摇晃都可以通过自身调节来应对。然而，真的是这样吗？假如，船体发生了剧烈的变化，此时船首仰起了90度（虽然可能不合理），此时的陀螺仪调节状态如下图：此时，船体再次发生转动，沿着当前世界坐标的 +Z 轴（蓝色轴，应该正指向船底）进行转动，那么来看看发生了什么情况。现在，转子不平衡了，陀螺仪的三板斧不起作用了。它失去了自身的调节能力。那么这是为什么呢？之前陀螺仪之所以能通过自身调节，保持平衡，是因为存在可以相对旋转的连接头。在这种情况下，已经不存在可以相对旋转的连接头了。 那么连接头呢？去了哪里？显然，它还是在那里，只不过是，连接头可以旋转的相对方向不是现在需要的按着+Z轴方向。从上图中，我们清楚地看到： 红色连接头：可以给予一个相对俯仰的自由度。 绿色连接头：可以给予一个相对偏航的自由度。 蓝色连接头：可以给予一个相对偏航的自由度。没错，三个连接头，提供的自由度只对应了俯仰和偏航两个自由度，桶滚自由度丢失了。这就是陀螺仪上的“万向节死锁”问题。我们可以用小程序来重现万向节死锁问题。首先，预设一下接下来的欧拉角变化顺序。见下图：上图中，红色框内的部分的列表，记录了接下来欧拉角的增长变化过程。即它会从 $(0,0,0)$ 变化到 $(90,0,0)$ ，再变化到 $(90,90,0)$ ，再变化到 $(90,180,0)$ ，再变化到 $(90,180,90)$ ，再变化到 $(90,180,180)$ 。下图是变化的过程演示：现在可以看到： 当先执行X轴旋转 90 度，此时在执行Pitch(俯仰)变化。 再在Y轴进行变化 0-180 度，此时在执行相对自身的 Roll (桶滚)变化。 再在Z轴进行变化 0-180 度，此时仍在执行相对自身的 Roll (桶滚)变化。这里所说的俯仰、桶滚、偏航都是相对自己局部坐标系的。这与上述的陀螺仪中出现的问题是一样的，万向节死锁。也就是尽管欧拉角在 XYZ 三个轴向进行进动(持续增长或者减少)，但是影响最终的结果，只对应了两个轴向。这一点在 Unity 编程中也应该注意。为了解决这一问题，我们引入四元数。由于万向锁的存在，欧拉角并不是一个完备的描述旋转的方式。事实上，我们找不到不带奇异性的三维向量描述方式。（3）四元数四元数的定义如下：\\(q = \\begin{bmatrix}w &amp;amp; x &amp;amp; y &amp;amp; z\\\\ \\end{bmatrix}^T, \\text{ where }|q|^2 = 1\\)定义 $\\psi,\\theta,\\phi$ 分别为绕Z轴、Y轴、X轴的旋转角度，如果用 Tait-Bryan angle 表示，分别为 Yaw 、 Pitch 、 Roll 。旋转角度-&amp;gt;四元数通过旋转轴和绕该轴旋转的角度可以构造一个四元数：\\(w = \\cos(\\alpha/2)\\\\x = \\sin(\\alpha/2)\\cos(\\beta_x)\\\\y = \\sin(\\alpha/2)\\cos(\\beta_y)\\\\z = \\sin(\\alpha/2)\\cos(\\beta_z)\\\\\\)其中 $\\alpha$ 是绕旋转轴旋转的角度， $\\cos(\\beta_x),\\cos(\\beta_y),\\cos(\\beta_z)$ 为旋转轴在 $x,y,z$ 方向的分量（由此确定了旋转轴)。欧拉角-&amp;gt;四元数\\[q =\\begin{bmatrix}w\\\\x\\\\y\\\\z\\\\\\end{bmatrix}=\\begin{bmatrix}\\cos(\\phi/2)\\cos(\\theta/2)\\cos(\\psi/2)+\\sin(\\phi/2)\\sin(\\theta/2)\\sin(\\psi/2)\\\\\\sin(\\phi/2)\\cos(\\theta/2)\\cos(\\psi/2)-\\cos(\\phi/2)\\sin(\\theta/2)\\sin(\\psi/2)\\\\\\cos(\\phi/2)\\sin(\\theta/2)\\cos(\\psi/2)+\\sin(\\phi/2)\\cos(\\theta/2)\\sin(\\psi/2)\\\\\\cos(\\phi/2)\\cos(\\theta/2)\\sin(\\psi/2)-\\sin(\\phi/2)\\sin(\\theta/2)\\cos(\\psi/2)\\\\\\end{bmatrix}\\]四元数-&amp;gt;欧拉角\\[\\begin{bmatrix}\\phi\\\\\\theta\\\\\\psi\\end{bmatrix}=\\begin{bmatrix}\\text{atan2}(2(wx+yz), 1-2(x^2+y^2))\\\\\\arcsin(2(wy-zx))\\\\\\text{atan2}(2(wz+xy), 1-2(y^2+z^2))\\end{bmatrix}\\]其他坐标系在其他坐标系下，需根据坐标轴的定义，调整一下以上公式。如在 Direct3D 中，笛卡尔坐标系的 X 轴变为 Z 轴， Y 轴变为 X 轴， Z 轴变为 Y 轴（无需考虑方向）。\\(q =\\begin{bmatrix}w\\\\x\\\\y\\\\z\\\\\\end{bmatrix}=\\begin{bmatrix}\\cos(\\phi/2)\\cos(\\theta/2)\\cos(\\psi/2)+\\sin(\\phi/2)\\sin(\\theta/2)\\sin(\\psi/2)\\\\\\cos(\\phi/2)\\sin(\\theta/2)\\cos(\\psi/2)+\\sin(\\phi/2)\\cos(\\theta/2)\\sin(\\psi/2)\\\\\\cos(\\phi/2)\\cos(\\theta/2)\\sin(\\psi/2)-\\sin(\\phi/2)\\sin(\\theta/2)\\cos(\\psi/2)\\\\\\sin(\\phi/2)\\cos(\\theta/2)\\cos(\\psi/2)-\\cos(\\phi/2)\\sin(\\theta/2)\\sin(\\psi/2)\\\\\\end{bmatrix}\\)\\[\\begin{bmatrix}\\phi\\\\\\theta\\\\\\psi\\end{bmatrix}=\\begin{bmatrix}\\text{atan2}(2(wz+xy), 1-2(x^2+z^2))\\\\\\arcsin(2(wx-yz))\\\\\\text{atan2}(2(wy+xz), 1-2(x^2+y^2))\\end{bmatrix}\\]三、作业链接: https://pan.baidu.com/s/19jWghlU5FS9YfwG4EcMADA 提取码: q5bg【其中部分题目提供了参考答案】 对数据包中的汽车照片中的车牌进行透视变换，可自行决定难度： 通过画图工具等手动确定透视变换 4 个像素点坐标 通过 OpenCV 窗口鼠标回调函数点击确定像素点坐标 通过传统视觉识别确定像素点坐标 项目实战：对桌面的扑克牌进行透视变换，给出扑克牌的正视图。要求用算法识别出角点并排序。 效果如下： 使用 PnP 算法求解相机相对于标定板的位置，相机标定结果已经在数据包中给出与 hw3.zip 压缩包。 使用 OpenCV （与 Eigen ）完成深度图重投影，文件位于 hw4.zip 压缩包，其中包含了图片、其对应的深度信息、以及相机内参矩阵与相机透视变换矩阵。 如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！四、参考资料 如何通俗地讲解「仿射变换」这个概念？ 仿射变换 学习笔记之——P3P与ICP位姿估计算法及实验 Eigen的速度为什么这么快？（部分代码有误） 【Unity编程】欧拉角与万向节死锁（图文版） 学习笔记—四元数与欧拉角之间的转换作者：Harry-hhj，Github主页：传送门作者：E-T-E-R-N-A-L-B-L-U-E，传送门" }, { "title": "神经网络集训 —— Numpy 的使用", "url": "/posts/Numpy-Tutorial/", "categories": "Course, Nerual Network", "tags": "getting started, robomaster, numpy", "date": "2021-10-14 22:00:00 +0800", "snippet": "神经网络集训 —— Numpy 的使用在讲解具体的知识点之前，先来做做以下的问卷，进行一个基础的自查。这样，既能避免过分地自信导致学习态度的降低，也能有针对性地学习自己不理解的知识。当然，做题时请不要借助外部资料！链接: https://pan.baidu.com/s/1Ip4Dz6sAel3htlETxWbOYg 提取码: op3f一、Python 基础（1）import 机制对于 Python 脚本， import 的顺序不同，运行脚本不同，程序执行的代码可能不同，结果自然也不会相同。我们来看以下三个脚本：A.py ：# A.pyx=1def func(val): print(val) return x + valx = func(4)B.py ：# B.pydef func(val): print(val)func(1)import AA.func(2)C.py ：# C.pyimport AA.x = 10import BB.func(2)print(A.x)那么 C.py 的运行结果是：412210为什么最后是 10 而不是 5 ？原因在于 python 的 import 机制。1）标准 importPython 中所有加载到内存的模块都放在 sys.modules 。当 import 一个模块时首先会在这个列表中查找是否已经加载了此模块，如果加载了则只是将模块的名字加入到正在调用 import 的模块的 Local 名字空间中。如果没有加载则从 sys.path 目录中按照模块名称查找模块文件，模块可以是 py 、 pyc 、 pyd ，找到后将模块载入内存，并加到 sys.modules 中，并将名称导入到当前的 Local 名字空间。一个模块不会重复载入。多个不同的模块都可以用 import 引入同一个模块到自己的 Local 名字空间，其实背后的 PyModuleObject 对象只有一个。这里说一个容易忽略的问题： import 只能导入模块，不能导入模块中的对象（类、函数、变量等）。例如：模块 A（A.py）中有个函数 getName ，另一个模块不能通过 import A.getName 将 getName 导入到本模块，只能用 from A import getName 。注意，虽然有一种写法 from A import * 可以一次性导入模块中的所有对象，但是我们无法确保所有模块的对象不重名，可能会造成内存覆盖的问题，这在项目中非常难 debug ，所以不要使用！2）嵌套 import1. 顺序嵌套例如：本模块导入 A 模块（import A）， A 中又 import B ， B 模块又可以 import C ……这中嵌套比较容易理解，需要注意的一点就是各个模块的 Local 名字空间是独立的。对于上面的例子，本模块 import A 之后本模块只能访问模块 A ，不能访问模块 B 及其他模块。虽然模块 B 已经加载到内存了，如果访问还要再明确的在本模块中 import B 。2. 循环嵌套举个例子：# A.pyfrom B import Dclass C: pass# B.pyfrom A import Cclass D: pass结果会报错 ImportError: cannot import name &#39;D&#39; from partially initialized module &#39;B&#39; (most likely due to a circular import) 。如果将 A.py 改为： import B 就可以了。为什么？这跟 Python 内部 import 的机制是有关的，具体到 from B import D ， Python 内部会分成几个步骤： 在 sys.modules 中查找符号 “B” 如果符号 B 存在，则获得符号 B 对应的 module 对象。从 的 `__dict__` 中获得符号 `“D”` 对应的对象，如果 `“D”` 不存在，则抛出异常。 如果符号 B 不存在，则创建一个新的 module 对象 &amp;lt;module B&amp;gt;，注意，此时， module 对象的 __dict__ 为空。执行 B.py 中的表达式，填充 &amp;lt;module B&amp;gt; 的 __dict__ 。从 &amp;lt;module B&amp;gt; 的 __dict__ 中获得 “D” 对应的对象，如果 “D” 不存在，则抛出异常。所以这个例子的执行顺序如下： 执行 A.py 中的 from B import D 由于是执行的 python A.py ，所以在 sys.modules 中并没有 &amp;lt;module B&amp;gt; 存在， 首先为 B.py 创建一个 module 对象 (&amp;lt;module B&amp;gt;) ， 注意，这时创建的这个 module 对象是空的，里边啥也没有，在 Python 内部创建了这个 module 对象之后，就会解析执行 B.py ，其目的是填充 &amp;lt;module B&amp;gt; 这个 __dict__ 。 执行 B.py 中的 from A import C 在执行 B.py 的过程中，会碰到这一句， 首先检查 sys.modules 这个 module 缓存中是否已经存在 &amp;lt;module A&amp;gt; 了， 由于这时缓存还没有缓存 &amp;lt;module A&amp;gt; ， 所以类似的，Python 内部会为 A.py 创建一个 module 对象(&amp;lt;module A&amp;gt;)， 然后，同样地，执行 A.py 中的语句。 再次执行 A.py 中的 from B import D 这时，由于在第 1 步时，创建的 &amp;lt;module B&amp;gt; 对象已经缓存在了 sys.modules 中， 所以直接就得到了 &amp;lt;module B&amp;gt; ， 但是，注意，从整个过程来看，我们知道，这时 &amp;lt;module B&amp;gt; 还是一个空的对象，里面啥也没有， 所以从这个 module 中获得符号 &quot;D&quot; 的操作就会抛出异常。 如果这里只是 import B ，由于 &quot;B&quot; 这个符号在 sys.modules 中已经存在，所以是不会抛出异常的。 3）包 import只要一个文件夹下面有个 __init__.py 文件，那么这个文件夹就可以看做是一个包。包导入的过程和模块的基本一致，只是导入包的时候会执行此包目录下的 __init__.py 而不是模块里面的语句了。另外，如果只是单纯的导入包，而包的 __init__.py 中又没有明确的其他初始化操作，那么此包下面的模块是不会自动导入的。例如有下面的包结构：PA|---- __init__.py|---- wave.py|---- PB1 |---- __init__.py |---- pb1_m.py|---- PB2 |---- __init__.py |---- pb2_m.py有如下程序：import sysimport PA.wave #1import PA.PB1 #2import PA.PB1.pb1_m as m1 #3import PA.PB2.pb2_m #4PA.wave.getName() #5m1.getName() #6PA.PB.pb2_m.getName() #7程序执行过程如下： 当执行 #1 后， sys.modules 会同时存在 PA 、 PA.wave 两个模块，此时可以调用 PA.wave 的任何类或函数了。不能调用 PA.PB1(2) 下的任何模块。当前 Local 中有了 PA 名字。 当执行 #2 后，只是将 PA.PB1 载入内存， sys.modules 中会有 PA 、 PA.wave 、 PA.PB1 三个模块，但是 PA.PB1 下的任何模块都没有自动载入内存，此时如果直接执行 PA.PB1.pb1_m.getName() 则会出错，因为 PA.PB1 中并没有 pb1_m 。当前 Local 中还是只有 PA 名字，并没有 PA.PB1 名字。 当执行 #3 后，会将 PA.PB1 下的 pb1_m 载入内存， sys.modules 中会有 PA 、 PA.wave 、 PA.PB1 、 PA.PB1.pb1_m 四个模块，此时可以执行 PA.PB1.pb1_m.getName() 了。由于使用了 as ，当前 Local 中除了 PA 名字，另外添加了 m1 作为 PA.PB1.pb1_m 的别名。 当执行 #4 后，会将 PA.PB2 、 PA.PB2.pb2_m 载入内存， sys.modules 中会有 PA 、 PA.wave 、 PA.PB1 、 PA.PB1.pb1_m 、 PA.PB2 、 PA.PB2.pb2_m 六个模块。当前 Local 中还是只有 PA 、 m1 。 下面的 #5 ， #6 ， #7 都是可以正确运行的。注意的是：如果 PA.PB2.pb2_m 想导入 PA.PB1.pb1_m 、 PA.wave 是可以直接成功的。最好是采用明确的导入路径，对于 ./.. 相对导入路径还是不推荐用。（2）避免使用全局表达式一个模块中定义的全局变量一般是可以被其他模块所修改的，比如之前的例子中，模块 B 相信 A.x 值是 1 ，但是它不知道在 C.py 中已经对它进行了修改。这些修改直接修改变量值的操作都应该放在 if __name__ == &#39;__main__&#39;: 中。if __name__ == &#39;__main__&#39;: 是指在终端运行该 python 脚本时才会执行的语句，除此之外的所有情况下这些代码都不会执行。（3）变量含义在 Python 中所有的变量名都是一个符号，其实现是将变量名和它的值绑定。 = 号并不代表赋值，而是重新将一个变量名与新的值进行绑定。有了这个理解，你就会对下面的示例有更好地理解：def func1(a): a = &quot;world&quot;def func2(a): a[0] = &quot;world&quot;x = &quot;hello&quot;func1(x)print(x)x = [&quot;hello&quot;]func2(x)print(x)在 func1 中，调用时先将 x 的值同时绑定到参数 a 上，然后将 a 重新绑定到常量 “world” 上，这并不影响 x 绑定在 &quot;hello&quot; 上。而在 func2 中，调用时先将 x 的值（数组）同时绑定到参数 a 上，然后将这个数组的第 0 个数据指向常量 “world” 上，这时 x 绑定的值也发生了变化。如果你有 C/C++ 基础，你可以把所有变量符号想象成一个指针， = 的右操作数就是指针要指向的对象，而 = 就是对指针赋值的过程。（4）原地运算在 Python 中，一些运算是返回备份的，而另一些是直接修改原值的，叫做原地运算。这些运算很多，不可能一一枚举，但我们需要有这样一个概念。例如下面的函数：def minus_one(minuend): minuend -= 1如果你没有办法区分这个函数是否可以直接修改调用时传入的参数值，那么我们推荐将所有函数写成 return 的形式返回运算结果。def minus_one(minuend): return minuend - 1x = 10x = minus_one(x)二、Numpy 基础（0）广播 （broadcasting）在讲解 Numpy 运算之前，我们先要讲一个非常有用的机制——广播（broadcasting），它能自动将两个大小不等的张量通过复制扩展自动变成两个相同大小的张量然后进行运算。尽管它非常有用，但是它也是程序没有报错却也运行结果不对的杀手！（因为程序不会报错，因此你可以使用 assert 确保程序符合你的想法）广播用于对应元素的二元运算，如+-*/等。对应元素的二元运算一般要求两个张量的shape相同，当shape不同时，会触发广播。广播的原则：如果两个数组的后缘维度（trailing dimension，即从末尾开始算起的维度）的轴长度相符，或其中的一方的长度为 1 ，则认为它们是广播兼容的。1. 后缘维度的轴长相符import numpy as npx = np.array([[0, 0, 0],[1, 1, 1],[2, 2, 2], [3, 3, 3]]) y = np.array([1, 2, 3]) print(x + y)上例中 x 的shape为 $(4, 3)$ ，y 的shape 为 $(3, )$ 。虽然前者是一维的，后者是二维的，但是比较后缘维度可知：(4,3) ^ (3, ) ^它们的后缘维度相等， x 的第二维长度为 3 ，和 y 的维度相同。因此他们可以通过广播机制完成相加，在这个例子当中是将 y 沿着 0 轴进行扩展。同样，下图也是可以的。2. 后缘维度不全相同，有一方长度为1import numpy as npx = np.array([[0, 0, 0],[1, 1, 1],[2, 2, 2], [3, 3, 3]]) y = np.array([[1],[2],[3],[4]]) print(x + y)虽然 x 的 shape 为 $(4, 3)$ ， y 的 shape 为 $(4, 1)$ ，但第二个数组在 1 维轴上长度为 1 ，所以可以在 1 轴上进行广播。(4,3) ^ ^(4,1) ^ ^反例：import numpy as npx = np.ones((4,3,5))y = np.ones((4,1,3))print(x + y)代码会报错无法计算，因为从后缘维度数起 2 轴上 x 、 y 大小即不相同也不为 1 。Numpy 中表示张量的数据类型是 ndarray 。我们先介绍 ndarray 对象的基本概念，理解这些概念对你以后了解张量运算和实现有非常大的帮助！（1）张量整体的属性一个张量是由一个数据头和一个数据块指针组成的。数据头中存放了张量的属性值，包括数据类型、数组形状和每个维度的 stride 。数据块指针指向的是张量的数据值，对应内存中的一块连续的内存空间。数据类型很容易理解，比如 int 、 float 、 bool ，这些值代表了多少个内存单元表示一个数据，例如 int 表示一个数据占用 4 个字节。数组形状表示张量的形状大小，它指定了张量的各个维度，例如 $(3,4,5)$ 表示一个 $3\\times4\\times5$ 的张量。我们规定：张量的最后一维称为低维，在低维上数据的内存分布是连续的，而第一个维称为高维。例如上面的例子中最高维是 $3$ 维，最低维是 $5$ 维。每个维度的 stride 是为了方便数据的索引、存放和运算。 stride 表示在每一个维度上加一时需要越过多少个数据。它是通过公式计算得出的，你很快会发现计算过程非常简单。例如，对于 shape 等于 $(3, 4, 5)$ ，那么 stride 等于 $(20, 5, 1)$。记得，最低维的数据是连续的，所以最低维索引加一意味着只要前进一个数据就能得到下一个数据，对于更高维，索引加一意味着需要越过比它维度低的所有数据，也就是比它低维的乘积。下面有个直观的示例，在上图中，紫色数据块第 0 维索引加一，对应红色数据块，此时它需要越过第 0 维大小的数据块个数 5 。之后你也会发现通过改变张量的 shape 和 stride 可以直接实现运算而不需要改变数据内存块！（2）张量中元素的属性一个元素的属性包括 元素值 元素坐标想象一下，对于转置，我们不需要改变数据块，只需要把每个元素的坐标颠倒一下就可以了。（3）张量运算张量有三种运算的方式： 返回 view ，即返回的是数据本身，修改返回值将导致原变量的值发生变化 返回 copy ，即返回的数据的拷贝，后续操作与原变量无关 原地运算，即直接修改数据本身，无返回值三、Numpy 运算下面举的例子都建议你手动在命令行输一遍，我们也提供了 ipynb 教程：链接: https://pan.baidu.com/s/1MOTfMB7XB2eQ-aEwS4z8_g 提取码: twd3。（1） ndarray 对象的创建np.array() ：从 python 列表创建，显式指定每个元素的值。np.empty() ：只指定形状，不指定值。元素值随机。np.zeros() ：只指定形状。元素值全 0 。np.ones() ：只指定形状。元素值全 1 。np.eye() ：创建二维张量，对角线为 1 ，其余为 0 。np.random.randn() ：只指定形状，非元组。元素值标准正态分布。np.random.uniform() ：指定形状和上下限。元素值均匀分布。闭区间。np.random.randint() ：指定形状和上下限。元素值均匀分布，但只会取整数。前闭后开。np.arange() ：创建一维张量。指定起点终点步长，类似 range 。前闭后开。np.linspace() ：创建一维等差数列。指定起点终点数量。闭区间。np.concatenate() ：在某个维度上拼接若干个张量。维度数不变。返回 copy 。除了拼接的维度外要求其它维度大小相等。特殊： torch.cat 。 可以想象成对于索引进行分类讨论，在一些时候选择某一个张量选择值np.stack() ：在某个维度上堆叠若干个张量。维度数增加。返回 copy 。要求所有维度大小相等。 除了第 0 维堆叠不破坏内存连续性外，其他都会破坏。np.meshgrid()：创建网格张量，返回两个张量，分别代表网格的 x 轴和 y 轴。 坐标矩阵其实有大量的重复—— $X$ 的每一行都一样， $Y$ 的每一列都一样。基于这种强烈的规律性， numpy 提供的 numpy.meshgrid() 函数可以让我们快速生成坐标矩阵 $X$ ，$Y$ 。 举例： x, y = np.meshgrid(np.array([0,1,2]), np.array([0,1])) print(x) # [[0,1,2], # [0,1,2]] print(y) # [[0,0,0], # [1,1,1]] （2） ndarray 对象的常用操作shape ：获取当前张量的维度信息（维数以及每一维的长度）。reshape() ：返回更改维度后的 view 。 更改的方式是不破坏内存连续性，只要各维度大小的乘积与原来各维度大小的乘积相等即可。因此，可以想象只需要强行改变 shape ，然后根据 shape 重新计算 stride，就能实现这一功能。例如， shape=(3,4,5) ， stride=(20, 5, 1) 经过 reshape(15, 4) 后 shape=(15, 4) ， stride=(4, 1) ，原数据块不用改变。resize() ：更改自己的维度，无返回值。 不破坏内存连续性transpose() ：返回更改维度顺序后的 view 。返回值内存不连续，但内存地址不变。特殊： torch.permute 。 这个操作通过改变shape 、 stride 即可实现。例如 shape=(3, 4, 5) ， stride=(20, 5, 1) 经过 transpose(2, 0, 1) 后变成 shape=(5, 3, 4) ， stride=(1, 20, 5) 。即对 stride 也进行相同的 transpose ，而不是根据公式重新计算！T ： transpose() 的特殊情况，针对二维张量，返回 view 。squeeze() ：删除长度为 1 的维度，返回 view 。特殊： torch.unsqueeze() ：添加某个长度为 1 的维度，返回 view 。view() ：提供对内存区域不同的切割方式，来完成数据类型的转换，而无须要对数据进行额外的copy，来节约内存空间，返回 view 。转换的数据内存必须是连续分布的。特殊： torch.view 。repeat() ：将某个维度复制 n 次，每个元素复制（因此在某个维度上复制出的数据是聚在一起的），返回 copy 。特殊： torch.repeat 。特殊： torch.expand 。tile() ：相当于多个张量 concatenate() 在一起，但可以同时复制多个维度。copy() ：返回自身的 copy 。特殊： torch.clone() 。astype() ：更改元素数据类型，返回 copy 。（3） ndarray 对象的索引（维度索引和整体索引）切片索引：一次只能索引一个维度。返回 view 。支持原地修改。 一个索引结构如下： [start:end:step] ，其中区间是左闭右开， step 表示一次跳过多少。这三个参数都可以参略，当 start 省略时，默认从第一个开始，即 0 ，当 end 省略时，默认从直到最后一个（包括），当 step 省略时，默认步长为 1 。第一个 : 不能参略。注意对于大小 (3, 4, 5) ，索引 [:, :4, :] 和 [:, :, :] 不同。坐标（列表）索引：一次只能索引一个维度。返回 copy 。支持原地修改。 举例，对一个 $3\\times3\\times3$ 的张量，在第二维度进行索引，并按照 [2, 0] 的顺序返回结果。布尔索引：一次索引整个张量。返回 copy 。支持原地修改。 用一个相同大小的 bool_ 型张量， 1 表示保留该值， 0 表示舍弃该值。返回一维张量，按照数据在内存中的排列顺序排列。区域索引：利用 np.ix_ ，产生笛卡尔积的映射关系。返回 copy 。支持原地修改。 举例，[np.ix_([0,2], [2, 1])] 提取的元素分别是 (0, 2), (0, 1), (2, 2), (2, 1) ，组成一个 $2\\times2$ 的张量。（4） ndarray 对象的运算max() ， min() ， mean() ：在某个维度/整个张量上计算最大值，最小值，平均值。argmax() ， argmin() ：在某个维度上计算最大值坐标，最小值坐标。+-*/ ：对应元素计算。注意 * 表示对应元素相乘，因此两个输入张量大小必须相等。dot() 和 @ ：针对二维张量，矩阵乘法。指数对数三角函数等：每个元素计算。大于小于等于比较运算：每个元素计算。返回布尔张量。floor() ， ceil() ， round() ：向下取整，向上取整，四舍五入。where() ：输入一个布尔张量和两个同形状的其他张量，根据布尔值选择两个张量中的值。即对于每个坐标，如果对应布尔值为 1 ，则选择第一个张量对应位置的值，否则选择第二个张量对应位置的值。（5）np.linalg 线性代数相关运算np.linalg.det() ：求二维矩阵的行列式，输入多维时以最低两维对高维分别进行计算np.linalg.inv() ：求逆np.linalg.eig() ：求特征值特征向量np.linalg.norm() ：求范数 范数是具有“长度”概念的函数。 L0 范数：向量中非 0 的元素的个数。( L0 范数很难优化求解) L1 范数：向量中各个元素绝对值之和。L1 会趋向于产生少量的特征，而其他的特征都是 0 。 L2 范数：向量各元素的平方和然后求平方根。可以防止过拟合，提升模型的泛化能力。L2 会选择更多的特征，这些特征都会接近于 0 。（6）文件 ionp.save 和 np.load ：用于保存和加载一个 ndarray 张量np.savetxt 和 np.loadtxt ：以 txt 格式保存和加载一个二维 ndarray 张量，可以指定分隔符np.savez 和 np.load ：用于同时保存多个 ndarray 张量，输入字典键值对，读取出一个字典四、可视化Matlab 是一个常用的数据分析和绘图软件，在 Python 我们也可以使用 matplotlib 库绘制图形。在进行可视化时，我们使用的是 matplotlib.pyplot 子库。 plt.plot() ：绘制折线图 plt.scatter() ：绘制散点图 plt.bar() ：绘制柱形图 plt.hist() ：绘制柱形图的频率分布 plt.imshow() ：绘制图像（RGB 格式，与 OpenCV 的 BGR 不同） plt.matshow() ：可视化数组（热力图） plt.savefig() ：保存最新绘制的一幅图，在 plt.show() 之前调用 plt.savefig() ；否则保存出去会是白纸一张。 plt.show() ：显示绘制好的图像 plt.imsave() ：保存绘制好的图像 seaborn 库，对 matplotlib 的二次封装，提供更美观的可视化。注意点：形状是参数列表（参数类型）还是以元组/列表（数据类型）表示、区间开闭、运算方式。讲了这么多，一定记住一点：在神经网络中，如果有可能不是用 for 循环，就不要使用 for 循环！五、课后作业为了巩固我们刚才讲解的知识，提升代码的实战能力，请完成以下课后作业 Quiz ，我们提供了参考答案，但这并不是唯一的正确答案。在下面的链接中还有一道较难的机器视觉实战题，我们并不是为了考察机器视觉，所以给出了计算方式，请用 Numpy 运算实现。百度网盘链接: https://pan.baidu.com/s/1OHNeqrErD8zIaBiRyR0lUw 提取码: 60kf如果觉得本教程不错或对您有用，请前往项目地址 https://raw.githubusercontent.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！六、参考教程 Python 被导入模块多次被加载的问题（基于python的import机制） Numpy学习——广播机制理解作者：Harry-hhj，Github主页：传送门讲师：xinyang，Github主页：传送门" }, { "title": "神经网络课程目录", "url": "/posts/NN-Tutorial-Catalogue/", "categories": "Course, Nerual Network", "tags": "catalog, robomaster", "date": "2021-10-13 00:00:00 +0800", "snippet": "NN Tutorial Catalogue 机械是血肉，电控是大脑，视觉是灵魂。一、培训安排二、培训教程 神经网络集训 —— Numpy 的使用 如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "RM 教程 4 —— 相机", "url": "/posts/RM-Tutorial-4-Camera/", "categories": "Course, RM", "tags": "getting started, robomaster, camera", "date": "2021-10-10 10:00:00 +0800", "snippet": "RM 教程 4 —— 相机 机械是肉体， 电控是大脑， 视觉是灵魂一、相机结构简介广义的相机由两部分组成： 工业相机 镜头（1）工业相机了解工业相机的相关参数能够帮助我们更好的理解相机功能，进而帮助我们完成对相机的选型工作。所谓外行看热闹，内行看门道，工业相机的门道就从其参数开始。1. 分辨率相机的传感器 sensor 是有许多像素点按照矩阵的形式排列而成，分辨率就是以水平方向和垂直方向的像素来表示的。分辨率越高，成像后的图像像素数就越高，图像就越清晰。常用的工业面阵相机分辨率有 130 万、 200 万、 500 万等；对于线阵相机而言，分辨率就是传感器水平方向上的像素数，常见有 1 K、 2 K、 6 K等。在相机分辨率的选型上，要根据我们的项目需求而定，并不一定是分辨率越高就越好，分辨率高带来的图像数据量就大，后期的算法处理复杂度就高，而且一般分辨率大的相机，帧率一般都不会太高。2. 传感器尺寸传感器尺寸是以有效面积（宽x高）或以对角线大小（英寸）来表示的，常见的传感器尺寸如下： 型号 有效面积 宽x高（mm） 1/4″ 3.2mm×2.4mm 1/3″ 4.8mm×3.6mm 1/2″ 6.4mm×4.8mm 2/3″ 8.8mm×6.6mm 1″ 12.8mm×9.6mm 传感器尺寸越大，一定程度上表示相机可容纳像素个数越多，成像的画幅越大（并不一定是视野更大）。3. 像元尺寸像元尺寸就是每个像素的面积。单个像素面积小，单位面积内的像素数量多，相机的分辨率增加，利于对细小缺陷的检测和增大检测视场。随着像素面积的缩小，满阱能力（每个像素能够储存的电荷数量）也随之减小，造成相机动态范围的降低。 4. 像素深度像素深度是指每个像素用多少比特位表示。通常，每个像素的比特位数多，表达图像细节的能力强，这个像素的颜色值更加丰富、分的更细，颜色深度就更深。一般像素深度有1位、8位、16位、24位和32位。灰度显示就是 8 个二进制位， RGB 显示就是 24 个二进制位。5. 动态范围动态范围是用来描述每个像素能够分辨出的灰度等级。它是饱和电压（最大的输出电平）相机输出的噪声之比。宽动态范围能够使场景中非常亮和非常昏暗部分的细节同时被清晰的显示。一般来说，低动态范围的相机噪声比较多，照片会缺失亮部细节和暗部细节。6. 最大帧率最大帧率表示的是面阵工业相机每秒能够采集并输出的最大帧数，这往往和传感器芯片和数据输出接口带宽有关。根据项目需求，对于拍摄运动物体，建议选取高帧率相机，具体帧率数要根据拍摄精度来确定。7. 曝光方式工业相机常见的曝光方式有帧曝光（global shutter）和行曝光（rolling shutter）。帧曝光是指传感器阵列中所有像素同时曝光，曝光周期由预先设定的快门时间确定。这种曝光方式的相机适合拍摄运动物体，图像不会偏移，不会失真。行曝光是指同一行上的像素同时曝光，不同行的曝光起始时间不同，每行的曝光时间是相同的，行间的延迟不变。这种曝光方式的相机适用于拍摄静止的物体，拍摄运动物体，图像会偏移。在工业相机的选型中，一般参数表中会标注全局快门或卷帘快门，他们分别对应帧曝光和行曝光。8. 曝光时间传感器将光信号转换为电信号形成一帧图像，每个像元接受光信号的过程叫曝光，所花费的时间叫曝光时间，也叫快门速度。这个时间是整个算法处理性能的上限。9. 采集模式采集模式分为了连续采集、外触发采集和软触发采集三种。 连续采集指相机进行连续曝光，输出实时图像。这是我们一般连接在电脑上使用相机的方式。 外触发采集是指当相机处于外触发模式后，相机处于待机模式，不曝光，只有当相机通过I/O口接收到相机规定的单个脉冲（方波）信号后，传感器曝光一次，部分相机支持信号的上升沿、下降沿和高低电平的触发。这种方法也是我们比赛所使用的方式，这样的好处是通过固定频率的触发信号，使得相机的数据与陀螺仪的信号尽可能在同一时刻产生，使其数据对齐。 软触发是指当相机处于外触发模式后，相机处于待机模式，不曝光，只有当相机软件发出指令后，传感器曝光一次。10. 增益工业相机通常具有一个对传感器的信号进行放大的视频放大器，其放大倍数称为增益。增益越大，噪声就会变大，对传统图像处理越不利。但这也是减少曝光时间提高图像亮度的一种方式。（2）镜头镜头是摄像机中的光学元件，直接影响成像质量的优劣。分类： 按照焦距分类：焦距决定了相机适合观察什么距离的物体，短焦一般适合观察近距离物体，长焦一般适合观察远距离物体。 按照视角大小分类： 广角：视角大，可观测范围广。但同时会产生较大畸变。 标准：视角小，但产生的畸变也较小。下图是一个畸变的例子： 一般来说，在没有特殊需求的情况下，镜头选型选择标准镜头。 光圈焦距调整方式 固定光圈定焦镜头 手动光圈定焦镜头 自动光圈定焦镜头 手动变焦镜头 自动变焦镜头 …… 在选择镜头时，一般是根据视野的大小确定焦距的。因此我们需要了解 FOV （视场角）。FOV 的全称是 Field of View 。如下图，如果成像平面的宽度 W 固定， FOV 的大小直接由 Focal Length （焦距）决定。 Focal Length 越大，看得越远，但 FOV 越小。 Focal Length 越小，看得越近，但 FOV 变大。如果已知 W 和 Focal Length ， FOV 可以用简单的三角函数关系就可以求出：\\(\\alpha = 2 \\tan^{-1} \\frac{w}{2f}\\)FOV 有三种： HFOV：由 Focal Length 和 senor 的宽度（W）决定 VFOV：由 Focal Length 和 sensor 的高度（H）决定 DFOV：由 Focal Length ， W ， H 共同决定当我们选定了一个相机时，我们就知道了相机芯片的参数，为其配置镜头。当我们选定了一个工业相机时，我们就已经知道它的感光芯片的参数，而我们需要为其配置一个合适的镜头，使得它的视野在我们的需求附近。视野过大，意味着图像中出现大量无关的目标，增加处理负担，同时也会导致目标所占的像素点降低，减少拍摄的特征；视野过小，那么没办法完整地记录目标，从而丧失处理的能力。视野的计算方法比较简单，就是一个相似三角形计算。同样，我们可以用类似的方法估计焦距大小，这也是相机标定的完成方式。（3）队内使用的相机队内现在主要使用的相机型号为 MINDVISION 公司生产的 MV-SUA133GC 。下面为组装好的摄像机图片： 二、相机成像模型相机成像的过程就是世界坐标系向像素坐标系转换的过程，即：世界坐标系(3d) -&amp;gt; 相机坐标系(3d) -&amp;gt; 像平面坐标系(2d) -&amp;gt; 像素坐标系(2d)，经过这样一级一级的转换之后，物体在空间中的坐标即转换为在图像中的像素坐标。四个坐标系的表示如下： 世界坐标系 $X_w, Y_w, Z_w$ 相机坐标系 $(X_c, Y_c, Z_c)$ 像平面坐标系 $(x, y)$ 像素坐标系 $(u, v)$1）世界坐标系(3d) -&amp;gt; 相机坐标系(3d)从世界坐标系到相机坐标系的转换是刚体变换，是旋转动作和平移动作的结果，如下所示：\\(\\begin{bmatrix}X_c\\\\Y_c\\\\Z_c\\\\1\\\\\\end{bmatrix}=\\begin{bmatrix}R&amp;amp;t\\\\0&amp;amp;1\\\\\\end{bmatrix}\\begin{bmatrix}X_w\\\\Y_w\\\\Z_w\\\\1\\\\\\end{bmatrix}\\)旋转矩阵R是正交矩阵，可通过罗德里格斯（Rodrigues）变换转换为只有三个独立变量的旋转向量：\\(\\left\\{\\begin{array}{c}\\theta \\leftarrow norm(r)\\\\r \\leftarrow r/\\theta\\end{array}\\right .\\\\R = \\cos(\\theta)I + (1-\\cos(\\theta))rr^T + \\sin(\\theta) \\begin{bmatrix}0&amp;amp;-r_z&amp;amp;r_y\\\\r_z&amp;amp;0&amp;amp;-r_x\\\\-r_y&amp;amp;r_x&amp;amp;0\\\\\\end{bmatrix}\\)因此，刚体变换可用 6 个参数来描述，这 6 个参数就称为相机的外参（Extrinsic），相机外参决定了空间点从世界坐标系转换到相机坐标系的变换，也可以说外参描述了相机在世界坐标系中的位置和朝向。2）相机坐标系(3d) -&amp;gt; 像平面坐标系(2d)相机坐标系到像平面坐标系的转换如下图所示：根据相似三角形，点 P 在相机坐标系和像平面坐标系中的坐标满足如下关系：\\(\\left \\{ \\begin{array}{c}\\cfrac{x}{f} = \\cfrac{X_c}{Z_c}\\\\\\cfrac{y}{f} = \\cfrac{Y_c}{Z_c}\\\\\\end{array}\\right .\\Longrightarrow\\left \\{ \\begin{array}{c}x = f \\cfrac{X_c}{Z_c}\\\\y = f \\cfrac{Y_c}{Z_c}\\\\\\end{array}\\right .\\)3）像平面坐标系(2d) -&amp;gt; 像素坐标系(2d)图像坐标系坐标轴的单位通常为毫米（mm），原点是相机光轴与相面的交点（称为主点），即图像的中心点，轴、轴分别与轴、轴平行。故两个坐标系实际是平移关系，即可以通过平移就可得到。像素坐标是光在平面成像的一个模拟量，所以需要对成像平面上的像进行采样和量化，得到物体的像在像素平面上的坐标值。像素平面与成像平面之间，相差一个缩放和原点的平移。如下式所示，在 $u$ 轴上放大了 $\\alpha$ 倍，在 $v$ 轴上放大 $\\beta$ 倍，原点平移 $c_x$ ， $c_y$ 。\\(\\left \\{\\begin{array}{c}u = \\alpha x + c_x\\\\v = \\beta y + c_y\\end{array}\\right .\\)这里忽略了相机畸变的影响。代入 $x, y$ 得到：\\(\\left \\{\\begin{array}{c}u = f_x \\cfrac{x_c}{z_c} + c_x\\\\v = f_y \\cfrac{y_c}{z_c} + c_y\\\\\\end{array}\\right .\\)整理成齐次形式：\\(\\begin{bmatrix}u\\\\v\\\\1\\\\\\end{bmatrix}=\\cfrac{1}{z_c}\\begin{bmatrix}f_x&amp;amp;0&amp;amp;c_x\\\\0&amp;amp;f_y&amp;amp;c_y\\\\0&amp;amp;0&amp;amp;1\\\\\\end{bmatrix}\\begin{bmatrix}x_c\\\\y_c\\\\z_c\\\\\\end{bmatrix}\\)最终得到\\(\\begin{bmatrix}u\\\\v\\\\1\\\\\\end{bmatrix}=\\cfrac{1}{z_c}\\begin{bmatrix}f_x&amp;amp;0&amp;amp;c_x\\\\0&amp;amp;f_y&amp;amp;c_y\\\\0&amp;amp;0&amp;amp;1\\\\\\end{bmatrix}\\begin{bmatrix}1&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;1&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;1&amp;amp;0\\\\\\end{bmatrix}\\begin{bmatrix}R&amp;amp;t\\\\0&amp;amp;1\\\\\\end{bmatrix}\\begin{bmatrix}X_w\\\\Y_w\\\\Z_w\\\\1\\\\\\end{bmatrix}\\)即世界坐标到像素坐标的转换过程。三、相机畸变理想的针孔成像模型确定的坐标变换关系均为线性的，而实际上，现实中使用的相机由于镜头中镜片因为光线的通过产生的不规则的折射，镜头畸变（lens distortion）总是存在的，即根据理想针孔成像模型计算出来的像点坐标与实际坐标存在偏差。畸变的引入使得成像模型中的几何变换关系变为非线性，增加了模型的复杂度，但更接近真实情形。畸变导致的成像失真可分为径向失真和切向失真两类：畸变类型很多，总体上可分为径向畸变和切向畸变两类。 径向畸变的形成原因是镜头制造工艺不完美，使得镜头形状存在缺陷，包括枕形畸变和桶形畸变等，可以用如下表达式来描述：\\(\\left \\{\\begin{array}{c}x_0 = x (1 + k_1 r^2+ k_2r^4 + k_3 r^6 )\\\\y_0 = y (1 + k_1 r^2+ k_2r^4 + k_3 r^6 )\\\\\\end{array}\\right .\\) 切向畸变又分为薄透镜畸变和离心畸变等，薄透镜畸变则是因为透镜存在一定的细微倾斜造成的；离心畸变的形成原因是镜头是由多个透镜组合而成的，而各个透镜的光轴不在同一条中心线上。切向畸变可以用如下数学表达式来描述：\\(\\left \\{\\begin{array}{c}x_0 = x + [2p_1y + p_2(r^2 + 2x^2)]\\\\y_0 = y + [2p_2x + p_1(r^2 + 2y^2)]\\\\\\end{array}\\right .\\) 实际计算过程中，如果考虑太多高阶的畸变参数，会导致标定求解的不稳定。在上述的径向畸变和切向畸变的数学模型中，我们一共使用了 $5$ 个参数描述畸变。它们分别是 $[k_1, k_2, k_3, p_1, p_2]$ 。它们被称为畸变参数。注意：鱼眼畸变需要用专门的鱼眼模型。对于相机坐标系中的一个点 $P(X, Y, Z)$ ，我们能够通过 $5$ 个畸变系数找到这个点在像素平面上的正确位置： 将三维空间点投影到归一化图像平面。设它的归一化坐标为 $[x, y]^T$ 。 对归一化平面上的点进行径向畸变和切向畸变纠正。给定归一化坐标，可以求出原始图像上的坐标。\\(\\left \\{\\begin{array}{c}x_{\\text{distorted}} = x (1 + k_1 r^2+ k_2r^4 + k_3 r^6 ) + [2p_1y + p_2(r^2 + 2x^2)]\\\\y_{\\text{distorted}} = y (1 + k_1 r^2+ k_2r^4 + k_3 r^6 ) + [2p_2x + p_1(r^2 + 2y^2)]\\\\\\end{array}\\right .\\) 将纠正后的点通过内参数矩阵投影到像素平面，得到该点在图像上的正确位置。\\(\\left \\{\\begin{array}{c}u = f_x x_{\\text{distorted}} + c_x\\\\v = f_y y_{\\text{distorted}} + c_y\\\\\\end{array}\\right .\\) 四、相机标定我们可以使用标定板辅助进行相机标定。这是一个非常贵重且易损坏的工具，使用时一定要小心！1）相机标定的程序实现1. 寻找标定板角点OpenCV提供了寻找标定板棋盘格角点的函数findChessboardCorners()，他的声明如下：bool cv::findChessboardCorners(InputArray image, Size patternSize, OutputArray corners, int flags = CALIB_CB_ADAPTIVE_THRESH+CALIB_CB_NORMALIZE_IMAGE)你只需在意前三个参数，他们分别意为： image 输入的图像 patternSize 棋盘格的大小，例如这一棋盘格的大小为(11, 8)，要注意的是棋盘格的大小只考虑内侧的角点数 corners 输出结果，用向量的形式储存输出的角点2. 对找到的角点亚像素精化OpenCV提供了函数find4QuadCornerSubpix()来实现对棋盘格角点的亚像素精化，他的声明如下：bool cv::find4QuadCornerSubpix(InputArray img, InputOutputArray corners, Size region_size)。它的功能为在给定的点的周围一定范围内以亚像素的精度逼近角点。下面说明部分参数意义： corners 需要逼近的角点的初始值 region_size 在region_size内寻找角点 利用find4QuadCornerSubpix函数可以更精确的找到角点，提高标定的精度。3. 相机标定OpenCV提供了函数calibrateCamera()来实现相机标定的相关功能，他的声明如下double cv::calibrateCamera(InputArrayOfArrays objectPoints, InputArrayOfArrays imagePoints, Size imageSize, InputOutputArray cameraMatrix, InputOutputArray distCoeffs, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, int flags = 0, TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON) ) 下面说明他的参数的意义： objectPoints 棋盘格上的角点对应的世界坐标系中的位置 imagePoints 棋盘格上找到的角点 imageSize 图片的大小 cameraMatrix 输出的相机内参矩阵 distCoeffs 输出的相机畸变矩阵 rvecs 相机坐标系与世界坐标系的旋转向量 tvecs 相机坐标系与世界坐标系的平移向量 4. 程序以下为程序的实现：链接: https://pan.baidu.com/s/1I0PD_DWOrrHCjrLXzzAo_g 提取码: 1ur9#include &amp;lt;iostream&amp;gt;#include &amp;lt;opencv2/opencv.hpp&amp;gt;#include &amp;lt;opencv2/core/core.hpp&amp;gt;using namespace cv;int main() { const int board_w = 11, board_h = 8; const int board_n = board_w * board_h; Size board_size( 11, 8 ); Mat gray_img, drawn_img; std::vector&amp;lt; Point2f &amp;gt; point_pix_pos_buf; std::vector&amp;lt; std::vector&amp;lt;Point2f&amp;gt; &amp;gt; point_pix_pos; int found, successes = 0; Size img_size; int cnt = 0; int k = 0, n = 0; for (int i = 0; i &amp;lt; 20; i++){ cv::Mat src0 = cv::imread(std::__cxx11::to_string(i).append(&quot;.jpg&quot;)); if ( !cnt ) { img_size.width = src0.cols; img_size.height = src0.rows; } found = findChessboardCorners( src0, board_size, point_pix_pos_buf ); if ( found &amp;amp;&amp;amp; point_pix_pos_buf.size() == board_n ) { successes++; cvtColor( src0, gray_img, COLOR_BGR2GRAY ); find4QuadCornerSubpix( gray_img, point_pix_pos_buf, Size( 5, 5 ) ); point_pix_pos.push_back( point_pix_pos_buf ); drawn_img = src0.clone(); drawChessboardCorners( drawn_img, board_size, point_pix_pos_buf, found ); imshow( &quot;corners&quot;, drawn_img ); waitKey( 50 ); } else std::cout &amp;lt;&amp;lt; &quot;\\tbut failed to found all chess board corners in this image&quot; &amp;lt;&amp;lt; std::endl; point_pix_pos_buf.clear(); cnt++; }; std::cout &amp;lt;&amp;lt; successes &amp;lt;&amp;lt; &quot; useful chess boards&quot; &amp;lt;&amp;lt; std::endl; Size square_size( 10, 10 ); std::vector&amp;lt; std::vector&amp;lt; Point3f &amp;gt; &amp;gt; point_grid_pos; std::vector&amp;lt; Point3f &amp;gt; point_grid_pos_buf; std::vector&amp;lt; int &amp;gt; point_count; Mat camera_matrix( 3, 3, CV_32FC1, Scalar::all( 0 ) ); Mat dist_coeffs( 1, 5, CV_32FC1, Scalar::all( 0 ) ); std::vector&amp;lt; Mat &amp;gt; rvecs; std::vector&amp;lt; Mat &amp;gt; tvecs; for (int i = 0; i &amp;lt; successes; i++ ) { for (int j = 0; j &amp;lt; board_h; j++ ) { for (int k = 0; k &amp;lt; board_w; k++ ){ Point3f pt; pt.x = k * square_size.width; pt.y = j * square_size.height; pt.z = 0; point_grid_pos_buf.push_back( pt ); } } point_grid_pos.push_back( point_grid_pos_buf ); point_grid_pos_buf.clear(); point_count.push_back( board_h * board_w ); } std::cout &amp;lt;&amp;lt; calibrateCamera( point_grid_pos, point_pix_pos, img_size, camera_matrix, dist_coeffs, rvecs, tvecs ) &amp;lt;&amp;lt; std::endl; std::cout &amp;lt;&amp;lt; camera_matrix &amp;lt;&amp;lt; std::endl &amp;lt;&amp;lt; dist_coeffs &amp;lt;&amp;lt; std::endl; return 0;}如果想要将畸变的图像还原为原图，可以使用函数cvUndistort2( ImageC1, Show1, &amp;amp;intrinsic_matrix, &amp;amp;distortion_coeffs);来进行图像矫正。五、作业请你自己编写一个相机标定程序，对下压缩包内的两个相机进行标定，分别给出标定的结果（重投影误差，相机内参矩阵，畸变矩阵）。不要复制粘贴！链接: https://pan.baidu.com/s/1yzcor8vEUOs2CmfF6BVGRw 提取码: 01b4如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！六、参考教程 浅析相机FOV 工业相机常见参数 相机成像模型 相机的那些事儿 (二)成像模型第一作者：Harry-hhj，Github主页：传送门第二作者：E-T-E-R-N-A-L-B-L-U-E，传送门" }, { "title": "RM 教程 3 —— OpenCV 传统视觉", "url": "/posts/RM-Tutorial-3-Getting-Started-with-OpenCV/", "categories": "Course, RM", "tags": "getting started, robomaster, opencv", "date": "2021-10-02 18:05:00 +0800", "snippet": "RM 教程 3 —— OpenCV 传统视觉 机械是血肉，电控是大脑，视觉是灵魂。本片教程主要集中于边缘及轮廓检测。一、OpenCV 基本组件 - MatMat 是 OpenCV 中常用的基本类型，即矩阵类。在计算机内存中，数字图像以矩阵的形式存储和运算，因此 OpenCV 中常常用 Mat 储存图像数据。Mat 本质上由两个数据部分组成：矩阵头和一个指向像素数据的指针。矩阵头部的大小是恒定的。然而，矩阵本身的大小因图像的不同而不同。这一数据结构的好处是： Mat 的每个对象具有其自己的头，但可通过矩阵指针指向同一地址让两个实例之间共享该矩阵。除非你明确指明需要复制数据，不然 Mat 只会复制矩阵头部，并将数据指针指向同一地址，而不会复制矩阵本身。1）构造函数Mat 常用的构造方式有两种： Mat() ：这种 Mat 由于未定义维度和大小，无法直接使用，一般用来接收函数的输出，被重新赋值 Mat (int rows, int cols, int type) ：创建一个行数为 rows ，列数为 cols ，数据类型为 type 的矩阵。 type ：CV_[位数][有无符号][数据类型][通道数] ，对于图片值一般为 CV_8UC3 ，其中 8U 代表 8 位无符号整数， C3 代表 3 通道，这是一般用来储存 3 通道图像的格式。当然 type 还有很多其他类型，例如 CV_64FC1 表示一般的实数矩阵。 2）初始化初始化一个矩阵有两种方式：等号赋值或 create() 成员函数 。cv::Mat src = imread(&quot;logo.png&quot;);cv::Mat src;if (src.empty()) { src.create(3, 3, CV_8UC3); // 这种方法创建的内存空间一定是连续的}3）成员变量和函数比较常用的获取矩阵信息的变量和函数有：cv::Mat src1(3, 3, CV_8UC3);std::cout &amp;lt;&amp;lt; src1.cols &amp;lt;&amp;lt; std::endl; // 图片行数：3std::cout &amp;lt;&amp;lt; src1.rows &amp;lt;&amp;lt; std::endl; // 图片列数：3std::cout &amp;lt;&amp;lt; src1.channels() &amp;lt;&amp;lt; std::endl; // 图片通道数，注意是成员函数：34）拷贝通过下面这个例子，你会很容易理解为什么当我们想复制数据时必须显示指明：cv::Mat src2(4, 4, CV_8UC3);std::cout &amp;lt;&amp;lt; &quot;Pointer src2.data points to&quot; &amp;lt;&amp;lt; (void*)src2.data &amp;lt;&amp;lt; std::endl;cv::Mat src2_copy1 = src2;std::cout &amp;lt;&amp;lt; &quot;Pointer src2_copy1.data points to&quot; &amp;lt;&amp;lt; (void*)src2_copy1.data &amp;lt;&amp;lt; std::endl;cv::Mat src2_copy2 = src2.clone();std::cout &amp;lt;&amp;lt; &quot;Pointer src2_copy2.data points to&quot; &amp;lt;&amp;lt; (void*)src2_copy2.data &amp;lt;&amp;lt; std::endl;程序运行结果：可以看到通过等号赋值的 src2_copy1 的指针与 src2 指向同一片内存地址，这意味着对任意一个变量的操作会影响另一个，而通过使用 clone() ，系统为新的变量 src_copy2 创建了一块新的内存空间，并把原始变量拷贝了过去。除了 clone() 外，成员函数 copyto(cv::Mat dst) 也有相同的效果。TODO：refcount5）格式化输出使用 std::cout 来格式化输出 Mat 类型的变量，仅限于二维的。cv::Mat src3 = cv::Mat::zeros(5, 5, CV_64F);// 默认格式std::cout &amp;lt;&amp;lt; src3 &amp;lt;&amp;lt; std::endl;// python 格式std::cout &amp;lt;&amp;lt; cv::format(src3, cv::Formatter::FMT_PYTHON) &amp;lt;&amp;lt; std::endl;// C 格式std::cout &amp;lt;&amp;lt; cv::format(src3, cv::Formatter::FMT_C) &amp;lt;&amp;lt; std::endl;// numpy 格式std::cout &amp;lt;&amp;lt; cv::format(src3, cv::Formatter::FMT_NUMPY) &amp;lt;&amp;lt; std::endl;输出结果如下：6）矩阵的随机访问Mat 类型本身没有实现 [] 的随机访问，因此如果想要随机访问矩阵中的元素，需要其他方法。 Mat 提供了 at 方法，其声明如下： template&amp;lt;typename _Tp &amp;gt;_Tp&amp;amp; cv::Mat::at(int row, int col) 通过 at 方法，可以随机访问 row 行 col 列的元素，下面是一个简单的例子： cv::Mat src4 = cv::Mat::eye(3, 3, CV_8UC1);src4.at&amp;lt;uint8_t&amp;gt;(1, 1) = static_cast&amp;lt;uint8_t&amp;gt;(2);std::cout &amp;lt;&amp;lt; src4 &amp;lt;&amp;lt; std::endl; 从结果可以看出，第 1 行 1 列的元素从 $1$ 变成了 $2$ ： Mat 类提供的 ptr 方法也可以借助指针的方式实现随机访问，其声明如下： uchar* cv::Mat::ptr(int i0 = 0) 通过 ptr 方法，可以返回矩阵第 i0 行的指针，通过指针进一步访问矩阵的元素，下面是一个 简单的例子： cv::Mat src5 = cv::Mat::eye(3, 3, CV_8UC1);uchar *ptr = src5.ptr(1);ptr[1] = 2;std::cout &amp;lt;&amp;lt; src5 &amp;lt;&amp;lt; std::endl; 从结果可以看出，该代码达到了和 at() 一样的效果： 7）Mat 简单运算 复制 clone() 为什么要使用 clone() 而不能使用 = 在上面已经讲过了，这里举个例子让读者直观感受两种操作的不同： cv::Mat src6 = cv::Mat::eye(3, 3, CV_8UC1);cv::Mat src6_copy1 = src6;cv::Mat src6_copy2 = src6.clone();src6.at&amp;lt;uint8_t&amp;gt;(1, 1) = 5;std::cout &amp;lt;&amp;lt; &quot;src6_copy1:\\n&quot; &amp;lt;&amp;lt; src6_copy1 &amp;lt;&amp;lt; std::endl;std::cout &amp;lt;&amp;lt; &quot;src6_copy2:\\n&quot; &amp;lt;&amp;lt; src6_copy2 &amp;lt;&amp;lt; std::endl; 结果是 = 复制的矩阵 src6_copy1 被同时修改，而通过 clone() 复制的 src6_copy2 没有变化： 如果想要安全地复制，使用 OpenCV 提供的矩阵复制函数。 + 、 - 、 * + OpenCV中重载了矩阵的 + 运算符，同时有 virtual void cv::MatOp::add(const MatExpr &amp;amp;expr1, const MatExpr &amp;amp;expr2, MatExpr &amp;amp;res) 方法实现了加法运算。 - OpenCV中重载了矩阵的 - 运算符，同时有 virtual void cv::MatOp::subtract(const MatExpr &amp;amp;expr1, const MatExpr &amp;amp;expr2, MatExpr &amp;amp;res) 方法实现了减法运算。 * OpenCV中重载了矩阵的 * 运算符，对应矩阵乘法。而 void cv::multiply(const MatExpr &amp;amp;expr1, const MatExpr &amp;amp;expr2, MatExpr &amp;amp;res) 函数实现的是矩阵的对应位数据相乘，而不是矩阵乘法。 cv::Mat src7 = cv::Mat::eye(2, 2, CV_64FC1);cv::Mat src8 = (cv::Mat_&amp;lt;double&amp;gt;(2, 2) &amp;lt;&amp;lt; 1, 1, 1, 1);std::cout &amp;lt;&amp;lt; &quot;src7 * src8 = \\n&quot; &amp;lt;&amp;lt; src7 * src8 &amp;lt;&amp;lt; std::endl;cv::Mat res;cv::multiply(src7, src8, res);std::cout &amp;lt;&amp;lt; &quot;cv::multiply(src7, src8, res) = \\n&quot; &amp;lt;&amp;lt; res &amp;lt;&amp;lt; std::endl; 最终两种运算的结果是不同的： 8）读写图片和视频OpenCV 中提供了函数 Mat cv::imread(const String &amp;amp;filename, int flags = IMREAD_COLOR) 实现从指定文件中读取图片，通过函数 cv::imwrite(const String &amp;amp;location, const cv::Mat &amp;amp;src) 实现。OpenCV 中提供了 VideoCapture 类完成读取视频的工作。cv::VideoCapture cap(PROJECT_DIR&quot;/assets/test.avi&quot;);assert(cap.isOpened());std::cout &amp;lt;&amp;lt; (int)cap.get(cv::CAP_PROP_FRAME_HEIGHT) &amp;lt;&amp;lt; &quot; &quot; &amp;lt;&amp;lt; (int)cap.get(cv::CAP_PROP_FRAME_WIDTH) &amp;lt;&amp;lt; std::endl;cv::VideoWriter writer(PROJECT_DIR&quot;/assets/test_copy.avi&quot;, cv::VideoWriter::fourcc(&#39;M&#39;, &#39;J&#39;, &#39;P&#39;, &#39;G&#39;), 10, {(int)cap.get(cv::CAP_PROP_FRAME_WIDTH), (int)cap.get(cv::CAP_PROP_FRAME_HEIGHT)}, true);cv::Mat src10;cv::namedWindow(&quot;video&quot;);std::cout &amp;lt;&amp;lt; &quot;press q to exit.&quot; &amp;lt;&amp;lt; std::endl;while (cap.read(src10)) { cv::imshow(&quot;video&quot;, src10); writer.write(src10); // writer &amp;lt;&amp;lt; src10; char k = cv::waitKey(200); if (k == &#39;q&#39;) break;}cv::destroyWindow(&quot;video&quot;);cap.release();writer.release();二、为什么要做边缘检测大多数图像处理软件的最终目的都是识别与分割。识别即“是什么”，分割即“在哪里”。而为了将目标物体从图片中分割出来，如果这个物体有着鲜明的特征，使得目标物体和背景有着极大的区分度（如黑暗中的亮点，大面积的色块），我们就可以比较容易的将这个物体提取出来。因为现在的目标物体和背景有着极大的区分度，也就意味着目标和背景有着明显的“分界线”，也就是边缘；而多个连续的边缘点，就构成了这个物体的轮廓。所以我们可以将检测物体这个任务，转换为检测物体和背景的分界线，也就是边缘检测。三、如何进行边缘检测在进行边缘检测之前，我们首先需要明确，我们想对图像中的哪种信息进行边缘检测。一般来讲，我们会对图像的亮度信息进行边缘检测，也就是在单色灰度图上检测边缘，此时检测到的边缘点是亮度变化较大的点。但有的时候，目标和背景的亮度差异不大，没法通过亮度边缘确定目标和背景的分界线；但目标和背景的颜色差异可能很大，这时就会对图像的颜色信息进行边缘检测，此时检测到的边缘点就是颜色变化最大的点。在确定了我们想检测怎样的边缘后，我们就需要一个方法把边缘给找出来。下面介绍几个常用的方法（假设我们现在是要检测亮度边缘）为了进行对一个图片的亮度进行判断，我们需要把一个 RGB 图片转成灰度图片，转换后越亮的像素点越接近白色（255），而越暗的像素点越接近黑色（0），图像由三通道变为单通道。其原理是：RGB 值和灰度的转换，实际上是人眼对于彩色的感觉到亮度感觉的转换，这是一个心理学问题，有一个公式：\\(Grey = 0.299*R + 0.587*G + 0.114*B\\)可以通过将浮点数运算转化为整数运算，整数运算转换为位操作进行优化。在 OpenCV 中，提供了 cv::cvtColor() 函数完成各种颜色空间的转换：void cv::cvtColor(cv::InputArray src, cv::OutputArray dst, int code, int dstCn = 0); 例如对于下面这张图片：我们通过以下代码将其转化为灰度图：cv::Mat img = cv::imread(PROJECT_DIR&quot;/assets/apple.jpg&quot;);cv::Mat gray;cv::cvtColor(img, gray, cv::COLOR_BGR2GRAY);cv::imshow(&quot;gray&quot;, gray);cv::waitKey(0);有另一种方法是在读如图片时指定读取灰度图，但是由于其实用性较低，不与赘述。1）二值化由于目标和背景的亮度差异很大，那么最简单的想法就是设定一个阈值，亮度高于该阈值的像素设为目标，亮度低于该阈值的像素设为背景。而这两片区域的交界处便是边缘。再特殊一点：目标的亮度不一定就是很高，或者很低，而是在一个范围内（如100~150），此时我们的二值化就和上面有一定的区别，将这两个阈值范围内的像素设为目标，不在该范围内的设为边缘。更进一步：二值化指的是一个函数 f(x) ，其自变量是某个像素的亮度值，其因变量（或者说函数的输出）是 $255$ 或 $0$ ，分别代表目标和背景。在 OpenCV 中，对应实现这一功能的函数是：double cv::threshold(InputArray src, OutputArray dst, double thresh, double maxval, int type)参数： src：输入 dst：输出 thres：设定的二值化阈值 maxval：使用 THRESH_BINARY 或 THRESH_BINARY_INV 进行二值化时使用的最大值 type：二值化算法类型 THRESH_BINARY：将小于 thres 的值变为 0 ，大于 thres 的值变为 255 THRESH_BINARY_INV：将小于 thres 的值变为 255, 大于 thres 的值变为 0 THRESH_TRUNC：将大于 thres 的值截取为 thres, 小于 thres 的值不变 THRESH_TOZERO：将小于 thres 的值变为 0 , 大于 thres 的值不变 THRESH_TOZERO_INV：将大于 thres 的值变为 0 , 小于 thres 的值不变 举个例子，现在我们需要将这样一种图进行二值化，提取其中棋盘格黑色的区域：我们用下面这段程序实现了这一功能：可以看到我们很好地提取出了黑色的部分。2） 自适应二值化1. 全局自适应由于图片的亮度很容易受到环境的影响，比如环境亮度不同，相机曝光不同等因素都可能影响到最终成像出来的图片的亮度。这样，原本在较亮环境下设定的 180 的亮度阈值可以较好和分割出目标，到了较暗环境下效果就变差，甚至完全不起作用了。但是环境对成像图片亮度的影响是整体的，也就是说整张图片一起变亮或者一起变暗，原本比背景亮的目标物体，在较暗环境下同样应该比背景亮。基于这一点，我们可以提出一个简易的自适应二值化方法：对图像所有像素的亮度值进行从大到小排序，取前 20%（该数值为人为设定的阈值参数）的像素作为目标，其余为背景。OpenCV 中常用的方法有 大津二值化 方法。对于之前提到的函数 threshold() ，当 type = cv::THRESH_OTSU 时，参数 thresh 无效，具体数值由大津法自行计算，并在函数的返回值中返回。下面是一个使用 大津法 计算 thresh 的例子。double thres = cv::threshold(src, binary_img, 100, 255, cv::THRESH_OTSU);程序运行的结果与手动设定阈值的结果相似。但是设定单一阈值的方法仍然有明显的缺点，对于一张图中有明显的光线亮度渐变的图像，单一阈值往往难以起到好的效果。2. 局部自适应例如下图这张图片，左侧的亮度明显高于右下角：如果使用大津法自动求阈值并直接二值化，会得到类似下图的结果：为了解决这种问题，我们需要对每个区域局部适应区域内的灰度情况，对每个区域使用不同的阈值分别二值化。 OpenCV 中提供了 adaptiveThreshold 方法实现这一功能。函数的声明如下：void cv::adaptiveThreshold(InputArray src, OutputArray dst, double maxValue, int adaptiveMethod, int thresholdType, int blockSize, double C)其中： adaptiveMethod 为自适应二值化算法使用的方法； blockSize 为自适应二值化的算子大小，注意必须为奇数； C 为用来手动调整阈值的偏置量大小。自适应二值化算法的运行结果如下：3） 基于梯度的边缘在上述全局的方法中，通过一个阈值将整张图片分为两个部分，而两部分的交界处就作为边缘。这样的一个做法还有另一个缺点，如果图像中有一片区域亮度从低逐渐过渡到高，二值化同样会把这片区域分为两块。即，二值化得出的边缘，并不一定是图像中亮度变化最大（或较大）的地方。由于目标和背景亮度差异较大，所以交界处一定是图像中亮度变化最大（或较大）的地方。为了解决该问题，还可以使用基于梯度的边缘。二值化和梯度检测是两种不同的方法。其基本思想是：首先计算图片中每个像素点的亮度梯度大小（一般使用Sobel算子），然后设定一个阈值，梯度高于该阈值的作为边缘点。同样，类似与自适应二值化，这个阈值也可以设定成一个比值。在实际使用中，我们通常会使用 Canny 算法进行基于梯度的边缘检测，这个算法中做了很多额外措施，使得边缘检测的效果较好。OpenCV 中 Canny 算法的函数声明如下：void cv::Canny(InputArray image, OutputArray edges, double threshold1, double threshold2, int apertureSize = 3, bool L2gradient = false)对于下面这张图：我们使用下面的程序进行梯度边缘检测：cv::Mat task3_img = cv::imread(PROJECT_DIR&quot;/assets/energy.jpg&quot;, cv::IMREAD_GRAYSCALE);cv::Mat task3_result;cv::Canny(task3_img, task3_result, 125, 225, 3);cv::imshow(&quot;task3_canny&quot;, task3_result);cv::waitKey(0);程序的结果是：4）补充：检测颜色边缘在上面几种方法中，我们都是进行亮度边缘检测，亮度边缘检测有一个明显的特征，即每个像素的亮度都可以用一个数值进行表达。但当我们想进行颜色边缘检测时，我们似乎并不能用一个数值来表达该像素的颜色差异，必须使用 RGB 三通道数值才能表达一个像素的颜色。首先，在 RGB 颜色表示方法中，每个颜色分量都包含了该像素点的颜色信息和亮度信息。我们希望对 RGB 颜色表示进行一个变换，使得像素点的颜色信息和亮度信息可以独立开来。为此，我们可以使用 HSV 颜色空间。hsv 六棱锥在 HSV 颜色空间中， H 分量代表色度，即该像素是哪种颜色； S 分量代表饱和度； V 分量代表亮度（和光强度之间并没有直接的联系）。这种颜色表示方法很好地将每个像素的颜色、饱和度和亮度独立开。至于 RGB 颜色空间如何转换为 HSV 颜色空间，这里不作介绍，有兴趣可以自行百度。有了 HSV 颜色空间，由于其 H 通道就代表了像素的颜色，我们就可以在 H 通道上使用上述几种边缘检测方式，从而得出颜色边缘。以下是几种常见颜色的 hsv 阈值，每种颜色对应 HSV 空间中的一块区域，在各通道上呈现一个或两个区间：这些数值可以作为调参的一个初值。OpenCV 提供了 inRange() 函数完成区间的筛选：void cv::inRange(InputArray src, InputArray lowerb, InputArray upperb, OutputArray dst)其中 lowerb 和 upperb 分别对应 HSV 空间中坐标范围的下界和上界。如果需要提取多个 HSV空间范围中的颜色，那么需要执行多次 inRange 并将得到的颜色取并集。我们以下图为例：我们想要提取的颜色为红色和橙色的区域，通过百度搜索，我们了解到红色和橙色的颜色在 HSV 空间中处于区间 $[(0, 43, 46), (255, 255, 255)] \\cup [(156, 43, 46), (180, 255, 255)]$ 中。cv::Mat task4_img = cv::imread(PROJECT_DIR&quot;/assets/energy.jpg&quot;);cv::Mat task4_hsv;cv::cvtColor(task4_img, task4_hsv, cv::COLOR_BGR2HSV);cv::Mat task4_hsv_part1, task4_hsv_part2;cv::inRange(task4_hsv, cv::Scalar(0, 43, 46), cv::Scalar(25, 255, 255), task4_hsv_part1);cv::inRange(task4_hsv, cv::Scalar(156, 43, 46), cv::Scalar(180, 255, 255), task4_hsv_part2); // 提取红色和橙色cv::Mat task4_ones_mat = cv::Mat::ones(cv::Size(task4_img.cols, task4_img.rows), CV_8UC1);cv::Mat task4_hsv_result = 255 * (task4_ones_mat - (task4_ones_mat - task4_hsv_part1 / 255).mul(task4_ones_mat - task4_hsv_part2 / 255));// 对hsv_part1的结果和hsv_part2的结果取并集cv::imshow(&quot;hsv&quot;, task4_hsv_result);cv::waitKey(0);程序结果如下：当然， HSV 颜色提取虽然是一种非常优秀的二值化方法，但他也存在自己的局限性。例如亮度的变化会对 HSV 数值造成干扰。同时，在实际使用过程中，如果相机的感光元件敏感度较高，也会造成图像中出现噪点，形成椒盐噪声。此外，在感光角度不同时，相机获取到的颜色饱和度和色相也会发生一定程度的变化，造成 HSV空洞 。这里我们顺便提供一段 HSV 的调参界面代码：void HSV_calib(const cv::Mat img, int *thres, int mode) { // mode: 0 for red; 1 for green; 2 for blue; cv::Mat imgHSV; cv::cvtColor(img, imgHSV, cv::COLOR_BGR2HSV); cv::namedWindow(&quot;Control&quot;, cv::WINDOW_AUTOSIZE); //create a window called &quot;Control&quot; thres[0] = (mode == 0) ? 156 : ((mode == 1) ? 100 : 35); thres[1] = (mode == 0) ? 180 : ((mode == 1) ? 140 : 70); thres[2] = (mode == 0) ? 43 : ((mode == 1) ? 90 : 43); thres[3] = (mode == 0) ? 255 : ((mode == 1) ? 255 : 255); thres[4] = (mode == 0) ? 46 : ((mode == 1) ? 90 : 43); thres[5] = (mode == 0) ? 255 : ((mode == 1) ? 255 : 255); //Create trackbars in &quot;Control&quot; window cv::createTrackbar(&quot;LowH&quot;, &quot;Control&quot;, &amp;amp;thres[0], 179); //Hue (0 - 179) cv::createTrackbar(&quot;HighH&quot;, &quot;Control&quot;, &amp;amp;thres[1], 179); cv::createTrackbar(&quot;LowS&quot;, &quot;Control&quot;, &amp;amp;thres[2], 255); //Saturation (0 - 255) cv::createTrackbar(&quot;HighS&quot;, &quot;Control&quot;, &amp;amp;thres[3], 255); cv::createTrackbar(&quot;LowV&quot;, &quot;Control&quot;, &amp;amp;thres[4], 255); //Value (0 - 255) cv::createTrackbar(&quot;HighV&quot;, &quot;Control&quot;, &amp;amp;thres[5], 255); std::vector&amp;lt;cv::Mat&amp;gt; hsvSplit; //因为我们读取的是彩色图，直方图均衡化需要在HSV空间做 cv::split(imgHSV, hsvSplit); cv::equalizeHist(hsvSplit[2], hsvSplit[2]); cv::merge(hsvSplit, imgHSV); cv::Mat imgThresholded; while (true) { cv::inRange(imgHSV, cv::Scalar(thres[0], thres[2], thres[4]), cv::Scalar(thres[1], thres[3], thres[5]), imgThresholded); //Threshold the image //开操作 (去除一些噪点) cv::Mat element = getStructuringElement(cv::MORPH_RECT, cv::Size(5, 5)); cv::morphologyEx(imgThresholded, imgThresholded, cv::MORPH_OPEN, element); //闭操作 (连接一些连通域) cv::morphologyEx(imgThresholded, imgThresholded, cv::MORPH_CLOSE, element); cv::imshow(&quot;Thresholded Image&quot;, imgThresholded); //show the thresholded image cv::imshow(&quot;Original&quot;, img); //show the original image char key = (char) cv::waitKey(300); if (key == 27) { cv::destroyWindow(&quot;Control&quot;); break; } else continue; }}四、边缘检测的后处理不论是使用二值化、还是自适应二值化、还是基于梯度的边缘检测方法，其检测结果都不可能正好分毫不差的将目标完整保留下来，并将背景完全剔除。即使图像质量极佳，或者目标特征极为明显，使得正好将目标和背景区分开，检测结果也还停留于像素层面，即每个像素是目标还是背景，而我们想要的则是目标在哪片区域。所以后处理的目的主要有三个：剔除错误的背景边缘、补充缺失的目标边缘、将目标表达成一个区域。对于前两点，我们通常会首先使用开闭运算处理二值化图或边缘图（取决于之前你采用的策略）。其中开运算连接断开区域，闭运算删除游离的噪声区域。详细算法的计算方式，这里不作介绍，有兴趣可以自行百度。图像滤波亦能达到类似的效果。对于第三点，我们会使用轮廓检测。轮廓可以理解为一系列连通的边缘点，并且这些边缘点可以构成一个闭合曲线。1）滤波滤波通常是对二值化方法使用的。在对现实中的图像进行二值化时，二值化的结果往往难以达到最佳状态。许多情况下，二值化会产生空洞或形成噪点。在这种情况下就需要滤波和形态学运算这两大工具来提升二值化结果的质量。滤波类似于卷积，有一个叫做算子的东西处理图像的局部特征。在开始之前，我们本节中的所有实例会针对以下图片进行。下面介绍几个比较常用的滤波算法。1. 均值滤波均值滤波是最简单的滤波，也被成为线性平滑滤波。其算子可以表达为：\\(K = \\cfrac{1}{\\text{ksize.width} \\times \\text{ksize.height}}\\begin{bmatrix}1&amp;amp;1&amp;amp;\\cdots&amp;amp;1\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\1&amp;amp;1&amp;amp;\\cdots&amp;amp;1\\\\\\end{bmatrix}\\)即对大小为 $M \\times N$的矩形框内的像素取平均值。OpenCV 中对应的函数是：void cv::blur(InputArray src, OutputArray dst, Size ksize, Point anchor = Point(-1,-1), int borderType = BORDER_DEFAULT)对例子中的图片应用均值滤波：cv::Mat blured_img;cv::blur(img, task5_blured_img, cv::Size(7, 7));结果如下中值滤波的效果是使得图片更加模糊，削弱噪声的边缘梯度，使其看起来不那么显著，但是噪声本身并没有得到很好的消除，同时有用的信息也被削弱了。均值滤波是最快速的滤波算法之一，但同时它的效果却也不够理想，一般无法有效地去除椒盐噪声。2. 高斯滤波高斯滤波通过对图像卷积高斯滤波算子实现滤波的效果。高斯算子如下：\\(G(x, y) = \\cfrac{1}{2\\pi\\rho^2} e^{-c\\frac{x^2+y^2}{2\\rho^2}}\\)例如这就是一个高斯算子：\\(\\frac{1}{16} \\times \\begin{bmatrix}1&amp;amp;2&amp;amp;1\\\\2&amp;amp;4&amp;amp;2\\\\1&amp;amp;2&amp;amp;1\\\\\\end{bmatrix}\\)高斯算子的思想是：有用的信息会以一定的数量聚在一起，而噪声是随机游离的；最中间的信息对于该位数据最有用，但也应当考虑边缘信息的影响。OpenCV 中对应的函数是：void cv::GaussianBlur(InputArray src, OutputArray dst, Size ksize, double sigmaX, double sigmaY = 0, int borderType = BORDER_DEFAULT)其中 ksize 为高斯算子的大小 sigmaX 和 sigmaY 为高斯函数在 x 和 y 方向上的偏置对例子中的图片应用高斯滤波：cv::Mat gaussian_blured_img;cv::GaussianBlur(src, gaussian_blured_img, cv::Size(7, 7), 0, 0);结果如下可以看到虽然结果的噪声仍然很大，但图像在平滑效果和特征保留上相对均值滤波都有一定的提升，例如边缘信息更加明显一些。3. 中值滤波中值滤波与前两者最大的不同在于，均值滤波和高斯滤波均为线性滤波，而中值滤波为非线性滤波。非线性滤波相对于线型滤波，往往都有更好的滤波效果，但代价是会有远高于线型滤波的时间开销。中值滤波是基于排序统计理论的一种能有效抑制噪声的非线性信号处理技术，基本原理是把数字图像或数字序列中一点的值用该点的一个邻域中各点值的中值代替，让周围的像素值接近的真实值，从而消除孤立的噪声点。中值滤波对于滤除脉冲干扰及图像扫描噪声最为有效，还可以克服线性滤波器（如邻域简单平滑滤波）带来的图像细节模糊。中值滤波算子不易用公式描述，总结如下：用某种结构的二维滑动模板，将板内像素按照像素值的大小进行排序，生成单调上升（或下降）的为二维数据序列。二维中值滤波输出为 $g(x,y)=med{f(x-k,y-l),\\ k,l \\in W}$ ，其中 $f(x,y)$ ， $g(x,y)$ 分别为原始图像和处理后图像。 $W$ 为二维模板，通常为 $3\\times3$ ， $5\\times5$ 区域，也可以是不同的的形状，如线状、圆形、十字形圆、环形等。对例子中的图片应用中值滤波：cv::Mat median_blured_img;cv::medianBlur(src, median_blured_img, 7);结果如下可以看到中值滤波在去除椒盐噪声上有着良好的表现，但在信息的保存上劣于高斯滤波。中值滤波不仅对孤立杂点的消除效果显著，对稍密集的杂点也有很好的去除效果。2）形态学处理形态学处理一般处理二值图像。结构元（Structuring Elements）：一般有矩形和十字形。结构元有一个锚点 O ，O 一般定义为结构元的中心。下图是几个不同形状的结构元，紫红色块为锚点 O 。常见的形态学运算有腐蚀、膨胀、开闭，常用于中击不中变换、边界提取和跟踪、区域填充、提取连通分量、细化和像素化， 以及凸壳。OpenCV 中构造结构元的函数是cv::Mat getStructuringElement(int shape, cv::Size esize, cv::Point anchor = Point(-1, -1));参数： shape ：内核的形状，有三种形状可以选择 cv::MORPH_RECT ：矩形 cv::MORPH_CROSS ：交叉形 cv::MORPH_ELLIPSE ：椭圆形 为了增强例子的可展示性，下面的例子中都采用了大结构元，但平时我们一般不会用那么大。cv::Mat element = cv::getStructuringElement(cv::MORPH_CROSS, cv::Size(21, 21));膨胀 Dilation将结构元 $s$ 在图像 $f$ 上滑动，把结构元锚点位置的图像像素点的灰度值设置为结构元值为1的区域对应图像区域像素的最大值。膨胀运算示意图如下，从视觉上看图像中的前景仿佛“膨胀”了一样：OpenCV 中的实现函数是void dilate(InputArray src, OutputArray dst, InputArray kernel, Point anchor=Point(-1,-1), int iterations=1, int borderType=BORDER_CONSTANT, const Scalar&amp;amp; borderValue=morphologyDefaultBorderValue());对中值滤波的结果图进行膨胀：cv::Mat task7_src = task5_median_blured_img.clone();cv::Mat element = cv::getStructuringElement(cv::MORPH_CROSS, cv::Size(21, 21));cv::Mat task7_dilated;cv::dilate(task7_src, task7_dilated, element);cv::imshow(&quot;dilate&quot;, task7_dilated);cv::waitKey(0);效果如下：腐蚀 Erosion将结构元 $s$ 在图像 $f$ 上滑动，把结构元锚点位置的图像像素点的灰度值设置为结构元值为 1 的区域对应图像区域像素的最小值。腐蚀运算示意图如下，从视觉上看图像中的前景仿佛被“腐蚀”了一样：OpenCV 中的实现函数是void erode(InputArray src, OutputArray dst, InputArray kernel, Point anchor=Point(-1,-1), int iterations=1, int borderType=BORDER_CONSTANT, const Scalar&amp;amp; borderValue=morphologyDefaultBorderValue());对中值滤波的结果图进行膨胀：cv::Mat task7_src = task5_median_blured_img.clone();cv::Mat task7_eroded;cv::erode(task7_src, task7_eroded, element);cv::imshow(&quot;eroded&quot;, task7_eroded);cv::waitKey(0);效果如下：开运算 Opening对图像 $f$ 用同一结构元 $s$ 先腐蚀再膨胀称之为开运算。开运算示意图如下，从视觉上看仿佛将原本连接的物体“分开”了一样：开运算能够除去孤立的小点，毛刺和小桥，而总的位置和形状不便。OpenCV 中的实现函数是void morphologyEx(InputArray src, OutputArray dst, int op, InputArray kernel, Point anchor=Point(-1,-1), int iterations=1, int borderType=BORDER_CONSTANT, const Scalar&amp;amp; borderValue=morphologyDefaultBorderValue());参数： op ：表示形态学运算的类型 MORPH_OPEN – 开运算（Opening operation） MORPH_CLOSE – 闭运算（Closing operation） MORPH_GRADIENT - 形态学梯度（Morphological gradient） MORPH_TOPHAT - 顶帽（Top hat） MORPH_BLACKHAT - 黑帽（Black hat） 对中值滤波的结果图进行膨胀：cv::Mat task7_src = task5_median_blured_img.clone();cv::Mat task7_opened;cv::morphologyEx(task7_src, task7_opened, cv::MORPH_OPEN, element);cv::imshow(&quot;open&quot;, task7_opened);cv::waitKey(0);效果如下：闭运算 Closing对图像 $f$ 用同一结构元 $s$ 先膨胀再腐蚀称之为闭运算。开运算示意图如下，从视觉上看仿佛将原本分开的部分“闭合”了一样：闭运算能够填平小湖（即小孔），弥合小裂缝，而总的位置和形状不变。OpenCV 中的实现函数同开运算。对中值滤波的结果图进行膨胀：cv::Mat task7_src = task5_median_blured_img.clone();cv::Mat task7_closed;cv::morphologyEx(task7_src, task7_closed, cv::MORPH_CLOSE, element);cv::imshow(&quot;close&quot;, task7_closed);cv::waitKey(0);效果如下：其他下面提供一段比较实用的代码，通过以下代码，你可以轻松地去除二值图中大于或者小于某一面积的区域而不需要进行轮廓提取：// CheckMode: 0 代表去除黑区域， 1 代表去除白区域; NeihborMode： 0 代表 4 邻域， 1 代表 8 邻域;void RemoveSmallRegion(cv::Mat &amp;amp;Src, cv::Mat &amp;amp;Dst, int AreaLimit, int CheckMode, int NeihborMode) { int RemoveCount = 0; // 记录除去的个数 // 记录每个像素点检验状态的标签， 0 代表未检查， 1 代表正在检查， 2 代表检查不合格（需要反转颜色）， 3 代表检查合格或不需检查 cv::Mat Pointlabel = cv::Mat::zeros(Src.size(), CV_8UC1); if (CheckMode == 1) {// std::cout &amp;lt;&amp;lt; &quot;Mode: 去除小区域. &quot;; for (int i = 0; i &amp;lt; Src.rows; ++i) { uchar *iData = Src.ptr&amp;lt;uchar&amp;gt;(i); uchar *iLabel = Pointlabel.ptr&amp;lt;uchar&amp;gt;(i); for (int j = 0; j &amp;lt; Src.cols; ++j) { if (iData[j] &amp;lt; 10) { iLabel[j] = 3; } } } } else {// std::cout &amp;lt;&amp;lt; &quot;Mode: 去除孔洞. &quot;; for (int i = 0; i &amp;lt; Src.rows; ++i) { uchar *iData = Src.ptr&amp;lt;uchar&amp;gt;(i); uchar *iLabel = Pointlabel.ptr&amp;lt;uchar&amp;gt;(i); for (int j = 0; j &amp;lt; Src.cols; ++j) { if (iData[j] &amp;gt; 10) { iLabel[j] = 3; } } } } std::vector&amp;lt;cv::Point2i&amp;gt; NeihborPos; // 记录邻域点位置 NeihborPos.push_back(cv::Point2i(-1, 0)); NeihborPos.push_back(cv::Point2i(1, 0)); NeihborPos.push_back(cv::Point2i(0, -1)); NeihborPos.push_back(cv::Point2i(0, 1)); if (NeihborMode == 1) {// std::cout &amp;lt;&amp;lt; &quot;Neighbor mode: 8 邻域.&quot; &amp;lt;&amp;lt; std::endl; NeihborPos.push_back(cv::Point2i(-1, -1)); NeihborPos.push_back(cv::Point2i(-1, 1)); NeihborPos.push_back(cv::Point2i(1, -1)); NeihborPos.push_back(cv::Point2i(1, 1)); } // else std::cout &amp;lt;&amp;lt; &quot;Neighbor mode: 4 邻域.&quot; &amp;lt;&amp;lt; std::endl; int NeihborCount = 4 + 4 * NeihborMode; int CurrX = 0, CurrY = 0; // 开始检测 for (int i = 0; i &amp;lt; Src.rows; ++i) { uchar *iLabel = Pointlabel.ptr&amp;lt;uchar&amp;gt;(i); for (int j = 0; j &amp;lt; Src.cols; ++j) { if (iLabel[j] == 0) { //********开始该点处的检查********** std::vector&amp;lt;cv::Point2i&amp;gt; GrowBuffer; // 堆栈，用于存储生长点 GrowBuffer.push_back(cv::Point2i(j, i)); Pointlabel.at&amp;lt;uchar&amp;gt;(i, j) = 1; int CheckResult = 0; // 用于判断结果（是否超出大小），0为未超出，1为超出 for (int z = 0; z &amp;lt; GrowBuffer.size(); z++) { for (int q = 0; q &amp;lt; NeihborCount; q++) //检查四个邻域点 { CurrX = GrowBuffer.at(z).x + NeihborPos.at(q).x; CurrY = GrowBuffer.at(z).y + NeihborPos.at(q).y; if (CurrX &amp;gt;= 0 &amp;amp;&amp;amp; CurrX &amp;lt; Src.cols &amp;amp;&amp;amp; CurrY &amp;gt;= 0 &amp;amp;&amp;amp; CurrY &amp;lt; Src.rows) // 防止越界 { if (Pointlabel.at&amp;lt;uchar&amp;gt;(CurrY, CurrX) == 0) { GrowBuffer.push_back(cv::Point2i(CurrX, CurrY)); // 邻域点加入buffer Pointlabel.at&amp;lt;uchar&amp;gt;(CurrY, CurrX) = 1; // 更新邻域点的检查标签，避免重复检查 } } } } if (GrowBuffer.size() &amp;gt; AreaLimit) CheckResult = 2; //判断结果（是否超出限定的大小），1为未超出，2为超出 else { CheckResult = 1; RemoveCount++; } for (int z = 0; z &amp;lt; GrowBuffer.size(); z++) //更新Label记录 { CurrX = GrowBuffer.at(z).x; CurrY = GrowBuffer.at(z).y; Pointlabel.at&amp;lt;uchar&amp;gt;(CurrY, CurrX) += CheckResult; } //********结束该点处的检查********** } } } CheckMode = 255 * (1 - CheckMode); //开始反转面积过小的区域 for (int i = 0; i &amp;lt; Src.rows; ++i) { uchar *iData = Src.ptr&amp;lt;uchar&amp;gt;(i); uchar *iDstData = Dst.ptr&amp;lt;uchar&amp;gt;(i); uchar *iLabel = Pointlabel.ptr&amp;lt;uchar&amp;gt;(i); for (int j = 0; j &amp;lt; Src.cols; ++j) { if (iLabel[j] == 2) { iDstData[j] = CheckMode; } else if (iLabel[j] == 3) { iDstData[j] = iData[j]; } } }// std::cout &amp;lt;&amp;lt; RemoveCount &amp;lt;&amp;lt; &quot; objects removed.&quot; &amp;lt;&amp;lt; std::endl;}五、轮廓提取不论是使用二值化还是边缘检测，最终得到的结果都是一个二值化了的图片，不论其中的点是表示物体信息还是边缘信息，我们都需要知道可能的目标的位置。因此它们最后都会被转化为轮廓，因为对这种边缘信息我们才能分析它的几何和拓扑特征。OpenCV 中提供了轮廓提取函数：void cv::findContours(InputArray image, OutputArrayOfArrays contours, OutputArray hierarchy, int mode, int method, Point offset = Point())其中： mode ： RETR_EXTERNAL：只列举外轮廓 RETR_LIST：用列表的方式列举所有轮廓 RETR_TREE：用列表的方式列举所有轮廓 用树状的结构表示所有的轮廓，在这种模式下会在 hierachy 中记录轮廓 hierachy：对于每一个轮廓， hierarchy 都包含 4 个整型数据，分别表示：后一个轮廓的序号、前一个轮廓的序号、子轮廓的序号、父轮廓的序号。 method ： CHAIN_APPROX_NONE ：绝对的记录轮廓上的所有点 CHAIN_APPROX_SIMPLE ：记录轮廓在上下左右四个方向上的末端点(轮廓中的关键节点) 下面演示如何使用 RETR_TREE 模式按照拓扑关系画出所有轮廓：void dfs(cv::Mat &amp;amp;drawer, const std::vector&amp;lt; std::vector&amp;lt;cv::Point&amp;gt; &amp;gt; &amp;amp;contours, const std::vector&amp;lt; cv::Vec4i &amp;gt; &amp;amp;hierachy, const int &amp;amp;id, const int &amp;amp;depth) { if (id == -1) return; static cv::Scalar COLOR_LIST[3] = { {220, 20, 20}, {20, 220, 20}, {20, 20, 220} }; cv::drawContours(drawer, contours, id, COLOR_LIST[depth % 3], 1); for (int i = hierachy[id][2]; i + 1; i = hierachy[i][0]) { dfs(drawer, contours, hierachy, i, depth + 1); // 向内部的子轮廓递归 }}cv::Mat src = cv::imread(PROJECT_DIR&quot;/assets/energy.jpg&quot;);cv::Mat hsv;cv::cvtColor(src, hsv, cv::COLOR_BGR2HSV); // 将颜色空间从BGR转为HSVcv::Mat hsv_part1, hsv_part2;cv::inRange(hsv, cv::Scalar(0, 43, 46), cv::Scalar(25, 255, 255), hsv_part1);cv::inRange(hsv, cv::Scalar(156, 43, 46), cv::Scalar(180, 255, 255), hsv_part2); // 提取红色和橙色cv::Mat ones_mat = cv::Mat::ones(cv::Size(src.cols, src.rows), CV_8UC1);cv::Mat hsv_result = 255 * (ones_mat - (ones_mat - hsv_part1 / 255).mul(ones_mat - hsv_part2 / 255)); // 对hsv_part1的结果和hsv_part2的结果取并集std::vector&amp;lt;std::vector&amp;lt;cv::Point&amp;gt;&amp;gt; contours;std::vector&amp;lt;cv::Vec4i&amp;gt; hierachy;cv::findContours(hsv_result, contours, hierachy, cv::RETR_TREE, cv::CHAIN_APPROX_NONE);cv::Mat drawer = cv::Mat::zeros(cv::Size(src.cols, src.rows), CV_8UC3);for (int i = 0; i + 1; i = hierachy[i][0]) dfs(drawer, contours, hierachy, i, 0); // 遍历所有轮廓cv::imshow(&quot;src&quot;, src);cv::imshow(&quot;contours&quot;, drawer);cv::waitKey(0);实现效果如图：六、筛选仅仅使用开闭运算，对三个目标中的前两点的改善十分有限，为了进一步从大量边缘中找到目标边缘，我们在进行完轮廓提取后，还会进行形状筛选。即根据目标的形状信息，剔除形状不正确的的轮廓（这里的形状同样包括大小等各种目标独特的特征）。形状筛选的方式通常有：计算轮廓面积、计算最小外接矩形、椭圆拟合、多边形拟合等。更准确地说，我们对提取出的轮廓使用先验信息和分类器进行筛选，从而找到我们所需要的目标。具体使用什么方法是和目标有关的。下面列举几个常用轮廓筛选的手段：1）面积/周长大小约束面积/周长大小约束是最简单的约束之一，即通过轮廓所包含区域的大小或是轮廓的周长大小筛选指定的轮廓。这种方法虽然简单粗暴，但对于一些环境干扰小的简单环境往往能够取得相当不错的效果。下面是一个简单的例子：bool judgeContourByArea(const std::vector&amp;lt;cv::Point&amp;gt; &amp;amp;contour){ if (cv::contourArea(contour) &amp;gt; 2000) // 舍弃小轮廓 return true; return false;}它对能量机关的轮廓提取如图：这种方法简单高效，但也尤其缺点，确定是鲁棒性低，容易受干扰，对于每一个场景往往需要针对输入调参后才能使用。2）轮廓凹凸性约束这种方法能通过轮廓的凹凸性对凹轮廓或凸轮廓进行有针对性的筛选。一般来说可以通过将轮廓的凸包与轮廓本身进行比较来实现。常用的比较方法有： 面积比例比较 对于凸轮廓，轮廓的凸包面积与轮廓本身的面积比应该接近 $1:1$ ，而一般的凹轮廓的比值应该明显大于 $1$ 。 周长比值比较 一般来说，对于凸轮廓，轮廓的凸包周长和轮廓本身的周长相近，而凹轮廓的轮廓本身周长应当明显大于凸包周长。 下面是一个简单的例子，筛选轮廓中的凹轮廓：bool judgeContourByConvexity(const std::vector&amp;lt;cv::Point&amp;gt; &amp;amp;contour){ if (contourArea(contour) &amp;lt; 500) // 去除过小轮廓的干扰 return false; double hull_area, contour_area; std::vector&amp;lt;cv::Point&amp;gt; hull; cv::convexHull(contour, hull); hull_area = cv::contourArea(hull); contour_area = cv::contourArea(contour); if (hull_area &amp;gt; 1.5 * contour_area) // 判断凹凸性 return true; return false;}它对能量机关的提取如图：3）与矩形相似性约束在轮廓筛选时常常会需要筛选一些较规则的形状，如矩形轮廓等。在这种情况下，一般来说我们可以通过将轮廓的最小外接矩形与轮廓本身进行比较来实现筛选。常见的筛选方法与凹凸性约束相似，也是通过面积和周长比较来实现。此外，由于矩形的特殊性，也可以通过矩形的长宽比进行筛选。下面是一个简单的例子，筛选能量机关的装甲板轮廓：bool judgeContourByRect(const std::vector&amp;lt;cv::Point&amp;gt; &amp;amp;contour){ if (cv::contourArea(contour) &amp;lt; 500) // 排除小轮廓的干扰 return false; double rect_area, contour_area, rect_length, contour_length; cv::RotatedRect rect = cv::minAreaRect(contour); rect_area = rect.size.area(); contour_area = cv::contourArea(contour); if (rect_area &amp;gt; 1.3 * contour_area) // 轮廓面积约束 return false; rect_length = (rect.size.height + rect.size.width) * 2; contour_length = cv::arcLength(contour, true); if (std::fabs(rect_length - contour_length) / std::min(rect_length, contour_length) &amp;gt; 0.1) // 轮廓周长约束 return false; if (std::max(rect.size.width, rect.size.height) / std::min(rect.size.width, rect.size.height) &amp;gt; 1.9) // 长宽比约束 return false; return true;}运行结果如图：以上几种方法是主要的几种基于单个轮廓本身几何性质的筛选方法，下面介绍几种轮廓间几何关系的约束。4）拓扑关系约束在一张复杂的图片中，轮廓中往往有各种复杂的拓扑关系。例如一个轮廓，它的拓扑关系可能有以下几种主要性质： 是否是最外层轮廓 是否是最内层轮廓 是否有子轮廓 子轮廓的个数是多少 它是谁的子轮廓 ……例如当我们想筛选未被激活的装甲板，我们会发现他有两个拓扑关系： 它是最外层轮廓 它有一个子轮廓再或者我们想筛选已经被激活的装甲板，我们会发现他也有连个拓扑关系： 它是最外层子轮廓 它有三个子轮廓下面是一个简单的例子，筛选已经被激活的装甲板：bool judgeContourByTuopu(const std::vector&amp;lt;cv::Vec4i&amp;gt; &amp;amp;hierachy, const int &amp;amp;id, const int &amp;amp;dep){ if (dep != 0) // 判断是否是最外层轮廓 return false; int cnt = 0; for (int i = hierachy[id][2]; i+1; i = hierachy[i][0]) // 子轮廓计数 cnt++; if (cnt != 3) // 判断子轮廓个数是否为3 return false; return true;}运行结果如图：5）通过与其他轮廓的几何关系判断这种方法整体上灵活多变，要根据具体情况选择具体方法，整体的思想是通过与另一个已知轮廓（也可能未知）的几何关系进行筛选。这里以筛选已激活装甲板中的空白区域为例：观察发现，已激活装甲板中的空白区域为一个接近矩形的四边形，其中的长边与扇叶的最小外接矩形的长边有着接近垂直的几何关系。而在上一问中，我们已经筛选出了已激活装甲板，因此这里我们可以利用这一性质完成空白区域的筛选。下面是一个简单的例子：bool judgeContourByRelation(const std::vector&amp;lt;std::vector&amp;lt;cv::Point&amp;gt;&amp;gt; &amp;amp;contours, const std::vector&amp;lt;cv::Vec4i&amp;gt; &amp;amp;hierachy, const int &amp;amp;id, const int &amp;amp;dep){ if (!(hierachy[id][3] + 1)) // 去除最外层轮廓 return false; if (dep != 1) // 判断是否是第二层轮廓 return false; if (!judgeContourByTuopu(hierachy, hierachy[id][3], dep - 1)) // 判断外轮廓是否为已激活扇叶 return false; cv::RotatedRect rect_father = cv::minAreaRect(contours[hierachy[id][3]]); cv::RotatedRect rect_this = cv::minAreaRect(contours[id]); cv::Point2f direction_father; cv::Point2f direction_this;// 寻找父轮廓最小外接矩形的短边 cv::Point2f pts[4]; rect_father.points(pts); double length1 = std::sqrt((pts[0].x - pts[1].x) * (pts[0].x - pts[1].x) + (pts[0].y - pts[1].y) * (pts[0].y - pts[1].y)); double length2 = std::sqrt((pts[2].x - pts[1].x) * (pts[2].x - pts[1].x) + (pts[2].y - pts[1].y) * (pts[2].y - pts[1].y)); if (length1 &amp;lt; length2) direction_father = {pts[1].x - pts[0].x, pts[1].y - pts[0].y}; else direction_father = {pts[2].x - pts[1].x, pts[2].y - pts[1].y}; // 寻找当前轮廓最小外接矩形的长边 rect_this.points(pts); length1 = std::sqrt((pts[0].x - pts[1].x) * (pts[0].x - pts[1].x) + (pts[0].y - pts[1].y) * (pts[0].y - pts[1].y)); length2 = std::sqrt((pts[2].x - pts[1].x) * (pts[2].x - pts[1].x) + (pts[2].y - pts[1].y) * (pts[2].y - pts[1].y)); if (length1 &amp;gt; length2) direction_this = {pts[1].x - pts[0].x, pts[1].y - pts[0].y}; else direction_this = {pts[2].x - pts[1].x, pts[2].y - pts[1].y};// 计算[父轮廓最小外接矩形的短边]与[当前轮廓最小外接矩形的长边]夹角的余弦值 double cosa = (direction_this.x * direction_father.x + direction_this.y * direction_father.y) / std::sqrt(direction_this.x * direction_this.x + direction_this.y * direction_this.y) / std::sqrt(direction_father.x * direction_father.x + direction_father.y * direction_father.y); std::cout &amp;lt;&amp;lt; cosa &amp;lt;&amp;lt; std::endl; if (std::fabs(cosa) &amp;gt; 0.1) // 筛选不符合条件的轮廓 return false; return true;}运行结果如图：对于轮廓筛选的部分就介绍到这里，传统视觉的奥妙远不止于此。以上内容有一部分是笔者的个人总结，并不一定是主流方法。读者可以在实践中慢慢探索，寻找自己的传统视觉的思路。六、传统视觉原则传统方法一般不怕多，就怕少。多出来的加上分类器总有办法筛选掉，但少的就没办法补上了。因此，及时你想得到一个完美的结果，也不应该将阈值设置到一个非常严苛的程度，不然算法的鲁棒性将收到影响。七、总结对于传统图像处理，我们有两种方式，一种基于二值化，一种基于边缘检测。不论哪种方法，我们之后需要对图像进行滤波或形态学处理，在更佳的图像上进行轮廓提取，最后根据轮廓的几何性质等设置分类器提取出我们想要的目标。八、作业链接: https://pan.baidu.com/s/1S94gVEPPdB1m4mwlFA7ImA 提取码: 49w9 苹果识别，请识别下图中的苹果 识别链接中两个视频中的能量机关，框出亮起扇叶的顶部矩形块位置 如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！九、参考文献 opencv中mat详细解析 【Opencv】Opencv中的Mat类介绍 OpenCV中HSV颜色模型及颜色分量范围 图像处理中常见的形态学方法 opencv getStructuringElement函数 opencv中的开运算，闭运算，形态学梯度，顶帽和黑帽简介 opencv 形态学变换 morphologyEx函数 Opencv–形态学图像处理–膨胀与腐蚀，开操作与闭操作作者列表： xinyang，Github主页：传送门 E-T-E-R-N-A-L-B-L-U-E，传送门 Harry-hhj，Github主页：传送门" }, { "title": "RM 教程 2 —— 安装 OpenCV", "url": "/posts/RM-Tutorial-2-Install-OpenCV/", "categories": "Course, RM", "tags": "getting started, robomaster, opencv", "date": "2021-10-02 13:30:00 +0800", "snippet": "RM 教程 2 —— 安装 OpenCV 机械是血肉，电控是大脑，视觉是灵魂。一、简介OpenCV 是计算机视觉中经典的专用库，其支持多语言，跨平台，功能强大。 opencv-python 为OpenCV 提供了 Python 接口，使得使用者在 Python 中能够调用 C/C++ ，在保证易读性和运行效率的前提下，实现所需的功能。OpenCV 现在支持与计算机视觉和机器学习有关的多种算法，并且正在日益扩展。OpenCV 支持多种编程语言，例如 C++、 Python 、 Java 等，并且可以在 Windows 、 Linux 、 OS X 、 Android 和 IOS 等不同平台上使用。基于 CUDA 和 OpenCL的高速GPU操作的接口也在积极开发中。二、快速安装注意：仅适合新手，队员参与实际项目时还请按照【三】完成安装。C++打开终端，输入以下命令：sudo apt-get install libopencv-dev python-opencv libopencv-contrib-dev以 Clion IDE 为例，配置 toolchains ，如下图所示。需要说明的是： 如果你的 cmake 是系统自带的，那么 cmake 路径选择 /usr/bin/cmake ，如果是编译安装的，那么选择 /usr/local/bin/cmake 。示例代码：链接: https://pan.baidu.com/s/1MDLwgGJ57cG3NfxDAfZASg 提取码: cph8测试方式：点击 IDE 右上角运行或命令行进入项目目录：mkdir buildcmake ..make./example如果出现一张苹果的图片表示安装成功。Python打开终端，输入以下命令：pip install opencv-python opencv-contrib-python -i https://pypi.tuna.tsinghua.edu.cn/simple如果你有 conda 环境的话，可以先创建一个新的环境：conda env listconda create -n opencv python=3.9conda activate opencv以 Pycharm IDE 为例，如果非系统默认的环境，请记得配置项目设置-python 解释器的路径，例如 conda 环境的解释器路径一般都为 ``//envs//bin/python3` 。示例代码：链接: https://pan.baidu.com/s/1AlPkGtZ-4HkRjhwuFB86eQ 提取码: v7dj测试方法：点击 IDE 右上角运行或者命令进入项目目录# 如果有 conda 环境记得先激活python3 main.py如果出现一张苹果的图片表示安装成功。p.s. ：这篇教程讲述了如何编译安装。三、备注Clion 和 Pycharm 的安装教程在对应的安装包中都有提供，这里给出申请学生免费账号的方法。首先进入官方申请网站，选择 For students and teachers 下的 learn more ，用自己的学校邮箱申请，然后打开邮箱内的确认邮件。然后创建自己的 JetBrains Account ，在软件安装完之后的 activate 过程中输入账号密码就可以使用了。注意：目前交大邮箱只能通过人工认证的方式验证。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "RM 教程 1 —— Linux 教程", "url": "/posts/RM-Tutorial-1-Linux-Introduction/", "categories": "Course, RM", "tags": "getting started, robomaster, ubuntu", "date": "2021-09-24 16:00:00 +0800", "snippet": "RM 教程 1 —— Linux 教程 机械是血肉，电控是大脑，视觉是灵魂。一、Why Linux &amp;amp; Why UbuntuUbuntu 是一个十分流行并且好用的 Linux 桌面发行版本。截止到目前，Ubuntu 已经发行了 Ubuntu 20.04 的版本，并且其稳定性和支持已经很不错了。你可以在这里下载各个版本的 Ubuntu 系统镜像文件，虚拟机的话一般下载桌面版本。常言道，不要重复造轮子。在实际大型项目的开发过程中，总是不可避免的会使用到大量的第三方库，而一旦用到第三方库，就不可避免的会遇到依赖的问题，这个问题在编写 C/C++ 程序的时候尤为明显。在 Windows 下使用 Visual Studio 开发 C++ 程序时，每创建一个工程都必须不厌其烦地挨个设置每个第三方库的头文件目录、库文件目录、以及库文件名。这样的事情是极为繁琐的。这时使用 Ubuntu 系统和 Cmake ，可以让你感受到无与伦比的遍历。所以，使用 Ubuntu 系统的第一个好处就是开发环境配置方便。然而 Linux 的桌面发行版层出不穷，为何偏偏要采用 Ubuntu 呢？这是因为 Ubuntu 作为最受欢迎的 Linux 桌面发行版之一，几乎所有软件包都会原生支持在 Ubuntu 上的安装，同时由于使用的人多，社区很广，遇到问题在网络上也总能搜索到 Ubuntu 下的解决方法。想象一下，如果安装一个不太热门的 Linux 发行版，想在上面安装 CUDA （一个极为流行的 GPU 编程库），然而官方没有原生支持，自行安装过程中的各种坑，在网络上又难以搜索到，这将会是一件多么令人恼火的事情。总之，视觉部推荐使用 Ubuntu 20.04 系统作为基本的开发环境。二、Ubuntu 基础知识网上有比较全面的 Ubuntu 入门介绍，这里不做过多的介绍，重点说一下实际使用过程中最为经常使用到的地方。1. Ubuntu 硬盘与文件目录结构区别于 Windows 系统，每个硬盘分区单独一个盘符，不同分区间相互独立，Linux 下所有硬盘分区要么直接作为根目录，要么是根目录下的一个子目录。如 硬盘分区 1 挂载到根目录，即：/ 硬盘分区 2 挂载到根目录的子目录，如：/data在没有其他挂载的情况下，目录 / ，下面的所有文件（除了目录 /data ）都是保存在硬盘分区 1 中。而目录 /data ，下面的所有文件都是保存在硬盘分区 2 中。2. Ubuntu 常用文件目录及其作用 /home ：该目录下保存不同账户的用户文件。假如你的 Ubuntu 有一个叫 user 的账户，那么 /home/user 下就保存着 user 账户的用户文件。如果还有一个叫 foo 的账户，那么 /home/foo 下就保存着 foo 账户的用户文件。 /root ：该目录下保存着 root 账户的用户文件。root 账户是 Ubuntu 中的一个特殊账户，拥有最高读写权限，类似与 Windows 中的管理员。 /etc ：该目录下保存着各种软件的配置信息。 /usr ：该目录下通常保存用户安装的各个软件、开发包等。 /proc ：该目录下都是虚拟文件，用于监控系统的运行状态。 /dev ：该目录下也是虚拟文件，用于保存各个设备驱动。 /mnt ：该目录下通常保存外部存储设备。如 U 盘等设备，通常可以在该目录下访问。3. Ubuntu 账户账户相当于是标记了这台电脑的不同使用者，当多人公用一台电脑时，可以通过不同账户来划分权限，这种情况在服务器上最为常见，因为服务器通常都会有很多个用户。但在个人电脑上，则通常仅有一个账户。每个账户，可以属于一个或多个组，就好比将多个同类的用户归为一类，同样是方便进行权限管理。4. Ubuntu 权限管理这里的权限包括文件权限和用户权限。通常来说，一个文件有 9 个权限可以设置，而这 9 个权限可以分为 3 类，分别是文件所有者权限，组权限和其他用户权限。其中这三类中，每类都包含 3 个权限，即读、写、执行，分别简写为 r 、 w 、x 。由于读、写、执行可以用 3 个二进制比特表示，所以这三个权限可以用一个 八进制数表示，而一共有 3 类权限，所以一个文件的权限可以由三个八进制数表示。我们可以使用命令 ls -l 来查看当前目录下所有文件的权限。我们可以通过 chmod 命令修改文件的权限，基本用法是 chmod &amp;lt;权限&amp;gt; &amp;lt;文件名&amp;gt; ，比如 chmod 755 ./run 。在上面我们提到，一个文件的权限可以由 3 个八进制数表示，这里就是一个典型的例子。由于有权限限制，在默认的用户权限下，我们通常只能修改目录 /home 下对应用户文件夹里的文件，而其他地方的文件都是无法修改的。为了获取修改任意文件的权限，我们可以使用 sudo 命令。该命令会使得用户获得临时的 root 权限，也就是类似于 Windows 下的管理员权限。这时我们就可以修改那些原本不能修改的文件了。注意：如果使用 sudo 命令创建文件，创建出的文件的所有者将是 root 用户，也就是意味着在用户权限下不能修改它。所以，非必要情况下，尽量不使用 sudo 命令。5. APT 包管理工具apt 是 Ubuntu 中的一个软件，负责管理系统中安装的各类软件包，开发包。包括但不限于安装：可执行软件、开发库（头文件，链接库等）、运行库（动态链接库）。其基本命令有：apt search &amp;lt;包名&amp;gt; # 搜索某个包apt update # 更新包数据库apt upgrade # 升级包apt install &amp;lt;包名&amp;gt; # 安装某个包apt remove &amp;lt;包名&amp;gt; # 删除某个包主要常用的命令就是上面几个。由于apt安装的包，默认并不是安装到用户目录，也就是意味着在安装/删除包时，需要 root 权限。所以，实际使用 apt 命令时还需要在前面加上 sudo 。三、常用 Linux 命令请读者进入 Ubuntu 系统，并打开终端： 方式一：按下 Command 键，搜索 Terminal ，回车 方式二：Ctrl + Alt + T ，这个快捷键和系统打开方式有关，比如原生系统、虚拟机，还和电脑键盘有关一个新打开的终端应该如下图所示，从现在开始你应该适应一个只有字符组成的世界。你会发现你刚进入时，你的默认工作目录是 ~ ，即 /home/&amp;lt;username&amp;gt; ，不信你可以验证一下：1. pwdpwd你会发现输出是 /home/&amp;lt;username&amp;gt; 。这时你希望进入到文档的目录，于是你需要用到：2. cdcd ~/Documents仔细观察，左侧的路径已经改变了。那么在这个文件夹里存在什么呢？我们可以这样查看：3. lsls打印出的结果如下图。如果你的系统是新的，那么你可能看不到任何结果。这空空如也的目录，我们改如何放入我们的东西呢？4. mkdirmkdir demo我们创建一个 demo 目录，用于存放以后要用的文件。我们进入此目录中：cd demo此时我们有一个想法需要记录，我们需要创建一个 test.txt 文件。5. touchtouch test.txtls 看一下，此时文件已经创建好了，那么我们怎么输入我们的想法呢？6. geditgedit test.txt注意 gedit 与其说是一个命令，不如说是一个软件。我们会打开一个图形化编辑窗口，在其中随意输入内容，保存并关闭。那么我们刚刚的操作是否成功， test.txt 中是否存在了我们希望的内容呢？当然可以再次打开文件，但我们有更简单的方式：7. catcat test.txt在终端会输出文件内容，而无需图形化界面。我们再次编辑刚刚的文件，将内容修改为：#include &amp;lt;iostream&amp;gt;int main() { std::cout &amp;lt;&amp;lt; &quot;Hello!&quot; &amp;lt;&amp;lt; std::endl; return 0;}保存并关闭。这是一个 C++ 文件，但此时文件的后缀不太正确，我们先将文件重命名：8. mvmv test.txt test.cppls 看一下，文件名称已经改变了。注意， mv 的本意是移动文件，但是当移动前后位置相同，且指定了移动后的名字时，我们可以将其用于重命名。此时我们编译它：g++ test.cpp -o test产生了可执行文件 test 。运行它，但我们希望把结果记录下来：9. &amp;gt;./test &amp;gt; test.log程序输出被重定向到了 test.log 中，不信你 cat test.log 看看是不是这样的。好了，看到效果后，我们已经不需要这些文件了，于是我们可以删掉它们了。10. rmrm test.logls 看一下 test.log 已经被删除了，但一个个删太麻烦了，我们来点更快的：rm -rf *此时会把当前目录下的所有东西都删除（慎用，或许我不该教你的）。Tips：如果你想偷懒复制粘贴，但又对 Ubuntu 不熟悉，或许我该提示你一般在终端中复制的快捷键是 shift+crtl+c ，粘贴的快捷键是 shfit+ctrl+v ，而 ctrl+c 其实是终止。这里旨在让读者熟悉 RM 日常需求中高频使用的命令，更多命令用法请查看这篇教程。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：唐欣阳，github主页：传送门第二作者：Harry-hhj，github主页：传送门" }, { "title": "RoboMaster 课程目录", "url": "/posts/RM-Tutorial-Catalogue/", "categories": "Course, RM", "tags": "catalog", "date": "2021-09-23 00:00:00 +0800", "snippet": "RM Tutorial Catalogue 机械是血肉，电控是大脑，视觉是灵魂。一、培训安排本课程依据由基础到复杂以及技术点难易设置，课程局限在 RM 比赛中所必须要知道的知识点，项目的功利性强，旨在帮助新队员快速掌握核心技能参与项目研发。学习最好的方式就是动手实践，看完一本书的作用并不比你做一个项目强，尤其是对比赛而言！建议观看者依据教程顺序接受课程，并按照要求完成课后作业。依据学生的时间安排，以下课程以一周一节的进度展开。课程包括以下技术点： Ubuntu 系统简单介绍、环境搭建 OpenCV 传统视觉思路简介 摄像机成像原理、相机畸变与相机内参、相机标定 四个坐标系介绍、基于 PNP 的单目定位、仿射变换与透视变换 三角形法则与双目视觉、特征点匹配 卡尔曼滤波介绍、ceres 库介绍 神经网络简介、trt 加速二、培训教程 RM 教程 1 —— Linux 教程 RM 教程 2 —— 安装 OpenCV RM 教程 3 —— OpenCV 传统视觉 RM 教程 4 —— 相机 RM 教程 5 —— 单目视觉如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "Linux Commands", "url": "/posts/Linux-Commands/", "categories": "Tutorial, Linux", "tags": "tools, linux", "date": "2021-09-22 22:00:00 +0800", "snippet": "Linux 常用命令一、目录 命令 意义 shutdown （立即/定时）关机，重启 poweroff 立即关机 reboot 立即重启 man 帮助 cd 进入目录 ls 枚举目录 mkdir 创建目录 rm 删除目录/文件 mv 移动目录/文件，重命名 cp 拷贝目录/文件 touch 新建目录/文件 rm 删除目录/文件 vi/vim 命令行操作文件 cat 查看文件 more 分页查看文件 less 随意查看文件 tail 查看文件尾部，适用实时更新 chmod 改变目录/文件权限 chown 改变拥有者 tar 打包/解包/压缩/解压 grep 搜索过滤 find 递归搜索 locate 搜索路径 whereis 命令路径 which 命令位置 su 用户切换 sudo 单次 root 权限 service 配置服务 chkconfig 开机自启 crontab 定时任务 pwd 打印当前路径 ps 查看进程信息 kill 杀死进程 ifconfig 查看网卡配置 ping 查看连接情况 netstat 查看端口 clear 清空输出 &amp;gt; 重定向符 | 管道 二、基本命令1. 关机shutdown or poweroffshutdown -h now # 立即关机shutdown -h 5 # 5 分钟后关机poweroff # 立即关机2. 重启shutdown or rebootshutdown -r now # 立即重启shutdown -r 5 # 5 分钟后重启reboot # 立即重启3. 帮助--help or manshutdown --helpman shutdown # 打开命令说明书之后，使用按键 q 退出三、目录操作1. 切换cd [&amp;lt;destination&amp;gt;]cd / # 切换到根目录cd /usr # 切换到根目录下的 usr 目录cd .. # 切换到上级目录cd ~ # 切换到 home 目录cd # 同上cd - # 切换到上次访问的目录2. 查看ls [-al] [&amp;lt;target&amp;gt;]ls # 查看当前目录下的所有目录和文件ls -a # 查看当前目录下的所有目录和文件（包含隐藏文件）ls -l # 查看当前目录下的所有目录和文件（列表，包含更多信息）ll # 同上ls /usr # 查看指定目录 /usr 下的所有目录和文件3. 增删改查1) 创建目录mkdir &amp;lt;folder_name&amp;gt;mkdir aaa # 在当前目录下创建一个名为 aaa 的目录mkdir /usr/aaa # 在指定目录 /usr 下创建一个名为 aaa 的目录2) 删除目录rm [-rf] &amp;lt;target&amp;gt;为了方便实用你可以一直带上 -rf 参数，不管你的对象是目录还是压缩包还是文件。rm -r aaa # 递归删除当前目录下的 aaa 目录，有些文件会询问是否确认删除rm -rf aaa # 递归删除当前目录下的 aaa 目录，不询问# 以下命令务必慎用！！！rm -rf * # 将当前目录下的所有目录和文件全部删除rm -rf /* # 将根目录下的所有文件全部删除（只是为了让你明白后果，你不可能会用到这个命令的！）3) 目录复制/移动mv &amp;lt;source&amp;gt; &amp;lt;destination&amp;gt;除了移动之外，还具有重命名的效果。mv &amp;lt;old_path/folder_or_file&amp;gt; &amp;lt;new_path&amp;gt; # 将 folder_or_file 从 &amp;lt;old_path&amp;gt; 移动到 &amp;lt;new_path&amp;gt;mv aaa bbb # 将目录/文件 aaa 重命名为 bbbcp [-r] &amp;lt;source&amp;gt; &amp;lt;destination&amp;gt;cp &amp;lt;path/of/file&amp;gt; &amp;lt;target_folder&amp;gt; # 将文件 &amp;lt;path/of/file&amp;gt; 拷贝到 &amp;lt;target_folder&amp;gt;cp -r &amp;lt;path/of/folder&amp;gt; &amp;lt;target_path&amp;gt; # 将目录 &amp;lt;path/of/folder&amp;gt; 拷贝到 &amp;lt;target_path&amp;gt;4) 搜索目录find &amp;lt;folder&amp;gt; &amp;lt;opt&amp;gt; &amp;lt;param&amp;gt;find /usr/tmp -name &#39;a*&#39; # 查找 /usr/tmp 目录下的所有以 a 开头的目录或文件四、文件操作1. 增删该查1) 新建文件touch &amp;lt;name&amp;gt;touch a.txt # 在当前目录下新建 a.txt 文件touch a # 在当前目录下新建 a 目录2) 删除文件rm [-f] &amp;lt;name&amp;gt;rm &amp;lt;file&amp;gt; # 删除文件 filerm -f &amp;lt;file&amp;gt; # 删除文件 file 且不询问3) 修改文件vi or vimvi &amp;lt;file_name&amp;gt;vim &amp;lt;file_name&amp;gt;基本上 vi 可以分为三种状态： 命令模式 Command mode ：控制屏幕光标的移动，字符、字或行的删除，查找，移动复制某区段 光标移动 $\\leftarrow$ 、 $\\rightarrow$ 、 $\\uparrow$ 、$\\downarrow$ ，分别对应 h 、l 、 k 、 j 删除当前行： dd 查找： /&amp;lt;string&amp;gt; 进入编辑模式： i ：在光标所在字符前开始插入 a ：在光标所在字符后开始插入 o ：在光标所在行的下面另起一新行插入 进入底行模式： : 插入模式 Insert mode ：只有在插入模式下才能做文字输入 回到命令模式：[ESC] 底行模式 last line mode ：将文件保存或退出，也可以设置编辑环境，如寻找字符串、列出行号等 退出： :q 强制退出： :q! 保存并退出： :wq 注意只有命令模式才能随意进入其他两种模式。4) 查看文件cat or more or less or tailcat /etc/bash.bashrc # 一次性显示文件全部内容more /etc/bash.bashrc # 以一页一页的形式显示文件，按 b 后退，按 space 前进less /etc/bash.bashrc # 随意浏览文件，支持翻页和搜索tail -10 /etc/bash.bashrc # 显示 /etc/bash.bashrc 的最后 10 行tail -f &amp;lt;filename&amp;gt; # 把 filename 文件里的最尾部的内容显示在屏幕上，并且不断刷新，适用于查阅正在改变的日志文件2. 修改权限Linux 下的权限类型有三种： r 代表可读， w 代表可写， x 代表该文件是一个可执行文件， - 代表不可读或不可写或不可执行文件。Linux 下的权限粒度有三类： User 、 Group 、 Other 。 User 表示某一登陆用户， Group 表示和 User 同组的其他用户，其他用户都属于 Other 。举个例子，公司的一个员工是 User ，公司的同事就是 Group ，而公司之外的人就是 Other 。在 Linux 中一般用 10 个字符表示一个文件/目录的权限，格式如下：【表示文件类型，d 表示是目录，l 是符号链接文件】-/d/s/p/l/b/c | 【User 的权限】-rwx/-rwx/-rwx ｜ 【Group 的权限】-rwx/-rwx/-rwx ｜ 【Other 的权限】-rwx/-rwx/-rwx例如下图中，红色部分表示 vim.txt 是一个文件， User 和 Group 可读可写，但不可执行，Group 可读，但不可修改删除、不可执行。补充知识：权限也可以用数字来表示，成为 8421 表示法。规则是 $\\text r = 4, \\text w = 2, \\text x = 1$ ，如上图中可以表示为 $664$ 。补充知识：附加权限位。chmod or chown [-R] user[:group] filechmod u+x a.txt # 仅 User 追加执行权限chmod a+x a.txt # 所有用户追加执行权限chmod 100 a # 仅 User 可执行 a ，所有人不可读不可修改chown tom:users file d.key # 设置文件 d.key 的拥有者设为 users 群体的 tomchown -R James:users * # 设置当前目录下与子目录下的所有文件的拥有者为 users 群体的 James五、压缩/解压1. 打包压缩Linux 中的打包文件的后缀为 .tar ，压缩文件的后缀为 .gz ，打包并压缩的文件后缀为 .tar.gz 。tar [-zcvf]参数说明： z ：调用 gzip 压缩命令进行压缩 c ：打包 v ：显示运行过程 f ：指定文件名tar -cvf &amp;lt;target.tar&amp;gt; &amp;lt;sources&amp;gt; # 仅打包不压缩 &amp;lt;sources&amp;gt; 的全部文件及目录，生成 &amp;lt;target.tar&amp;gt;tar -zcvf &amp;lt;target.tar.gz&amp;gt; &amp;lt;sources&amp;gt; # 打包 &amp;lt;sources&amp;gt; 中的全部文件及目录，并压缩为 &amp;lt;target.tar.gz&amp;gt;2. 解压tar [-zxvf] &amp;lt;target&amp;gt;参数说明： z ：调用 gzip 压缩命令进行解压 x ：解包 v ：显示运行过程 f ：指定文件名 -C ：指定解压的位置tar -xvf &amp;lt;source.tar&amp;gt; # 将 &amp;lt;source.tar&amp;gt; 解压到当前目录下tar -xvf &amp;lt;source.tar&amp;gt; -C &amp;lt;destination&amp;gt; # 将 &amp;lt;source.tar&amp;gt; 解压到指定目录 &amp;lt;destination&amp;gt; 下六、查找1. grep强大的文本搜索工具ps -ef | grep sshd | grep -v grep # 查找指定服务进程，排除gerp身ps -ef | grep sshd # -c 查找指定进程个数grep &amp;lt;file&amp;gt; -E [-v] &amp;lt;regex&amp;gt; # 在文件 file 中查找包含 regex 的行并输出， -v 表示不包含2. find默认搜索当前目录及其子目录，并且不过滤任何结果（也就是返回所有文件），将它们全都显示在屏幕上。find . -name &quot;*.log&quot; -ls # 在当前目录查找以.log结尾的文件，并显示详细信息。 find /root/ -perm 600 # 查找/root/目录下权限为600的文件 find . -type f -name &quot;*.log&quot; # 查找当目录，以.log结尾的普通文件 find . -type d | sort # 查找当前所有目录并排序 find . -size +100M # 查找当前目录大于100M的文件3. locate让使用者可以很快速的搜寻某个路径。默认每天自动更新一次，可以在使用 locate 之前，先使用 updatedb 命令，手动更新数据库。可能需要先安装命令： apt install mlocate 。locate /etc/sh # 搜索etc目录下所有以sh开头的文件 locate pwd # 查找和 pwd 相关的所有文件4. whereis定位可执行文件、源代码文件、帮助文件在文件系统中的位置。whereis ls # 将和 ls 文件相关的文件都查找出来5. which在 PATH 变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。which pwd # 查找pwd命令所在路径 七、用户切换1. su用于用户之间的切换。但是切换前的用户依然保持登录状态。如果是 root 向普通或虚拟用户切换不需要密码，反之普通用户切换到其它任何用户都需要密码验证。su test # 切换到test用户，但是路径还是/root目录su - test # 切换到test用户，路径变成了/home/testsu # 切换到root用户，但是路径还是原来的路径su - # 切换到root用户，并且路径是/rootexit # 退出返回之前的用户2. sudo为所有想使用root权限的普通用户设计的。可以让普通用户具有临时使用root权限的权利。只需输入自己账户的密码即可。配置文件：sudo vi /etc/sudoerssudo visudo配置案例如下：hadoop ALL=(ALL) ALL # 允许 hadoop 用户以 root 身份执行各种应用命令，需要输入 hadoop 用户的密码hadoop ALL=NOPASSWD: /bin/ls, /bin/cat # 只允许 hadoop 用户以 root 身份执行 ls 、cat 命令，并且执行时候免输入密码八、系统服务service iptables status # 查看 iptables 服务的状态service iptables start # 开启 iptables 服务service iptables stop # 停止 iptables 服务service iptables restart # 重启 iptables 服务 chkconfig iptables off # 关闭 iptables 服务的开机自启动chkconfig iptables on # 开启 iptables 服务的开机自启动九、网络管理1. 主机名配置vi /etc/sysconfig/networkNETWORKING=yesHOSTNAME=node12. IP 地址配置vi /etc/sysconfig/network-scripts/ifcfg-eth03. 域名映射/etc/hosts 文件用于在通过主机名进行访问时做 ip 地址解析之用。所以，你想访问一个什么样的主机名，就需要把这个主机名和它对应的 ip 地址。vi /etc/hosts# 在最后加上192.168.52.201 node1192.168.52.202 node2192.168.52.203 node3十、定时任务crontab [-u &amp;lt;user&amp;gt;] &amp;lt;file&amp;gt; or crontab [-u user] [-e|-l|-r]通过 crontab 命令，可以在固定间隔时间，执行指定的系统指令或 shell 脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。首先你需要先安装 crontab ：apt install crontabs服务操作说明：service crond start # 启动服务 service crond stop # 关闭服务 service crond restart # 重启服务参数说明： [-u &amp;lt;user&amp;gt;] ：用来设定某个用户的 crontab 服务 &amp;lt;file&amp;gt; ：crontab 的任务列表文件 -e ：编辑某个用户的 crontab 文件内容。如果不指定用户，则表示编辑当前用户的 crontab 文件。 -l ：显示某个用户的 crontab 文件内容。如果不指定用户，则表示显示当前用户的 crontab 文件内容。 -r ：删除定时任务配置，从 /var/spool/cron 目录中删除某个用户的 crontab 文件，如果不指定用户，则默认删除当前用户的 crontab 文件。crontab file [-u user] # 用指定的文件替代目前的 crontabcrontab -l [-u user] # 列出用户目前的 crontabcrontab -e [-u user] # 编辑用户目前的 crontab配置： 第 1 列表示分钟 1～59 ，每分钟用 * 或者 */1 表示 第 2 列表示小时 0～23 （ 0 表示 0 点） 第 3 列表示日期 1～31 第 4 列表示月份 1～12 第 5 列标识号星期 0～6 （ 0 表示星期天） 第 6 列要运行的命令# 每分钟执行一次date命令 */1 * * * * date &amp;gt;&amp;gt; /root/date.txt # 每晚的21:30重启apache。 30 21 * * * service httpd restart # 每月1、10、22日的4 : 45重启apache。 45 4 1,10,22 * * service httpd restart # 每周六、周日的1 : 10重启apache。 10 1 * * 6,0 service httpd restart # 每天18 : 00至23 : 00之间每隔30分钟重启apache0,30 18-23 * * * service httpd restart# 晚上11点到早上7点之间，每隔一小时重启apache* 23-7/1 * * * service httpd restart十一、其他1. 重定向&amp;gt; or &amp;gt;&amp;gt; or 2&amp;gt;&amp;amp;1输出重定向到一个文件或设备。ls &amp;gt; a.txt # 将 ls 结果输出到 a.txt 文件echo &quot;This the end of the file.&quot; &amp;gt;&amp;gt; a.txt # 在 a.txt 末尾追加 This the end of the file. 这句话./main 2&amp;gt;&amp;amp;1 main.log # 将 main 运行时的标准输出和标准错误都输出到 main.log 中2. 管道|将一个命令的输入变成另一个命令的输出。find . -type f -readable -regex &#39;.*\\.c\\|.*\\.h&#39; | xargs -I {} grep -c -H &#39;hello&#39; {} # 从当前目录开始递归寻找可读的 .c 和 .h 结尾的文件，查看文件并输出具有 hello 的总行数3. 查看当前路径pwd # 打印出当前路径4. 查看进程ps -ef # 输出所有进程信息5. 结束进程kill [-9] &amp;lt;pid&amp;gt; # 杀死进程号为 pid 的进程， -9 表示强制。6. 网络通信ifconfig # 查看网卡信息，一般用来看 dhcp 的 ip 地址ping &amp;lt;ip&amp;gt; # 查看与机器 &amp;lt;ip&amp;gt; 的连接情况netstat -an # 查看当前系统端口7. 关闭防火墙chkconfig iptables offservice iptables stop8. 清屏clear快捷键： ctrl+l如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！十二、参考资料 Linux常用命令 Linux 命令大全 Linux权限详解（chmod、600、644、666、700、711、755、777、4755、6755、7755） Linux中重定向 Linux Shell管道详解作者：Harry-hhj，github主页：传送门" }, { "title": "Skills about MacOS", "url": "/posts/Skills-about-MacOS/", "categories": "Tutorial, MacOS", "tags": "skills", "date": "2021-09-20 18:40:00 +0800", "snippet": "MacOS 使用技巧开盖自动开机sudo nvram AutoBoot=%00 # 关闭sudo nvram AutoBoot=%03 # 打开从关闭到打开后，会自动打开开机声音。开机声音sudo nvram BootAudio=%00 # 关闭sudo nvram BootAudio=%01 # 打开查看硬盘寿命smartctl -a /dev/disk1设置截图保存位置defaults write com.apple.screencapture location /path/ # 默认~/Desktopdefaults write com.apple.screencapture type jpg # 默认png遇到没有声音的问题打开活动监视器，找到 coreaudiod ，强制退出。SSH public key 存放位置~/.ssh/known_hostsSSH 免 RSA key fingerprint-o &quot;StrictHostKeyChecking no&quot;切换 zsh 和 bash环境变量配置： bash 的环境变量是 .bash_profile 文件 zsh 的环境变量是 .zshrc 文件从一个交互式终端的角度来讲， zsh 更为强大，但是作为脚本解释器， bash 更加符合 posix 标准，因此，建议读者日常使用 zsh （配合 oh-my-zsh ），但是使用 bash 做脚本解释器。chsh -s /bin/zshchsh -s /bin/bash注意不要加 sudo ，此时为切换 root 用户默认解释器。更多关于 zsh 的内容可以查看这篇教程。隐藏终端主机名sudo vim /etc/zshrc修改 PS1 ，例如：PS1=&quot;%F{green}%n:%F{cyan}%~%F{green}%F{white} %# &quot;如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考资料 优化mac下的terminal的zsh路径显示作者：Harry-hhj，github主页：[传送门](" }, { "title": "Pytorch Network Parameter Statistics", "url": "/posts/Pytorch-Network-Parameter-Statistics/", "categories": "Tutorial, Pytorch", "tags": "computer science, pytorch, tools", "date": "2021-09-20 18:40:00 +0800", "snippet": "PyTorch 统计网络参数量神经网络的参数统计是很重要的，它反映了一个网络的硬件需求与性能。PyTorch 可以使用第三方库 torchsummary 来统计参数并打印层结构。但是想要正确统计出参数量，需要对如何统计参数有一定的了解。Case1 无参数共享（最常见）import torchimport torch.nn as nnimport torchsummaryfrom torch.nn import initclass BaseNet(nn.Module): def __init__(self): super(BaseNet,self).__init__() self.conv1=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False) self.conv2=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_uniform_(m.weight.data) if m.bias is not None: m.bias.data.zero_() elif isinstance(m, nn.BatchNorm2d): init.normal_(m.weight.data, 1.0, 0.02) init.constant_(m.bias.data, 0.0) def forward(self,x): x=self.conv1(x) out_map=self.conv2(x) return out_map def count_parameters(model): &#39;&#39;&#39; model.parameters() 取得模型的参数，在参数可求导 p.requires_grad 的情况下，使用 numel()统计 numpy 数组里面的元素的个数。 &#39;&#39;&#39; return sum(p.numel() for p in model.parameters() if p.requires_grad)model = BaseNet()torchsummary.summary(model, (1, 512, 512))print(&#39;parameters_count:&#39;,count_parameters(model))结果：在这个案例中，使用 torchsummary 和自己统计得到相同的结果。Case2 参数共享import torchimport torch.nn as nnimport torchsummaryfrom torch.nn import initclass BaseNet(nn.Module): def __init__(self): super(BaseNet,self).__init__() self.conv1=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_uniform_(m.weight.data) if m.bias is not None: m.bias.data.zero_() elif isinstance(m, nn.BatchNorm2d): init.normal_(m.weight.data, 1.0, 0.02) init.constant_(m.bias.data, 0.0) def forward(self,x): x=self.conv1(x) out_map=self.conv1(x) return out_map def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)model = BaseNet()torchsummary.summary(model, (1, 512, 512))print(&#39;parameters_count:&#39;,count_parameters(model))结果：在这里例子中， parameter_count 统计的是 9 个参数，而 torchsummary 统计的是 18 个参数，为什么会出现这种问题？在这个网络中，我们只初始化了一个卷积层对象 conv1 ，然后在网络构建时（ forward 函数中），重复调用了conv1 ，以实现参数共享，即 Conv2d-1 和 Conv2d-2 层共享了 conv1 的参数。因此本例中 parameter_count 的计算是对的，而 torchsummary 计算时是先把层结构打印下来，然后统计各个层的参数并求和，不区分 Conv2d-1 和 Conv2d-2 层的参数是否相同。结论：在遇到参数共享的时候， torchsummary 统计的是不正确的！Case3 初始化无用变量import torchimport torch.nn as nnimport torchsummaryfrom torch.nn import initclass BaseNet(nn.Module): def __init__(self): super(BaseNet,self).__init__() self.conv1=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False) self.conv2=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_uniform_(m.weight.data) if m.bias is not None: m.bias.data.zero_() elif isinstance(m, nn.BatchNorm2d): init.normal_(m.weight.data, 1.0, 0.02) init.constant_(m.bias.data, 0.0) def forward(self,x): x=self.conv1(x) out_map=self.conv1(x) return out_mapdef count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)model = BaseNet()torchsummary.summary(model, (1, 512, 512))print(&#39;parameters_count:&#39;,count_parameters(model))结果：这个例子中我们在初始化时多初始化了一个 conv2 卷积层对象，但是没有在 forward 中使用。此时 parameter_count 出现了错误，即使没有在 forward 中调用，但是也会被算在 model.parameters() 中。但是要注意，尽管 torchsummary 和 parameter_count 都出现了同样结果的错误，两者出现错误的原因是不同的。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考文献 PyTorch几种情况下的参数数量统计可以下载本文的例子自行实践：链接: https://pan.baidu.com/s/1eet8b_HVmc_WMdIGxCibqA 提取码: p1j3作者：Harry-hhj，github主页：传送门" }, { "title": "Install VNC", "url": "/posts/Install-VNC/", "categories": "Tutorial, VNC", "tags": "install, tools, vnc", "date": "2021-09-19 11:48:00 +0800", "snippet": "Install VNC前言边缘计算平台通常没有显示设备，其本身就以小巧轻便为目的，配置一个显示器反而有些舍本求末了，再加上一些工作环境本身就不适合显示器存在，于是一种不通过显示器就能访问桌面的需求就产生了。借助 VNC 工具，我们可以仅通过一根网线访问运算平台的桌面，这在一些场景将会很有帮助。我们知道，连接网线之后配置好 IP 地址、子网掩码和路由器，我们可以轻松地通过 ssh 登陆目标设备。但是，当目标设备是 Ubuntu 系统且没有自动登录时，我们无法建立 ssh 连接的。对于这些特殊的场景，我觉得，配置一个 VNC ，将会省去你很多的麻烦。更何况配置过程本身就不复杂，何乐而不为呢！这里以 Tegra 处理器为例，理论上任何 ARM 架构的处理器上的 Linux 系统都通用。安装步骤 for Tegra安装 VNC 服务器sudo apt updatesudo apt install vino启用 VNC 服务器启用每次登录时启动 VNC 服务器：mkdir -p ~/.config/autostartcp /usr/share/applications/vino-server.desktop ~/.config/autostart配置 VNC 服务器：gsettings set org.gnome.Vino prompt-enabled falsegsettings set org.gnome.Vino require-encryption false设置访问 VNC 服务器的密码（将 &amp;lt;your_password&amp;gt; 替换为你的密码）：gsettings set org.gnome.Vino authentication-methods &quot;[&#39;vnc&#39;]&quot;gsettings set org.gnome.Vino vnc-password $(echo -n &#39;&amp;lt;your_password&amp;gt;&#39;|base64)重启系统使设置生效：sudo reboot只有在本地登录 Jetson 后，VNC 服务器才可用。如果您希望 VNC 自动可用，请使用系统设置应用程序启用自动登录。连接到 VNC 服务器在你希望在远程操作的操作系统上安装 VNC 客户端应用程序。为了连接，你需要知道 Linux 系统的 IP 地址：ifconfig在输出中搜索文本 inet addr: 后跟四个序列数字（可以这样实现 ifconfig | grep &amp;lt;eth0&amp;gt;），用于相关网络接口（例如 eth0 用于有线以太网， wlan0 用于 WiFi，或 l4tbr0 用于 USB 设备模式以太网连接）。设置静态 IP 地址操作主机为了防止 Linux 系统在不同的 Wi-Fi 中有不同的 IP 地址，或是 DHCP 每次分配了不一样的 IP 地址，我们可以使用网线来连接它，这样，我们可以通过这根网线配置一个局域网，而 IP 地址都是手动静态的了。在你的电脑主机上，配置网口或者拓展坞的 IP 地址、子网掩码和路由器。我们以常见的 Windows 系统和 MacOS 系统为例。对于 MacOS 系统，一般较新的苹果电脑是没有网口的，因此需要插上拓展坞，这里给出一个可用的产品（非广告，不提供链接）：然后插上电脑后，点击设置-&amp;gt;网络，会出现一个新的网卡连接，配置 IPv4 为手动，然后按照你的需求设置其他选项，点击应用就完成了。对于 Windows 系统，以 Windows 10 为例。打开控制面板：进入 网络和Internet-&amp;gt;网络和共享中心 。选择网线接口对应的连接，我这里选择 以太网3 。要注意的是，只有在网线连接电脑和对应设备时，才会有这一选项出现：在 以太网3状态 窗口中，选择 属性 。在弹出的 以太网3属性 窗口中选择 Internet协议版本4 ，并点击下方的按钮 属性 ：在弹出的窗口中部署 ip ， 子网掩码 ， 默认网关 。其中 ip 地址的前三位( 192.168.*** )需要保持与需要配置 VNC 的设备保持一致。最后一位需要与 VNC设备 不同，建议设置成 1 ，子网掩码为 255.255.255.0 ，默认网关与 ip 一致即可。点击确认保存，完成配置。目标机在 Linux 系统中，以 Ubuntu 系统中为例，运行 Settings 软件，点击 Network ，点击 Wired 中右侧设置图标：点击 IPv4 ，点击 Manual ，在 Addresses 中添加 IP 地址、子网掩码和网关，注意这里的子网和网关必须和远程操作机上的一致，而 IP 地址必须不同，且都不和网关 IP 冲突：设置桌面分辨率如果未连接显示器，则默认为选择了 $640\\times480$ 的分辨率。要使用不同的分辨率，请编辑 /etc/X11/xorg.conf 并附加以下几行：Section &quot;Screen&quot; Identifier &quot;Default Screen&quot; Monitor &quot;Configured Monitor&quot; Device &quot;Tegra0&quot; SubSection &quot;Display&quot; Depth 24 Virtual 1280 800 # 将这些值 EndSubSectionEndSection如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考文献 链接: https://pan.baidu.com/s/11QKGlXG_p99FQEzr7eV2tQ 提取码: 0omm作者：Harry-hhj，github主页：传送门第二作者：E-T-E-R-N-A-L-B-L-U-E，github主页：传送门" }, { "title": "CNN 中的解释性问题", "url": "/posts/Interpretative-Questions-in-CNN/", "categories": "Question, CNN", "tags": "computer science, questions", "date": "2021-09-18 16:20:00 +0800", "snippet": "目录 为什么 CNN 中卷积核的大小一般为奇数？Q&amp;amp;AQ1：为什么 CNN 中卷积核的大小一般为奇数？卷积核大小一般是奇数，原因是： 容易找到卷积锚点（主要）： 使用奇数尺寸的滤波器可简化索引，并更为直观，因为滤波器的中心落在整数值上。奇数相对于偶数，有中心点，对边沿、对线条更加敏感，可以更有效的提取边沿信息。因此，奇数大小的卷积核效率更高。 便于进行 padding （次要）： padding 的做法是双边填充，这就导致不管我们怎么填充最终图像增长的长度是偶数。然而我们知道在卷积时如果最后的剩余部分比卷积核小，那么就会损失部分边缘信息，这是我们不希望看到的。我们假设卷积大小 $(k \\times k)$ ，令 $\\text{stride}=1$ ， $\\text{dilation}=1$ ，则 $\\text{padding} = \\frac{\\text{kernel_size}-1}{2}$ 。 如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考文献 deeplearning.ai 《卷积神经网络》作者：Harry-hhj，github主页：传送门" }, { "title": "Docker", "url": "/posts/Docker/", "categories": "Tutorial, Docker", "tags": "getting started, install, tools, docker", "date": "2021-09-13 22:14:00 +0800", "snippet": "DockerDocker 是一个开源的、轻量级的容器引擎，主要运行于 Linux 和 Windows，用于创建、管理和编排容器。和 VMware 虚拟机相比，Docker 使用容器承载应用程序，而不使用操作系统，所以它的开销很少，性能很高。但是，Docker 对应用程序的隔离不如虚拟机彻底，所以它并不能完全取代 VMware。Docker 简介Docker 公司的由来 “Docker”一词来自英国口语，意为码头工人（Dock Worker），即从船上装卸货物的人。Docker 公司起初是一家名为 dotCloud 的平台即服务（Platform-as-a-Service, Paas）提供商，其平台利用了 Linux 容器技术。为了方便创建和管理这些容器， dotCloud 开发了一套内部工具 “Docker”。后来由于业务不景气，公司在聘请了新的 CEO Ben Golub 后，将公司改名为 Docker ，放弃了 Paas 平台，专注于 Docker 技术。如今 Docker 公司被普遍认为是一家创新型科技公司，已经过多轮融资。Docker 运行时与编排引擎多数技术人员在谈到 Docker 时，主要是指 Docker 引擎。运行虚拟机的核心管理程序是 ESXi ，而 Docker 引擎是运行容器的核心容器运行时。Docker 引擎位于中心，其他产品基于 Docker 引擎的核心功能进行集成Docker 引擎主要有两个版本：企业版（EE）和社区版（CE）。每个季度，企业版和社区版都会发布一个稳定版本。从 2017 年第一季度开始，Docker 版本号遵循 YY.MM-xx 格式，类似于 Ubuntu 等项目。Docker 开源项目 —— Moby开源 Docker 项目在 2017 年于 Austin 举办的 DockerCon 上正式命名为 Moby 项目，并且拥有了项目自己的 Logo，如下图所示。Moby 项目的目标是基于开源的方式，发展成为 Docker 上游，并将 Docker 拆分为更多的模块化组件。多数项目及其工具都是基于 Golang 编写的，这是谷歌推出的一种新的系统级编程语言，又叫 Go 语言。使用 Go 语言的读者，将更容易为该项目贡献代码。容器生态Docker 公司的一个核心哲学通常被称为“含电池，但可拆卸”（Batteries included but removable），意思是许多 Docker 内置的组件都可以替换为第三方的组件。随着 Docker 提供的内置组件越来越好，越来越不需要将它们移除了。这也导致了生态内部的紧张关系和竞争的加剧。这是一个好现象！因为良性的竞争是创新之母。开放容器计划如果不谈及开放容器计划（The Open Container Initiative, OCI）的话，对 Docker 和容器生态的探讨总是不完整的。OCI 是一个旨在对容器基础架构中的基础组件（如镜像格式与容器运行时）进行标准化的管理委员会。一个名为 CoreOS 的公司不喜欢 Docker 的某些行事方式。因此它就创建了一个新的开源标准，称作“appc”，该标准涉及诸如镜像格式和容器运行时等方面。此外它还开发了一个名为 rkt 的实现。两个处于竞争状态的标准将容器生态置于一种尴尬的境地。这使容器生态陷入了分裂的危险中，同时也令用户和消费者陷入两难。虽然竞争是一件好事，但是标准的竞争通常不是。因为它会导致困扰，降低用户接受度，对谁都无益。考虑到这一点，所有相关方都尽力用成熟的方式处理此事，共同成立了 OCI 。OCI 已经发布了两份规范（标准）：镜像规范和运行时规范。公平地说，这两个 OCI 规范对 Docker 的架构和核心产品设计产生了显著影响。到目前为止，OCI 已经取得了不错的成效，将容器生态团结起来。然而，标准总是会减慢创新的步伐！尤其是对于超快速发展的新技术来说更是如此。Docker 安装因为 Linux 常作为开发平台，这里以 Linux 安装为例。Linux在 Linux 上安装 Docker 是常见的安装场景，并且安装过程非常简单。唯一的两个需求就是： Linux 操作系统 能够访问 https://get.docker.comDocker 有两个版本可供选择：社区版（CE）和企业版（EE），其中 CE 是免费的，下面演示 CE 的安装过程。注：在开始下面的步骤之前，要确认系统升级到最新的包，并且打了相应的安全补丁。接下来的示例基于 Ubuntu 版本 Linux，同样适用于更低或者更高的版本。 在 Linux 机器上打开一个新的 Shell。 使用 wget 从 https://get.docker.com 获取并运行 Docker 安装脚本，然后采用 Shell 中管道（pipe）的方式来执行这个脚本。 wget -qO- https://get.docker.com/ | sh 最好通过非 root 用户来使用 Docker。这时需要添加非 root 用户到本地 Docker Unix 组当中。下面的命令展示了如何把名为 &amp;lt;username&amp;gt; 的用户添加到 Docker 组中，以及如何确认操作是否执行成功。 sudo usermod -aG docker &amp;lt;username&amp;gt;cat /etc/group | grep docker 输出： docker:x:998:&amp;lt;username&amp;gt; 如果当前登录用户就是要添加到 Docker 组中的用户的话，则需要重新登录，组权限设置才会生效。 至此 Docker 已经在 Linux 上安装成功。运行下面命令来确认安装结果。 docker --versiondocker system info 分别输出： 如果上述步骤在自己的 Linux 发行版中无法成功执行，可以访问 Docker Docs 网站并单击与自己的版本相关的那个链接。接下来页面会跳转到 Docker 官方提供的适合当前版本的安装指南页面，这个安装指南通常会保持更新。Docker 网站上提供的指令使用了包管理器，相比前面的例子需要更多的步骤才能完成安装操作。更多其他在 Linux 上安装 Docker 的方式，可以打开 Docker 主页面，单击页面中 Get Started 按钮来获取。Docker 引擎升级升级步骤： 停止 Docker 守护程序 移除旧版本 Docker 安装新版本 Docker 配置新版本的 Docker 为开机自启动 确保容器重启成功下面以 Ubuntu 20.04 为例（刚安装完的 Docker 不需要更新版本）。更新 APT 包：sudo apt update卸载当前 Docker ：sudo apt-get remove docker docker-engine docker-ce docker.io -y安装新版本 Docker ，使用 get.docker.com 的脚本完成最新版本 Docker CE 的安装和配置：wget -qO- https://get.docker.com/ | sh将 Docker 配置为开机自启动：systemctl enable dockersystemctl is-enabled docker重启 Ubuntu 。检查并确保每一个容器和服务都已经重启成功（没有容器时无需检查）：docker container lsdocker service lsDocker Storage Drive：存储驱动如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！" }, { "title": "Deconvolution", "url": "/posts/Deconvolution/", "categories": "Tutorial, Nerual Network Theory", "tags": "getting started, computer science, nerual network", "date": "2021-09-06 12:00:00 +0800", "snippet": "Deconvolution一、概念逆卷积（Deconvolution）一般和转置卷积（transposed conv）、微步卷积（fractionally strided conv）的叫法等价。其常见的用处包括： 在 ZF-Net 中用于对 feature map 做可视化 在 FCN 中用于生成等于原图 shape 的图像 无监督的 autoencoder 和 deconvNet 中用于解码器 DSSD、GAN中的应用 ……从上面可以看出，deconvolution 最大的用处是：对 feature map 进行升采样，这和双线性插值（bilinear interpolation）类似。注意，它虽然叫做逆卷积，但是它并不是卷积的逆过程，不能完全还原出卷积前的输入，与原输入仅仅在大小上相同，在数值上虽然具有一定的相关性，但是没有可逆关系。deconv 仅仅是一个普通的卷积层，在神经网络中也是需要通过梯度下降去学习的。在 Pytorch 中通过 torch.nn.ConvTranspose2d 实现，使用方法参考这篇教程。二、最基本的三种形式注：以下推导时，假设长和宽大小相等，如果大小不等，只需要按照以下操作分别计算就行了。1. 无 padding 、无 stride 首先我们来看看最基本的卷积形式：对于 $(m \\times m)$ 的特征图 $I$ ，用大小为 $(k \\times k)$ 的核做卷积，则得到的特征图 $O$ 大小为 $((m-k+1) \\times (m-k+1))$ 。怎么让特征图 $O$ 经过同样大小的卷积核以后的到和特征图 $I$ 一样的大小呢？我们先对特征图 $O$ 做 $padding=k-1$ 的填充，大小变为 $((m+k-1) \\times (m+k-1))$ ，再用等大的 $(k \\times k)$ 核做卷积，则得到的特征图 $I’$ 的大小是 $(m \\times m)$ 。2. 无 padding 、有 stride 然后我们来看看加入 stride 后如何 deconv ：对于 $(m \\times m)$ 的特征图 $I$ ，用 $(k \\times k)$ 大小的核做卷积，记 stride 为 $s$ ，则得到的特征图 $O$ 的大小为 $((\\lfloor \\cfrac{m-k}{s}+1 \\rfloor) \\times (\\lfloor \\cfrac{m-k}{s}+1 \\rfloor))$ 。怎么让特征图 $O$ 经过同样大小的卷积核以后的到和特征图 $I$ 一样的大小呢？与之前不同的是，我们需要根据 stride 对 $I$ 做内部扩充（填 $0$），具体的规则是：在两个元素之间加入 $s-1$ 个 $0$ ，共有 $\\lfloor \\cfrac{m-k}{s}+1 \\rfloor - 1$ 个插入点。再和之前一样，加入 $padding=k-1$ 的填充，得到 $O’$ 。此时计算可得 $O’$ 的边长为为 $\\lfloor \\cfrac{m-k}{s}+1 \\rfloor + 2(k-1) + (s-1)(\\lfloor \\cfrac{m-k}{s}+1 \\rfloor-1) = m+k-1$ ，即大小为 $(m-k+1, m-k+1)$ ，用等大的 $(k \\times k)$ 核做卷积之后得到的特征图 $I’$ 的大小是 $(m \\times m)$ 。另 s=1 就得到 [1] 中的情况。3. 有 padding 、无 stride 为了方便了解加入 padding 之后我们应该如何操作，我们先不考虑 stride 带来的影响，即令 stride=1 。对于大小为 $(m \\times m)$ 的特征图 $I$ ，先做大小为 $p$ 的 padding ，用 $(k \\times k)$ 的核做卷积，则得到的特征图 $O$ 的大小为 $((m+2p-k+1) \\times (m+2p-k+1))$ 。怎么让特征图 $O$ 经过同样大小的卷积核以后的到和特征图 $I$ 一样的大小呢？我们先假设我们对 $O$ 做大小为 $p’$ 的 padding 得到 $O’$ ，再用等大的 $(k \\times k)$ 的核做 stride=1 的卷积，则得到的特征图 $I’$ 的边长是 $(m+2p-k+1)+2p’-k+1$ ，最终需要得到大小为 $(m \\times m)$ 的特征图 $I’$ 。那么得到以下等式：\\((m+2p-k+1)+2p&#39;-k+1 = m\\)得到 \\(p&#39; = k-1-p\\) 。三、公式推导接下来我们考虑最一般的情况（不考虑长宽不等，因为计算过程相同）。对于大小为 $(m \\times m)$ 的特征图 $I$ ，先做大小为 $p$ 的 padding ，得到 $I’$ 的大小为 $((m+2p) \\times (m+2p))$ ，卷积后得到特征图 $O$ 的大小为 $((\\cfrac{m+2p-k}{s}+1) \\times (\\cfrac{m+2p-k}{s}+1))$ 。对 $O’$ 进行 deconv ，先做大小为 $p’$ 的 padding 得到 $O’$ ，边长为 $\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor + 2p’$ 。然后根据 stride 填充得到 $O’’$ ，边长为 $\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor + 2p’+(s-1)(\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor - 1)$ 。再用等大的 $(k \\times k)$ 的核做 stride=1 的卷积，则得到的特征图 $I’’$ 的边长是 $\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor + 2p’+(s-1)(\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor - 1) -k+1$ ，令 $I’’$ 的边长为 $m$ （我们的目标），可得等式：\\(\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor + 2p&#39;+(s-1)(\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor - 1) -k+1 = m\\)解得 \\(p&#39;=k-1-p\\) 。四、总结我们来做一个总结，假设特征图 $I$ 大小为 $(m \\times m)$ ，经过大小为 $(k \\times k)$ 卷积核 kernel ，padding 的大小为 $p$ ， stride 的大小为 $s$ 的卷积，得到特征图 $O$ 。 deconv 的操作可以归为两步，分别是： 将卷积核 kernel 做行列转置，得到 kernel&#39; 对特征图 $O$ 根据 stride 做内部填充，填充规则是：在每两行/列元素之间插入 $s-1$ 行/列的 $0$ ，得到特征图 $O’$ 对特征图 $O’$ 做 padding ，大小为 $k-1-p$ ，得到特征图 $I’$ ，此时 $I’$ 的大小和 $I$ 相同，但数据不同我们可以发现：stride 仅和填充的大小有关，而 deconv 的实际卷积操作是 stride=1 的。五、解释为什么逆卷积可以一定程度上还原卷积操作呢？这里简单说明一下逆卷积和卷积的关系： 特征图大小相似 保证了同样的连通性什么是同样的连接性？这是指从 $I$ 到 $O$ （ $I$ 、 $O$ 分别表示卷积前和卷积后的特征图），如果中 $I$ 一个位置与 $O$ 中一个位置通过 kernel 有关系，那么在卷积核逆卷积中有相同的连通。六、一般情况如果我们不需要 deconv 的输出与原输入卷积的特征图大小相同，那么这就是最一般的情况。此时我们不再限制 stride 和 padding 的大小，而是根据它们计算 deconv 输出的大小，其实这在 [三] 中已经推导过了：输入大小：$(N, C_{in}, H_{in}, W_{in})$输出大小：$(N, C_{out}, H_{out}, W_{out})$其中：\\(H_{out} = (H_{in}-1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size[0]}-1) + \\text{out\\_padding}[0] + 1 \\\\W_{out} = (W_{in}-1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1] \\times (\\text{kernel\\_size[1]}-1) + \\text{out\\_padding}[1] + 1\\)七、out_padding在上面的式子中，出现了一个新的参数 - out_padding ，但其只用于查找输出形状，但实际上并不向输出添加零填充。我们先来提出一个问题：假定输入特征图为 $(6 \\times 6)$ ， stride=2 ， kernel_size=3 ，进行 same 卷积操作得到输出特征图的大小为 $(3 \\times 3)$ 。再假讨论另一种情况，假定输入特征图为 $(5 \\times 5)$ ， stride=2 ， kernel_size=3 ，这时候设置 padding=1 ，那么也会得到输出特征图为 $(3 \\times 3)$ 。如果继续考虑 valid 卷积，那么会有更多的情况得到相同大小的输出特征图。这在进行逆卷积的时候就出现了问题，因为卷积时是多种情况对应到了一种情况，那么逆卷积时该如何对应回去呢？解决的方法就是使用 out_padding 参数，它的作用是：当 $\\text{stride} \\gt 1$ 时， Conv2d 将多个输入形状映射到相同的输出形状。output_padding 通过在一边有效地增加计算出的输出形状来解决这种模糊性。首先我们要认可一个前提：在大多数情况下我们都希望经过卷积/反卷积处理后的图像尺寸比例能够被步长整除，即 $输入特征图大小/输出特征图大小=stride$ ，也就是 same 模式。所以我们通过添加 out_padding 这一参数来使得结果满足这一前提，那么 deconv 的输出特征图大小就能够满足为 $其输入大小*stride$ ，而不是任意可能的大小。这样的好处是：网络在后面进行预尺寸相关的操作时，输入的大小是已知且固定的。实现方法：对于 conv 一般推荐的 padding 是 (kernel_size-1)/2 ，那么对于 deconv 来说为了满足前提有如下的等式（假设 dilation 为 $1$）：\\(\\begin{equation}\\begin{split}H_{out} &amp;amp; = (H_{in}-1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size[0]}-1) + \\text{out\\_padding}[0] + 1 \\\\ &amp;amp; = (H_{in}-1) \\times \\text{stride}[0] - (\\text{kernel\\_size}[0]-1) + \\text{dilation}[0] \\times (\\text{kernel\\_size[0]}-1) + \\text{out\\_padding}[0] + 1 \\\\\\end{split}\\end{equation}\\)得到 \\(\\text{out\\_padding}[0] = \\text{stride}[0]-1\\)。out_padding[1] 同理。当然可以取其他值，不妨碍 deconv 的计算，但是需要注意，网络后面进行尺寸有关的操作时输入的大小可能不能确定。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！八、参考文献 Deconvolution（逆卷积） Convolution arithmetic ConvTranspose2d原理，深度网络如何进行上采样？ nn.ConvTranspose2d的参数output_padding的作用作者：Harry-hhj，github主页：传送门" }, { "title": "Netron", "url": "/posts/Netron/", "categories": "Tutorial, Netron", "tags": "install, tools, netron", "date": "2021-09-04 20:25:00 +0800", "snippet": "NetronNetron 是一款深度神经网络可视化工具，这样一款神器的开发作者是微软的大神 Lutz Roeder ，并且在自己的家中完成的。Netron 强大的原因在于： 所支持的平台广泛。不像 tensorboard 等较为“专一”的可视化平台，当前主流的深度学习框架，Netron 都能得到很好的支持； 操作简单快捷。不需要写一行代码，只需要下载软件安装，然后打开需要可视化的文件，一步操作即可，当然也可以通过代码实现； 保存快捷。对于可视化的结果，就像保存普通的文件一样，一步到位，保存在自己的电脑上。一、支持的框架Netron 最为强大的功能，就在于它所支持的框架十分广泛： ONNX： .onnx 、 .pb 、 ,pbtxt Keras： .h5 、 .keras CoreML： .mlmodel Caffe2： predict_net.pb 、 predict_net.pbtxt MXNet： .model 、 -symbol.json Tensorflow Lite： tflite Caffe： .caffemodel 、 .prototxt PyTorch： .pth Torch： .t7 CNTK： .model 、 .cntk PaddlePaddle： __model__ Darknet： cfg scikit-learn： .pkl TensorFlow.js： .model.json 、 .pb TensorFlow： .pb 、 .meta 、 .pbtxt二、安装1. 在线使用这种方式最为简单，只需要打开网页，放入模型就可以浏览了。2. python 安装打开终端，输入：pip install netron进入 python 解释器或新建一个 python 脚本，输入：import netronnetron.start(r&quot;&amp;lt;path/to/model&amp;gt;&quot;)运行该代码会跳出一个服务网址，并自动打开浏览器，得到如下的效果：这里提供一个 onnx 模型（链接: https://pan.baidu.com/s/1C2abik9L9e0XRJVhPIJFZA 提取码: 17ka），供读者体验效果。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！三、参考文献 【神经网络可视化01】——用Netron实现可视化作者：Harry-hhj，github主页：传送门" }, { "title": "Pytorch Building Nueral Network", "url": "/posts/Pytorch-Building-Neural-Network/", "categories": "Tutorial, Pytorch", "tags": "getting started, computer science, pytorch", "date": "2021-09-04 08:00:00 +0800", "snippet": "Pytorch 搭建神经网络一、热身torch.nn 包依赖 autograd 包来定义模型并求导。 一个 nn.Module 包含： 各个层 一个 forward(input) 方法，该方法返回网络的 output在模型中必须要定义 forward() 函数， backward() 函数（用来计算梯度）会被 autograd 自动创建。 可以在 forward() 函数中使用任何针对 Tensor 的操作。神经网络的典型训练过程如下： 定义包含一些可学习的参数（权重）神经网络模型； 在数据集上迭代； 通过神经网络处理输入； 计算损失（输出结果和正确值的差值大小）； 将梯度反向传播回网络的参数； 更新网络的参数，主要使用如下简单的更新原则： weight = weight - learning_rate * gradient本篇将着重于模型定义，而下一篇将着重于网络训练。在讲解 pytorch 的网络包之前，我们先尝试使用 torch.nn 包自己搭建一个简单的网络。我们先来看这样一个网络：import torchimport torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) # 3 通道输入，6 通道输出，5x5 卷积核 self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) # 全连接层 y = Wx + b self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # (2, 2) 最大池化 x = F.max_pool2d(F.relu(self.conv2(x)), 2) # 方形卷积核可以用一个数字代替大小 x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] # 第 0 维是 batch 大小 num_features = 1 for s in size: num_features *= s return num_featuresnet = Net()print(net)为了更好地观察网络结构，我们可以借助可视化工具 Netron 来输出网络的结构图。使用如下的代码，有关 Netron 的更多内容，可以查看这篇教程。x = torch.randn(1, 3, 32, 32)torch.onnx.export(net, x, &quot;example.onnx&quot;)import netronimport osmodel_path = os.path.join(os.getcwd(),&quot;example.onnx&quot;)netron.start(model_path)运行这段代码会自动跳出一个网页，如下图：先请读者思考一个问题，这个网络的输入大小是多少，为什么？想要了解网络的结构，我们需要看 forward() 的函数，注意不是看 init() 。 __init__() 中可以定义网络的比较关键的部件，这样的做的好处是：便于变量名称管理（见 【三】 ）和规定层的参数，增加代码的可读性。解析：对于大小为 $(w, h, c)$ 的输入 x ，首先经过 conv1 ，可以看出 conv1 的输入通道是 $3$ ，因此 $c=3$ ，输出 $6$ 通道。经过 $(5 \\times 5)$ 的卷积，大小变为 $(w-4, h-4, 6)$ 。经过 $(2,2)$ 的最大池化层，默认 stride=kernel_size=2，大小缩减一半，通道数不变，为 $(\\cfrac{w-4}{2}, \\cfrac{h-4}{2}, 6)$ 。再经过一层 $(5 \\times 5)$ 卷积，卷积核数量为 $16$ ，此时特征图尺寸 $(\\cfrac{w-4}{2}-4, \\cfrac{h-4}{2}-4, 16)$ 。再经过 $(2,2)$ 的最大池化层，变为 $(\\cfrac{\\cfrac{w-4}{2}-4}{2}, \\cfrac{\\cfrac{h-4}{2}-4}{2}, 16)$ 。全连接层的输入大小是固定的，因此我们得到以下的等式：\\(\\left \\{\\begin{array}{c}\\cfrac{\\cfrac{w-4}{2}-4}{2} = 5\\\\\\cfrac{\\cfrac{h-4}{2}-4}{2} = 5\\\\\\end{array}\\right .\\)得到 $w=h=32$ ，因此答案是 $(32, 32, 3)$ 。如果对于上面的推导没有看懂的读者，建议先学习神经网络原理，再来看本篇教程。在定义一个自己的网络时，我们二、torch.nn1. 卷积层1) nn.Conv2d二维输入卷积层class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode=&#39;zeros&#39;, device=None, dtype=None)参数： in_channels (int) – 输入的通道数量 out_channels (int) – 输出的通道数量 kernel_size (int or tuple) – 卷积核的大小 stride (int or tuple，可选) – 卷积步长，默认为 1 padding (int or tuple or str，可选) – 向输入四边添加的填充宽度，默认为 0 padding_mode (string**，可选) – &#39;zeros&#39;, &#39;reflect&#39;, &#39;replicate&#39; or &#39;circular&#39;，默认&#39;zeros&#39; dilation (int or tuple，可选) – 内核元素之间的距离，默认 1 groups (int，可选) – 从输入通道到输出通道到阻塞连接数，默认为 1 bias (bool，可选) – 如果 bias=True ，添加科学系的偏置到输出中，默认为 true参数说明： dilation ：空洞卷积。下图蓝色为输入，绿色为输出（注意参考文献 4 中的阐述有误） dilation=1 dilation=2 以此类推 其实这里 dilation 的定义和 stride 是一致的， dilation 并不代表跳过多少个元素，而代表两个内核元素之间的距离，因此默认值是 1 。 好处：使用 dilation 的好处是增大单次计算时的感受域（即覆盖的面积），在增大感受域的同时却没有增加计算量，保留了更多的细节信息。例如在上面的例子中， dilation=1 时感受域为 $33=9$ ， dilation=2 时感受域为 $55=25$ 。 groups ：深度可分离卷积。 groups=1 ：输出是所有的输入的卷积 conv = nn.Conv2d(in_channels=6, out_channels=3, kernel_size=1, groups=1)conv.weight.data.size() # torch.Size([3, 6, 1, 1]) groups=2 ：此时相当于有并排的两个卷积层，每个卷积层计算输入通道的一半，并且产生的输出是输出通道的一半，随后将这两个输出连接起来得到结果 conv = nn.Conv2d(in_channels=6, out_channels=6, kernel_size=1, groups=2)conv.weight.data.size() # torch.Size([6, 3, 1, 1]) groups=in_channels ：每一个输入通道和它对应的卷积核进行卷积，该对应的卷积核大小为 \\(\\cfrac{C_{out}}{C_{in}}\\) conv = nn.Conv2d(in_channels=6, out_channels=6, kernel_size=1, groups=6)conv.weight.data.size() # torch.Size([6, 1, 1, 1]) 提示一下，**一般卷积网络中出现的大小都是四维数组，他们分别表示 $(数量N, 通道C, 高度H, 宽度W)$ **。注意顺序。 groups 的值必须能同时整除 in_channels 和 out_channels 。 【理解】其规律是共有 out_channels 个卷积核，被分为 groups 组，即每组有 out_channels/groups 个卷积核，输入的通道也被分为 groups 组，每组的通道数为in_channels/groups ，因此每个卷积核的通道数为 in_channels/groups 组，每一组卷积核负责输入的一组，最后将 groups 组的卷积结果拼接起来，就得到了最终的输出。具体的实验结果可以查看这篇教程。 好处：深度可分离卷积的目的是减少卷积操作的参数量和计算量，从而提升运算速度。在实际实验中，同样的网络结构下，这种分组的卷积效果是好于未分组的卷积的效果的。 参数 kernel_size ， stride ， padding ， dilation 可以是一个 int 的数据，此时卷积 height 和 width 值相同 也可以是一个 tuple 数组， tuple 的第一维度表示 height 的数值， tuple 的第二维度表示 width 的数值 大小推导：假设输入大小为 $(N, C_{in}, H_{in}, W_{in})$ ，输出为 $(N, C_{out}, H_{out}, W_{out})$ ，满足以下关系：\\[H_{out} = \\lfloor \\cfrac{H_{in}+2 \\times \\text{padding}[0]-\\text{dilation}[0] \\times (\\text{kernel\\_size}[0]-1)-1}{\\text{stride}[0]}+1 \\rfloor\\]\\[W_{out} = \\lfloor \\cfrac{W_{in}+2 \\times \\text{padding}[1]-\\text{dilation}[1] \\times (\\text{kernel\\_size}[1]-1)-1}{\\text{stride}[1]}+1 \\rfloor\\]卷积层含有两个变量： ~Conv2d.weight (Tensor)：权重，可学习参数，大小为 $(\\text{out_channels}, \\frac{\\text{in_channels}}{\\text{groups}}, \\text{kernel_size}[0], \\text{kernel_size}[1])$ ~Conv2d.bias (Tensor)：偏置，可学习参数用法：m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))2) nn.ConvTranspose2d微步卷积（fractionally-strided convolutions）或解卷积（deconvolutions），也可以看作是输入卷积的梯度。注意，解卷积并不是卷积的逆过程， 不能还原卷积前的数据。class torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode=&#39;zeros&#39;, device=None, dtype=None)参数： in_channels (int) – 输入的通道数量 out_channels (int) – 输出的通道数量 kernel_size (int or tuple) – 卷积核的大小 stride (int or tuple，可选) – 卷积步长，默认为 1 padding (int or tuple，可选) – 向输入四边添加 dilation * (kernel_size - 1) - padding 零填充，默认为 0 output_padding (int or tuple，可选) – 向输出图片一边添加的填充，默认为 0 groups (int，可选) – 从输入通道到输出通道到阻塞连接数，默认为 1 bias (bool，可选) – 如果 bias=True ，添加科学系的偏置到输出中，默认为 true dilation (int or tuple，可选) – 内核元素之间的距离，默认 1参数说明： 本质同样是卷积，很多参数的意义都和 conv 一样 out_padding ：这种填充只会填充一边，目的是规定输出的大小。 在进行卷积时，对于不同大小的输入，规定不同的 padding 、 stride 和卷积类型，可能得到相同大小的输出。举个例子，对于 $6\\times6$ 的输入特征图，定义 stride 为 $2$ ，kernel_size 为 $3$ ，padding 为 $2$，输出的特征图大小为 $3\\times3$ 。对于 $5\\times5$ 的输入特征图，定义 stride 为 $2$ ，kernel_size 为 $3$ ，padding 为 $1$，输出的特征图大小也为 $3\\times3$ 。既然不同大小的图片经过卷积运算能够得到相同尺寸的输出，那么作为解卷积，同样的一样图片可以得到不同尺寸的合法输出，这就引发了歧义。当我们后续的操作涉及到尺寸有关的行为时，就无法保证网络按照预期进行计算。为了解决这种模糊性，pytorch 巧妙地引入了参数 out_padding 来获得固定大小的输出。 这里有一个默认前提，一般情况下我们希望经过卷积/解卷积处理后的图像尺寸比例与步长相等，即 $输入特征图大小/输出特征图大小=\\text{stride}$ 。 我们先来算为了满足这个前提 padding 应该设置为多少。根据公式\\(H_{out} = \\lfloor \\cfrac{H_{in}+2 \\times \\text{padding}[0]-\\text{dilation}[0] \\times (\\text{kernel\\_size}[0]-1)-1}{\\text{stride}[0]}+1 \\rfloor = \\cfrac{H_{in}}{\\text{stride}[0]}\\)得到：\\(\\text{padding}[0] = \\cfrac{\\text{dilation}[0] \\times (\\text{kernel\\_size[0] - 1}) + 1 - \\text{stride}[0]}{2}\\)根据这个 padding 求 outpadding ，代入公式\\(H_{out} = (H_{in}-1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size}[0]-1) + \\text{out\\_padding}[0] + 1 = H_{in} \\times \\text{stride}[0]\\)得到：\\(\\text{out\\_padding}[0] = 0\\)这说明，当按照完全相同的尺寸逆卷积，且规定网络参数一致，输入输出特征图的比例互为倒数（即整个大小运算中应没有使用到下取整），此时无需 out_padding 。而当运算使用到了下取整，就意味着我们需要通过 out_padding 补足这部分被舍弃的大小。 而这一点，参考文献6的表述就略有问题了，请读者注意。 大小推导：假设输入大小为 $(N, C_{in}, H_{in}, W_{in})$ ，输出为 $(N, C_{out}, H_{out}, W_{out})$ ，满足以下关系：\\[H_{out} = (H_{in}-1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size}[0]-1) + \\text{out\\_padding}[0] + 1\\]\\[W_{out} = (W_{in}-1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1] \\times (\\text{kernel\\_size}[1]-1) + \\text{out\\_padding}[1] + 1\\]逆卷积层含有两个变量： ~ConvTranspose2d.weight (Tensor)：权重，可学习参数，大小为 $(\\text{in_channels}, \\frac{\\text{out_channels}}{\\text{groups}}, \\text{kernel_size}[0], \\text{kernel_size}[1])$ ~ConvTranspose2d.bias (Tensor)：权重，可学习参数，大小为 $(\\text{out_channels})$更详细的说明可以查看这篇 Deconvolution教程 。用法：upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1)2. 池化层1) nn.MaxPool2d下采样的一种。torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)参数： kernel_size – 取最大值的窗口大小 stride – 窗口滑动的步幅。默认值为 kernel_size （注意不是 $1$ ） padding – 要在两侧添加隐式零填充 dilation – 控制窗口中元素步幅的参数 return_indices – 如果True，将返回最大索引和输出。对之后的 torch.nn.MaxUnpool2d 有用。 ceil_mode – 当为 True 时，将使用上取整 ceil （即填充数据）而不是下取整 floor （即舍弃数据）来计算输出形状参数说明： stride ：默认值等于卷积核的大小 ceil_mode ：当 ceil_mode = true 时，将保存剩余的不足为 kernel_size 大小的数据保存，自动补足 $\\text{NAN}$ 至 kernel_size 大小；当 ceil_mode = False 时，剩余数据不足 kernel_size 大小时，直接舍弃。 举例：对于如下原始数据，进行 $(2\\times2)$ MaxPool2d： 0 0 | 0 0 | 0 1 1 | 1 1 | 1 ————————————----———————————— 2 2 | 2 2 | 2 3 3 | 3 3 | 3 —————————————---———————————— 4 4 | 4 4 | 4 当ceil_mode = True时： 0 0 | 0 0 | 0 × 1 1 | 1 1 | 1 × ————————————----————————————---- 2 2 | 2 2 | 2 × 3 3 | 3 3 | 3 × —————————————---————————————---- 4 4 | 4 4 | 4 × × × | × × | × × ————————————————————————————---- 输出： [ 1 1 1 3 3 3 4 4 4 ] 即：当数据不足以构成 2*2 时，仍然对剩余数据进行计算 当ceil_mode = False时： 0 0 | 0 0 1 1 | 1 1 ————————————----——- 2 2 | 2 2 3 3 | 3 3 输出： [ 1 1 3 3 ] 即：当数据不足以构成 2*2 时，舍弃 大小推导：假设输入大小为 $(N, C_{in}, H_{in}, W_{in})$ ，输出为 $(N, C_{out}, H_{out}, W_{out})$ ，满足以下关系：\\(H_{out} = \\lfloor \\cfrac{H_{in}+2 \\times \\text{padding}[0]-\\text{dilation}[0] \\times (\\text{kernel\\_size}[0]-1)-1}{\\text{stride}[0]}+1 \\rfloor\\)\\[W_{out} = \\lfloor \\cfrac{W_{in}+2 \\times \\text{padding}[1]-\\text{dilation}[1] \\times (\\text{kernel\\_size}[1]-1)-1}{\\text{stride}[1]}+1 \\rfloor\\]用法：m = nn.MaxPool2d((3, 2), stride=(2, 1))2) nn.MaxUnpool2d一种上采样方法， MaxPool2d 的部分逆运算，因为非最大值已经丢失了。MaxUnpool2d 将MaxPool2d 包含最大值索引的输出作为输入，并计算部分逆，其中所有非最大值都设置为零。参数： kernel_size ( int or tuple ) – 最大池化窗口的大小 stride ( int or tuple ) – 最大池化窗口的步幅。默认设置为 kernel_size 。 padding ( int or tuple ) – 添加到输入的填充，可以通过输入 output_size 来确定输入： input ：输入张量 indices ：MaxPool2d 返回 output_size (optional)：目标输出大小用法：pool = nn.MaxPool2d(2, stride=2, return_indices=True)unpool = nn.MaxUnpool2d(2, stride=2)input = torch.tensor([[[[ 1., 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12], [13, 14, 15, 16]]]])output, indices = pool(input)unpool(output, indices, output_size=torch.Size([1, 1, 5, 5]))# tensor([[[[ 0., 0., 0., 0., 0.],# [ 6., 0., 8., 0., 0.],# [ 0., 0., 0., 14., 0.],# [ 16., 0., 0., 0., 0.],# [ 0., 0., 0., 0., 0.]]]])3) nn.AvgPool2d平均池化。\\(\\text{out}(N_i, C_j, h, w) = \\frac{1}{kH*kW}\\sum_{m=0}^{kH-1}\\sum_{n=0}^{kW-1} \\text{input}(N_i, C_j, \\text{stride}[0] \\times h+m, \\text{stride}[1] \\times w+n)\\)class torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)参数： kernel_size – 窗口的大小 stride – 窗口的步幅，默认值为 kernel_size padding – 要在两侧添加的隐式零填充 ceil_mode – 当为 True 时，将使用 ceil 而不是 floor 来计算输出形状 count_include_pad – 当为 True 时，将在平均计算中包括零填充 divisor_override – 除法因子，如果指定，它将被用作平均时的除数，否则 kernel_size 将被使用用法：m = nn.AvgPool2d(3, stride=2)4) nn.AdaptiveMaxPool2d二维自适应最大池化。对于任何大小的输入，可以产生指定输出大小。class torch.nn.AdaptiveMaxPool2d(output_size, return_indices=False)参数： output_size – H 和 W 可以是 int，或者 None 表示大小将与输入相同。 return_indices – 如果True，将返回索引和输出。传递给 nn.MaxUnpool2d 很有用。默认：FalseAdaptiveMaxPool2d 自动计算了 kernel_size 、 stride 、 padding ，它可以用以下公式与 MaxPool2d 转换：\\(\\begin{equation}\\begin{split}&amp;amp; \\text{kernel\\_size} = \\text{input\\_size} - (\\text{output\\_size}-1) * \\text{stride}\\\\&amp;amp; \\text{stride} = \\lfloor \\frac{\\text{input\\_size}}{\\text{output\\_size}} \\rfloor\\\\&amp;amp; padding = 0\\end{split}\\end{equation}\\)用法：m = nn.AdaptiveMaxPool2d((None, 7))5) nn.AdaptiveAvgPool2d3. 非线性激活函数1) nn.ELU2) nn.Hardshrink3) nn.Hardsigmoid4) nn.Hardtanh5) nn.Hardwish6) nn.LeakyReLu7) nn.LogSigmoid8) nn.MultiheadAttention9) nn.PReLu10) nn.ReLu11) nn.ReLu612) RReLu13) nn.SELU14) nn.CELU15) nn.GELU16) nn.Sigmoid17) nn.SiLU18) nn.Mish19) nn.Softplus20) nn.Softsign21) nn.Tanh22) nn.Tanhshrink23) nn.Threshold4. 其他非线性操作1) nn.Softmax2) nn.LogSoftmax3) nn.AdaptiveLogSoftmaxWithLoss5. 标准化层1) nn.BatchNorm2dclass torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)论文来源： Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift 。对于一个 4D 的输入（小批量的带通道的二维输入）：\\(y = \\cfrac{x-\\mathbf{E}[x]}{\\sqrt{\\mathbf{Var}[x]+\\epsilon}}*\\gamma+\\beta\\)平均值和标准差是在小批量上的每个维度计算的，并且 $\\gamma$ 和 $\\beta$ 是大小为 $C$ 的可学习参数向量（其中 $C$ 是输入大小）。默认情况下，元素 $\\gamma$ 被设置为 1 和元素 $\\beta$ 被设置为 $0$ 。标准偏差是通过偏置估计器计算的，相当于 torch.var(input, unbiased=False) 。此外，默认情况下，在训练期间，该层不断运行其计算出的均值和方差的估计值，然后在评估期间将其用于归一化。运行估计保持默认值 momentum 0.1。更新规则：$\\hat x_{new} = 1 - \\text{momentum} \\times \\hat x + \\text{momentum} \\times x_t$ ，其中 $\\hat x$ 是估计值， $x_t$ 是新的观测值。参数： num_features – 输入大小 $(N, C, H, W)$ 中的 $C$ eps – 为数值稳定性添加到分母的值（当分母趋近于 $0$ 时会出现数值爆炸）。默认值：1e-5 momentum – 用于 running_mean 和 running_var 计算的值。可以设置 None 为累积移动平均（即简单平均）。默认值：0.1 affine – bool，当设置为 True 时，该模块具有可学习的仿射参数。默认：True track_running_stats – bool，当设置为 True ，该模块跟踪运行的均值和方差，当设定为 False ，该模块不跟踪这些统计数据，并初始化统计缓冲区 running_mean 和 running_var 作为 None 。当这些缓冲区为 None 时，此模块始终使用 batch 统计信息。在训练和评估模式中。默认：True参数说明： afine ： 当 afine=true 时， weight($\\gamma$) 和 bias($\\beta$) 将被使用，即进行缩放和平移 举例： import torchfrom torch import nn m = nn.BatchNorm2d(2,affine=True)# 通过梯度下降更新，初始化为不缩放、不平移print(m.weight) # tensor([1., 1.], requires_grad=True)print(m.bias) # tensor([0., 0.], requires_grad=True) # 操作 m.weight 和 m.bias ，你将看到网络产生不同的输出input = torch.arange(1*2*3*4, dtype=torch.float).view(1,2,3,4)output = m(input)print(output) 当 afine=true 时， weight($\\gamma$) 和 bias($\\beta$) 都为 None 举例： m = torch.nn.BatchNorm2d(2,affine=False)print(m.weight) # Noneprint(m.bias) # None track_running_stats ：如果为 True ，则针对每次 mini-batch 结合上次的历史信息动态统计，如果为 false ，则使用该次 mini-batch 的静态统计信息。 计算步骤： 先对输入按照通道进行归一化， $\\mathbf E(x)$ 为计算的均值， $\\mathbf{Var}(x)$ 为计算的方差 然后对归一化的结果按照通道进行缩放和平移，设置 affine=True ，即意味着 weight($\\gamma$) 和 bias($\\beta$) 将被使用大小推导：输入：$(N, C, H, W)$ ，输出：$(N, C, H, W)$用法：m = nn.BatchNorm2d(100) # 输入通道 100 batch &amp;amp; mini-batch这里顺便聊聊 batch 和 mini-batch 的区别： batch ：整个数据集，遍历一次完整的数据集称为一个 epoch 。遍历完所有输入数据后才进行参数更新。 mini-batch ：将整个数据集分成几组，每次同时送入的一批数据称为一个 mini-batch 。每次迭代进行参数更新。其中 mini-batch 的方案在现在应用更为广泛，它是以下两种方案的折中： 批梯度下降 Batch gradient descent ： 遍历全部数据集算一次损失函数，然后计算梯度更新参数。这种方法每更新一次参数需要遍历整个数据集，计算量开销大，计算速度慢，不支持在线学习。但是由于梯度下降方向稳定，不容易震荡。 随机梯度下降 Stochastic gradient descent ： 每输入一个数据就更新参数。这种方法速度比较快，但不容易收敛，会在最有点附近剧烈晃动，且梯度下降过程震荡剧烈。 为了结合上述两种方法的优势，克服各自的缺点，我们采用小批量梯度下降。一个 mini-batch 中的数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为 mini-batch 的样本数与整个数据集相比小了很多，每次更新所需的计算量也不是很大。2) nn.GroupNormclass torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True, device=None, dtype=None)论文来源： Group Normalization 。\\(y = \\cfrac{x-\\mathbf E[x]}{\\sqrt{\\mathbf{Var}[x]+\\epsilon}} * \\gamma + \\beta\\)输入通道被分成 num_groups 个组，每组有 num_channels / num_groups 个通道，有各自独立计算的均值和标准差。 $\\gamma$ 和 $\\beta$ 是针对每个通道可学习的参数： num_groups ( int ) – 将通道分成的组数 num_channels ( int ) – 输入中预期的通道数 eps – 为数值稳定性添加到分母的值。默认值：1e-5 affine – bool，当设置为 时 True ，该模块具有可学习的每通道仿射参数，初始化为 1（对于权重）和 0（对于偏差）。默认值：True。大小推导：输入：$(N, C, *)$ ，输出：$(N, C, *)$用法：m = nn.GroupNorm(3, 6) # Separate 6 channels into 3 groups6. 循环层1)Vision Layers（上采样）1) nn.PixelShuffle2) nn.Upsamplehttps://samuel92.blog.csdn.net/article/details/82855946https://zhuanlan.zhihu.com/p/98081181三、各层变量命名规则PyTorch 在对于网络中的参数，采用以下的规则命名变量。了解一下规则，能够帮助我们在需要时知道该如何调用某个变量，比如某层的权重。1) init对于 __init__() 中使用 self 定义的变量会使用这个变量的名字作为存储时的名字。举例：self.conv1 = torch.nn.Conv2d(3, 12, kernel_size=3, stride=1, padding=1) # 卷积层有 2 个参数，对应 conv1.weight 和 conv.bias self.bn1 = torch.nn.BatchNorm2d(12) # 标准化层油 5 个参数，对应 bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, bn1.num_batches_tracked 2) nn.Sequential使用 nn.Sequential 时会根据传入 list 的顺序对其进行标号。举例：conv1 = nn.Conv2d(3, 12, kernel_size=3, stride=1, padding=1)bn1 = nn.BatchNorm2d(12)s1 = [conv1, bn1]self.stage1 = nn.Squential(*s1)# stage1.0.weight, stage1.0.bias# stage1.1.weight, stage1.1.bias, stage1.1.running_mean, stage1.1.running_var, stage1.1.num_batches_tracked注意此时的 conv1 和 bn1 都没有 self ， stage1 有 self ，而 s1 是 python 基本数据类型。3) DataParallel/DistributedDataParallel当一个 module 被 from torch.nn import DataParallel 或者 from torch.nn.parallel import DistributedDataParallel 包围住后，会在这个变量名后面加上 module. 。举例：conv1 = nn.Conv2d(3, 12, kernel_size=3, stride=1, padding=1)bn1 = nn.BatchNorm(12)s1 = [conv1, bn1]stage1 = nn.Sequential(*s1)self.stage2 = DataParallel(stage1)# stage2.module.0.weight, stage2.module.0.bias# stage2.module.1.weight, stage2.module.1.bias, stage2.module.1.running_mean, stage2.module.1.running_var, stage2.module.1.num_batches_tracked注意只有 stage2 前面有 self 。4) 综合下面举两个综合起来的例子供读者练习。Example 1：import torchimport torch.nn as nnimport torch.nn.functional as Fimport numpy as npfrom torch.nn import DataParallelfrom torch.nn.parallel import DistributedDataParallelimport torch.distributed as dist class CNN(nn.Module): def __init__(self): super(CNN, self).__init__() self.conv1 = nn.Conv2d(3, 12, kernel_size=3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(12) self.s1 = [self.conv1, self.bn1] self.stage1 = nn.Sequential(*self.s1) self.conv2 = nn.Conv2d(12, 24, kernel_size=3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(24) self.fc1 = nn.Linear(24 * 5 * 5, 128) self.fc2 = nn.Linear(128, 10) def forward(self, x): x = F.relu(self.bn1(self.conv1(x))) x = F.relu(self.bn2(self.conv2(x))) x = x.view(-1, 24 * 5 * 5) x = F.relu(self.fc1(x)) x = self.fc2(x) return x if __name__ == &#39;__main__&#39;: model = CNN() for name in model.state_dict(): print(name)解析： self.conv1 和 self.bn1 通过 self.s1 传入 Sequential ，所以 self.stage 会根据出现顺序进行编号，但原本的 self.conv1 和 self.bn1 仍然存在，同时 self.s1 并没有，虽然它有 self ，但是它不是 pytorch 自带的层，是 python 的基本数据结构。conv1.weight、conv1.biasbn1.weight、bn1.bias、bn1.running_mean、bn1.running_var、bn1.num_batches_trackedstage1.0.weight、stage1.0.biasstage1.1.weight、stage1.1.bias、stage1.1.running_mean、stage1.1.running_var、stage1.1.num_batches_trackedconv2.weight、conv2.biasbn2.weight、bn2.bias、bn2.running_mean、bn2.running_var、bn2.num_batches_trackedfc1.weight、fc1.biasfc2.weight、fc2.biasExample2：import torchimport torch.nn as nnimport torch.nn.functional as Fimport numpy as npfrom torch.nn import DataParallelfrom torch.nn.parallel import DistributedDataParallelimport torch.distributed as dist class CNN(nn.Module): def __init__(self): super(CNN, self).__init__() conv1 = nn.Conv2d(3, 12, kernel_size=3, stride=1, padding=1) bn1 = nn.BatchNorm2d(12) s1 = [conv1, bn1] self.stage1 = nn.Sequential(*s1) self.stage2 = DataParallel(self.stage1) self.conv2 = nn.Conv2d(12, 24, kernel_size=3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(24) self.fc1 = nn.Linear(24 * 5 * 5, 128) self.fc2 = nn.Linear(128, 10) def forward(self, x): x = self.stage2(x) x = F.relu(self.bn2(self.conv2(x))) x = x.view(-1, 24 * 5 * 5) x = F.relu(self.fc1(x)) x = self.fc2(x) return x if __name__ == &#39;__main__&#39;: model = CNN() model = DataParallel(model) for name in model.state_dict(): print(name)解析：self.stage1 按照 Sequential 进行编号， self.stage 通过 DataParallel 进行包裹，因此会在 stage2 后面多出 module. ，由于最后的 model 也被 DataParallel 包裹，所以 CNN 里面所有变量前面都多了 module. 。module.stage1.0.weight、module.stage1.0.biasmodule.stage1.1.weight、module.stage1.1.bias、module.stage1.1.running_mean、module.stage1.1.running_var、module.stage1.1.num_batches_trackedmodule.stage2.module.0.weight、module.stage2.module.0.biasmodule.stage2.module.1.weight、module.stage2.module.1.bias、module.stage2.module.1.running_mean、module.stage2.module.1.running_var、module.stage2.module.1.num_batches_trackedmodule.conv2.weight、module.conv2.biasmodule.bn2.weight、module.bn2.bias、module.bn2.running_mean、module.bn2.running_var、module.bn2.num_batches_trackedmodule.fc1.weight、module.fc1.biasmodule.fc2.weight、module.fc2.bias如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！、参考文献 TORCH.NN pytorch中存储各层权重参数时的命名规则，为什么有些层的名字中带module. pytorch中文文档-torch.nn常用函数-待添加 pytorch的函数中的dilation参数的作用 pytorch卷积操作nn.Conv中的groups参数用法解释 nn.ConvTranspose2d的参数output_padding的作用 Batch、Mini-batch和随机梯度下降的区别和Python示例 https://github.com/vdumoulin/conv_arithmetic Pytorch池化层Maxpool2d中ceil_mode参数 作者：Harry-hhj，github主页：传送门" }, { "title": "Markdown Fomula", "url": "/posts/Markdown-Formula/", "categories": "Tutorial, MathJax", "tags": "tools, latex, markdown", "date": "2021-09-03 18:00:00 +0800", "snippet": "Markdown 公式编辑教程Markdown 中的数学公式，其背后是由 MathJax 提供支持的。MathJax 是一个开源的 web 数学公式渲染器，由 JS 编写而成，提供和 LaTex 一样的公式书写方式。一般公式分为两种，可以理解为一种特殊的代码块： 行内公式：由 $ 将公式代码块括起 效果：$\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt$ 源代码： $\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt$ 行间公式：由 $$ 将公式代码块括起 效果：\\(\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt\\) 源代码： $$\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt$$ 一、希腊字母 大写 code 小写 code 名称 $A$ A $\\alpha$ \\alpha alpha $B$ B $\\beta$ \\beta beta $\\Gamma$ \\Gamma $\\gamma$ \\gamma gamma $\\Delta$ \\Delta $\\delta$ \\delta delta $E$ E $\\epsilon$ \\epsilon epsilon $Z$ Z $\\zeta$ \\zeta zeta $H$ H $\\eta$ \\eta eta $\\Theta$ \\Theta $\\theta$ \\theta theta $I$ I $\\iota$ \\iota iota $K$ K $\\kappa$ \\kappa kappa $\\Lambda$ \\Lambda $\\lambda$ \\lambda \\lambda $M$ M $\\mu$ \\mu \\mu $N$ N $\\nu$ \\nu nu $\\Xi$ \\Xi $\\xi$ \\xi xi $O$ O $\\omicron$ \\omicron omicron $\\Pi$ \\Pi $\\pi$ \\pi pi $P$ P $\\rho$ \\rho rho $\\Sigma$ \\Sigma $\\sigma$ \\sigma sigma $T$ T $\\tau$ \\tau tau $\\Upsilon$ \\Upsilon $\\upsilon$ \\upsilon upsilon $\\Phi$ \\Phi $\\phi$ \\phi phi $X$ X $\\chi$ \\chi chi $\\Psi$ \\Psi $\\psi$ \\psi psi $\\Omega$ \\Omega $\\omega$ \\omega omega 二、符号位置（1）上下标上标：^{}下标：_{}当上下标仅为一个元素时，{} 可以省略。举例：x_i^2 表示 $x_i^2$（2）底部符号在符号底部写符号： \\underset{}{}在符号顶部写符号： \\overset{}{}举例： \\underset{0\\le j \\le k-1}{\\arg \\min} 表示 $\\underset{0\\le j \\le k-1}{\\arg \\max}$ ， a\\overset{?}=b 表示 $a\\overset{?}=b$（3）底部换行在符号下部换行： \\understack{}举例： \\sum_{\\substack{0 \\le i \\le n \\\\ 0 \\le j \\le n}} A_{ij} 表示 $\\sum_{\\substack{0 \\le i \\le n \\ 0 \\le j \\le n}} A_{ij}$三、括号1. 小括号、方括号使用原始的 () 、[]举例：(2+3)[4*4] 表示 $(2+3)[4*4]$。2. 大括号需使用转义符号 \\ 阻止解析：\\{\\} 或使用 \\lbrace 和 rbrace举例：\\{a*b\\}:a*b 或 \\lbrace a*b \\rbrace:a*b 表示 $\\lbrace ab \\rbrace:ab$3. 尖括号\\langle 和 \\rangle举例：\\langle x \\rangle 表示 $\\langle x \\rangle$4. 上取整\\lceil 和 rceil举例：\\lceil x \\rceil 表示 $\\lceil x \\rceil$5. 下取整\\lfloor 和 \\rceil举例：\\lceil x \\rceil 表示 $\\lceil x \\rceil$四、求和、乘积、求导、积分1. 求和\\sum_{}^{} ，其下标表示求和下限，上标表示求和上限使用 \\limits 控制下标是在符号右侧还是上下侧举例：\\sum_1^n 表示 $\\sum_1^n$ ， \\sum\\limits_{i=1} 表示 $\\sum\\limits_{i=1}$2. 乘积\\prod_{}^{} ，其下标表示乘积下限，上标表示乘积上限使用 \\limits 控制下标是在符号右侧还是上下侧举例：\\prod_i^n 表示 $\\prod_i^n$ ，\\prod\\limits_i^n 表示 $\\prod\\limits_i^n$3. 求导导数： \\cfrac{\\mathrm{d}y}{\\mathrm{d}x}偏导数： \\cfrac{\\partial y}{\\partial x}举例：导数 $\\cfrac{\\mathrm{d}y}{\\mathrm{d}x}$ ，偏导数 $\\cfrac{\\partial y}{\\partial x}$4. 积分\\int_{}^{} ，其下标表示积分下限，上标表示积分上限举例：\\int_0^\\infty 表示 $\\int_0^\\infty$多重积分：\\iint 表示 $\\iint$ 、 \\iiint 表示 $\\iiint$ 、 \\iiiint 表示 $\\iiiint$5. 其他\\bigcup 表示 $\\bigcup$\\bigcap 表示 $\\bigcap$五、分式与根式1. 分式\\frac{}{} 或 {}\\over{}举例：\\frac ab 表示 $\\frac ab$ ，a \\over b 表示 $a \\over b$2. 连分数\\cfrac 而不要使用 \\frac举例：x=a_0 + \\cfrac {1^2}{a_1 + \\cfrac {2^2}{a_2 + \\cfrac {3^2}{a_3 + \\cfrac {4^2}{a_4 + \\cdots}}}} 表示 $x=a_0 + \\cfrac {1^2}{a_1 + \\cfrac {2^2}{a_2 + \\cfrac {3^2}{a_3 + \\cfrac {4^2}{a_4 + \\cdots}}}}$3. 根式\\sqrt[]{} ，其中 [] 表示根式的次数， {} 表示根式的内容举例：\\sqrt[4]{\\frac xy} 表示 $\\sqrt[4]{\\frac xy}$六、多行表达式1. 分类表达式\\begin{cases} 和 \\end{cases} ，其中使用 \\\\ 换行，使用 &amp;amp; 指示需要对齐的位置，\\ 表示空格。举例：f(n)\\begin{cases}\\cfrac n2, &amp;amp;if\\ n\\ is\\ even\\\\3n + 1, &amp;amp;if\\ n\\ is\\ odd\\end{cases}表示\\(f(n)\\begin{cases}\\cfrac n2, &amp;amp;if\\ n\\ is\\ even\\\\3n + 1, &amp;amp;if\\ n\\ is\\ odd\\end{cases}\\)使用 \\\\[2ex] 代替 \\\\ （相当于 \\\\[1ex]）增大分类之间的垂直距离，以此类推。2. 方程\\begin{equation} 和 \\end{equation}举例：\\begin{equation}a = b + c - d\\end{equation}表示\\(\\begin{equation}a = b + c - d\\end{equation}\\)3. 多行表达式\\begin{split} 和 \\end{split}举例：\\begin{equation}\\begin{split} a&amp;amp;=b+c-d \\\\ &amp;amp;\\quad +e-f\\\\ &amp;amp;=g+h\\\\ &amp;amp; =i \\end{split}\\end{equation}表示\\(\\begin{equation}\\begin{split} a &amp;amp; = b + c - d \\\\ &amp;amp; \\quad + e - f \\\\ &amp;amp; = g + h \\\\ &amp;amp; = i \\end{split}\\end{equation}\\)4. 方程组\\left \\{ 与 \\right . 和 \\begin{array} 和 \\end{array} 配合使用，或使用 \\beign{cases} 与 \\end{cases}举例：\\left \\{ \\begin{array}{c}a_1x+b_1y+c_1z=d_1 \\\\ a_2x+b_2y+c_2z=d_2 \\\\ a_3x+b_3y+c_3z=d_3\\end{array}\\right .表示\\(\\left \\{ \\begin{array}{c}a_1x+b_1y+c_1z=d_1 \\\\ a_2x+b_2y+c_2z=d_2 \\\\ a_3x+b_3y+c_3z=d_3\\end{array}\\right .\\)七、特殊函数与符号1. 三角函数\\sin x 表示 $\\sin x$\\cos x 表示 $\\cos x$\\arctan x 表示 $\\arctan x$以此类推2. 比较符号小于 $\\lt$ ：\\lt大于 $\\gt$：\\gt小于等于 $\\le$：\\le大于等于 $\\ge$ ：\\ge不等于 $\\ne$ ：\\ne3. 集合关系与运算并集 $\\cup$ ：\\cup交集 $\\cap$ ：\\cap差集 $\\setminus$ ：\\setminus子集 $\\subset$ ：\\subset父集 $\\supset$ ：\\supset属于 $\\in$ ：\\in不属于 $\\notin$ ：\\notin包含 $\\subseteq$ ：\\subseteq非包含 $\\subsetneq$ ：\\subsetneq空集 $\\emptyset$ ：\\emptyset空 $\\varnothing$ ：\\varnothing4. 排列组合二项式 $\\binom{n+1}{2k}$ ：\\binom{n+1}{2k} 或 {n+1 \\choose 2k}5. 箭头$\\to$ ：\\to$\\rightarrow$ ：\\rightarrow$\\leftarrow$ ： \\leftarrow$\\leftrightarrow$ ： \\leftrightarrow$\\uparrow$ ： \\uparrow$\\downarrow$ ： \\downarrow$\\updownarrow$ ： updownarrow$\\Rightarrow$ ： \\Rightarrow$\\Leftarrow$ ： \\Leftarrow$\\Leftrightarrow$ ： \\Leftrightarrow$\\Uparrow$ ： \\Uparrow$\\Downarrow$ ： \\Downarrow$\\Updownarrow$ ： Updownarrow$\\longrightarrow$ ： \\longrightarrow$\\longleftarrow$ ： \\longleftarrow$\\longleftrightarrow$ ： \\longleftrightarrow$\\Longrightarrow$ ： \\Longrightarrow$\\Longleftarrow$ ： \\Longleftarrow$\\Longleftrightarrow$ ： \\Longleftrightarrow$\\xleftarrow[T]{n=0}$ ： \\xleftarrow[]{}$\\xrightarrow[T]{n&amp;gt;0}$ ： \\xrightarrow[]{}$\\mapsto$ ： \\mapsto更多箭头符号可以查看这篇教程。6. 逻辑运算符$\\land$： \\land$\\lor$： \\lor$\\lnot$： \\lnot$\\forall$： \\forall$\\exists$： \\exists$\\top$： \\top$\\bot$： \\bot$\\vdash$： \\vdash$\\vDash$： \\vDash7. 定义$\\triangleq$ ： \\triangleq8. 操作符$\\star$： \\star$\\ast$： \\ast$\\oplus$：\\oplus$\\circ$： \\circ$\\bullet$： \\bullet9. 等于$\\approx$： \\approx$\\sim$： \\sim$\\cong$： \\cong$\\equiv$： \\equiv$\\prec$： \\prec10. 范围$\\infty$： infty$\\aleph_o$： aleph_o$\\nabla$ ： \\nabla$\\partial$： \\partial$\\Im$： \\Im$\\Re$： \\Re11. 模运算$\\pmod p$： pmod p12. 点$\\ldots$： ldots$\\cdots$： cdots$\\cdot$： cdot八、顶部符号$\\hat x$： \\hat{}$\\widehat{xy}$： \\widehat{}$\\overline x$： \\overline{}$\\vec x$：\\vec{}$\\overrightarrow x$：\\overrightarrow{}$\\dot x$ ： \\dot{}$\\ddot x$： \\ddot{}九、表格\\begin{array}{列样式} 和 \\end{array}TODO：列样式\\begin{array}{c|lcr}n &amp;amp; \\text{Left} &amp;amp; \\text{Center} &amp;amp; \\text{Right} \\\\\\hline1 &amp;amp; 0.24 &amp;amp; 1 &amp;amp; 125 \\\\2 &amp;amp; -1 &amp;amp; 189 &amp;amp; -8 \\\\3 &amp;amp; -20 &amp;amp; 2000 &amp;amp; 1+10i \\\\\\end{array}效果：\\(\\begin{array}{c|lcr}n &amp;amp; \\text{Left} &amp;amp; \\text{Center} &amp;amp; \\text{Right} \\\\\\hline1 &amp;amp; 0.24 &amp;amp; 1 &amp;amp; 125 \\\\2 &amp;amp; -1 &amp;amp; 189 &amp;amp; -8 \\\\3 &amp;amp; -20 &amp;amp; 2000 &amp;amp; 1+10i \\\\\\end{array}\\)十、矩阵1. 基本\\begin{matrix} 和 \\end{matrix}\\begin{matrix}1 &amp;amp; x &amp;amp; x^2 \\\\1 &amp;amp; y &amp;amp; y^2 \\\\1 &amp;amp; z &amp;amp; z^2 \\\\\\end{matrix}效果：\\(\\begin{matrix}1 &amp;amp; x &amp;amp; x^2 \\\\1 &amp;amp; y &amp;amp; y^2 \\\\1 &amp;amp; z &amp;amp; z^2 \\\\\\end{matrix}\\)2. 加括号可以使用 \\left 和 \\right 配合表示括号符号，也可以使用特殊矩阵：pmatrix： \\(\\begin{pmatrix}1&amp;amp;2\\\\3&amp;amp;4\\\\\\end{pmatrix}\\)bmatrix： \\(\\begin{bmatrix}1&amp;amp;2\\\\3&amp;amp;4\\\\\\end{bmatrix}\\)Bmatrix： \\(\\begin{Bmatrix}1&amp;amp;2\\\\3&amp;amp;4\\\\\\end{Bmatrix}\\)vmatrix： \\(\\begin{vmatrix}1&amp;amp;2\\\\3&amp;amp;4\\\\\\end{vmatrix}\\)Vmatrix： \\(\\begin{Vmatrix}1&amp;amp;2\\\\3&amp;amp;4\\\\\\end{Vmatrix}\\)3. 省略元素$\\cdots$ ： \\cdots$\\vdots$ ： \\vdots$\\ddots$ ：\\ddots举例：\\begin{pmatrix}1&amp;amp;a_1&amp;amp;a_1^2&amp;amp;\\cdots&amp;amp;a_1^n\\\\1&amp;amp;a_2&amp;amp;a_2^2&amp;amp;\\cdots&amp;amp;a_2^n\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\1&amp;amp;a_m&amp;amp;a_m^2&amp;amp;\\cdots&amp;amp;a_m^n\\\\\\end{pmatrix}效果：\\(\\begin{pmatrix}1&amp;amp;a_1&amp;amp;a_1^2&amp;amp;\\cdots&amp;amp;a_1^n\\\\1&amp;amp;a_2&amp;amp;a_2^2&amp;amp;\\cdots&amp;amp;a_2^n\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\1&amp;amp;a_m&amp;amp;a_m^2&amp;amp;\\cdots&amp;amp;a_m^n\\\\\\end{pmatrix}\\)4. 增广矩阵\\left 与 \\right 和 \\begin{array} 与 \\end{array}举例：\\left[\\begin{array}{cc|c}1&amp;amp;2&amp;amp;3\\\\4&amp;amp;5&amp;amp;6\\end{array}\\right]效果：\\(\\left[\\begin{array}{cc|c}1&amp;amp;2&amp;amp;3\\\\4&amp;amp;5&amp;amp;6\\end{array}\\right]\\)十一、公式标记与引用\\tag{} 来标记公式，如果以后需要引用此公式，还需要加上 \\label{} 在 \\tag{} 之后。举例：a := x^2 - y^3 \\tag{10}\\label{10}效果：\\(a := x^2 - y^3 \\label{10}\\)\\stackrel{\\eqref{}}{} 引用公式。举例：a + y^3 \\stackrel{\\eqref{10}}= x^2效果：\\(a + y^3 \\stackrel{\\eqref{10}}= x^2\\)\\stackrel{\\ref{}}{} 不带括号引用。举例a + y^3 \\stackrel{\\ref{10}}= x^2效果：\\(a + y^3 \\stackrel{\\ref{10}}= x^2\\)十二、字体1. 黑板粗体字\\mathbb 或 \\Bbb ，此字体常用来表示实数、整数、有理数、复数和大写字母。举例：\\mathbb CHNQRZ\\Bbb CHNQRZ效果：\\(\\mathbb CHNQRZ\\)2. 黑体字\\mathbf举例：\\mathbf CHNQRZ效果：\\(\\mathbf CHNQRZ\\)3. 打印机字体\\mathtt举例：\\mathtt ABCDEFGHIJKLMNOPQRSTUVWXYZ效果：\\(\\mathtt ABCDEFGHIJKLMNOPQRSTUVWXYZ\\)4. 罗马字体\\mathrm举例：\\mathrm abcdefghijklmnopqrstuvwxyz效果：\\(\\mathrm abcdefghijklmnopqrstuvwxyz\\)5. 手写字体\\mathscr举例：\\mathscr abcdefghijklmnopqrstuvwxyz效果：\\(\\mathscr abcdefghijklmnopqrstuvwxyz\\)6. Fraktur 字母（一种德国字体）\\mathfrak举例：\\mathfrak ABCDEFGHIJKLMNOPQRSTUVWXYZ效果：\\(\\mathfrak ABCDEFGHIJKLMNOPQRSTUVWXYZ\\)十三、颜色\\color{}举例： 颜色 源码 效果 黑色 \\color{black}{text} \\(\\color{black}{text}\\) 灰色 \\color{grey}{text} \\(\\color{grey}{text}\\) 银色 \\color{silver}{text} \\(\\color{silver}{text}\\) 白色 \\color{white}{text} \\(\\color{white}{text}\\) 褐红色 \\color{maroon}{text} \\(\\color{maroon}{text}\\) 红色 \\color{red}{text} \\(\\color{red}{text}\\) 黄色 \\color{yellow}{text} \\(\\color{yellow}{text}\\) 绿黄色 \\color{lime}{text} \\(\\color{lime}{text}\\) 橄榄色 \\color{olive}{text} \\(\\color{olive}{text}\\) 绿色 \\color{green}{text} \\(\\color{green}{text}\\) 深蓝绿 \\color{teal}{text} \\(\\color{teal}{text}\\) 水绿色 \\color{aqua}{text} \\(\\color{aqua}{text}\\) 蓝色 \\color{blue}{text} \\(\\color{blue}{text}\\) 海军蓝 \\color{navy}{text} \\(\\color{navy}{text}\\) 紫色 \\color{purple}{text} \\(\\color{purple}{text}\\) 浅莲红 \\color{fuchsia}{text} \\(\\color{fuchsia}{text}\\) 十四、其他1. 空格MathJax 通过内部策略管理自己的公式内的空间，因此公式中无论空多少格最后都不会有效果，可以插入\\, 增加些许间隙，插入 \\; 插入较宽的间隙，\\quad 与 \\qquad 会增肌更大的间隙。2. 括号任何运算符后的 {} 在只有单个字符时可以省略，但此时如果为单个字母则需加入空格分隔。如：\\frac12 表示 $\\frac12$ ，\\frac ab 表示 $\\frac ab$。3. 转义对于 MathJax 的保留字符，如 \\ 、 {} 等，如果不是为了解析，那么需要在前面添加转义字符 \\ 。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！十五、参考文献 Mathjax公式教程作者：Harry-hhj，github主页：传送门" }, { "title": "Install OpenCV", "url": "/posts/Install-OpenCV/", "categories": "Tutorial, Computer Vision, OpenCV", "tags": "install, computer science, opencv", "date": "2021-08-31 14:15:00 +0800", "snippet": "OpenCV 安装教程 机械是血肉，电控是大脑，视觉是灵魂。一、安装环境 Ubuntu 系统版本：20.04 LTS，链接: https://pan.baidu.com/s/1ojBoCBSHbMVZHhD8HOHYyA 提取码: 76wv（不建议下载，因为反而慢） OpenCV 版本：4.5.3，链接: https://pan.baidu.com/s/1foen04ULGOwGpwLJUwvS2A 提取码: vwmq OpenCV_contrib版本：需与 OpenCV 一致，链接: https://pan.baidu.com/s/1wI7IgSBt3sSBjE374Gnksg 提取码: 7mef通过 Github 访问可能会非常缓慢，所以我们提供了百度网盘下载地址。二、前言OpenCV （开源的计算机视觉库）是基于 BSD 协议，因此它可免费用于学术和商业用途。其提供 C++ 、 C 、 Python 和 Java 接口，支持 Windows 、 Linux 、 Mac OS 、 iOS 和 Android 。OpenCV 致力于高效运算和即时应用开发。因其是用优化的 C/C++ 编写的，故其可以充分利用多核处理优势，并且还启用了 OpenSL ，它可以利用底层异构计算平台的硬件加速。可以说，想要入门机器视觉，安装 OpenCV 是躲不掉的第一步。我在 RoboMaster 的组员一年后还在参考此教程，足见它的实用性了。配置环境是做项目的第一步，也是非常重要的一步，如果你希望培养自己的这种能力，我非常鼓励你先自己查找资料探索整个安装步骤，并给出你可能需要查阅资料用到的关键词：Git 、 OpenCV 、 OpenCV_contrib 、 cmake/cmake-gui 、以及可能出现的问题：权限不足、文件下载失败（TimeOut）等，这些问题一般只需要搜索关键字或将报错的句子复制到搜索引擎中，就能找到解决方法，其中大部分问题在 CSDN 中都有解答，少部分问题需要查阅 Overstackflow 查看英文解决方法，查阅官方资料（实际上这是最重要的一种方式）和论坛也是一种不错的方法。三、OpenCV 安装详细步骤准备阶段一般来说我们的电脑都是 Windows 和 MacOS 为操作系统的，虽然在它们上面也能进行开发，但是使用体验不如 Linux 系统方便畅快。我这么说的原因是： 大部分开发环境对于 Linux 的支持更好，操作以终端命令为主，环境部署效率高，而Windows 和 MacOS 则对图形化界面更友好，舒适度取决于软件开发商 Linux 本身就是面向服务器而非个人电脑的，因此更适合于大型项目的开发，其系统运行效率更高 相比较而言 Linux 更加简洁，很适合喜欢简洁的程序员 当然，这都看个人喜好，只要你用得顺手，对个人开发而言其实无所谓为了拥有一个我们自己的 Linux 系统，有三种方法： 安装双系统 配置虚拟机 再买一台电脑重装 Linux ：和安装双系统差不多，不做介绍如果您的主机性能良好，那么这两个方案都是可选的，如果它的性能不足以同时运行两个系统，那么安装双系统可能是一个比较合理的选择。如果这两个方案都是可选的，那么首先你需要明白它们的优劣： 双系统 优点：硬件使用效率更高，所有电脑的硬件将只被一个系统使用；能够使用 GPU ，如果你的开发需要使用 GPU ，如深度学习，那么安装双系统将是你唯一的选择。 缺点：无法同时使用日常的操作系统，切换系统需要重启。 虚拟机： 优点：可以快速进行操作系统间的切换，以及之间的文件传输；虚拟机环境损坏后重装更方便一些，且拥有系统快照功能，方便一键还原 缺点：同时运行两个系统，消耗系统资源；虚拟机支持软件需要付费（VM 对学生免费） 由于虚拟机安装更快且坑较少，所以本篇教程现以虚拟机安装为主，而对双系统教程将会另外出一篇教程讲述。一般配置的 Linux 虚拟机至少需要分配 1 核 2 GB 才能运行起来，如果要运行比较耗资源的项目的话， 2 核 4 GB 是推荐的选择，当然，SSD 的速度能在一定程度上弥补内存的不足。在安装完虚拟机后，仍应留有一定的资源供主机使用。一种直观的感受是，如果你的虚拟机运行卡顿，那么首先看你装在哪里，如果是机械硬盘，那么情有可原，试着提高分配的内存，不行再提高分配的核心，如果是固态硬盘，那么就意味着分配的核心或内存太少了，根据情况提高核心或内存或同时提高。如果你选择了双系统，那么请提前规划好你的硬盘容量，因为双系统会在安装时需要固定死系统容量，当然以后改的方法还是有点。如果你选择了虚拟机，那么你需要一个底层的支撑软件，比如 VMware 、 Parallel Desktop 等，前者作为交大的学生可以在网络信息服务中心申请免费使用。安装完虚拟机之后，就可以正式开始安装 OpenCV 了。首先，我们先确保系统安装了一些基本的依赖库，打开终端输入以下命令：sudo apt install git gcc g++ ffmpeg cmake cmake-gui make python3-dev python3-numpy python3-pip libavcodec-dev libavformat-dev libswscale-dev libgstreamer-plugins-base1.0-dev libgstreamer1.0-dev libgtk-3-dev libpng-dev libjpeg-dev libopenexr-dev libtiff-dev libwebp-dev libavresample-dev libtbb-devsudo add-apt-repository &quot;deb http://security.ubuntu.com/ubuntu xenial-security main&quot;sudo apt updatesudo apt install libjasper1 libjasper-dev如果想要升级 gcc/g++ 版本，请看这篇文章中的相关部分。如果想要安装最新版的 cmake ，可以参考这篇教程。（非必须，推荐）安装 aptitude ：sudo apt install aptitude（非必须）安装 Boost 和 Eigen3：sudo apt install libboost-all-devsudo apt-get install libeigen3-dev（非必须）安装 ceres：首先打开终端，添加源：sudo gedit /etc/apt/sources.list不然你可能会遇到以下问题：在文件中加入：deb http://cz.archive.ubuntu.com/ubuntu trusty main universe然后关闭，在终端输入以下命令，更新源并安装依赖库：sudo apt updatesudo apt-get install liblapack-dev libsuitesparse-dev libcxsparse3.1.2 libgflags-dev libgoogle-glog-dev libgtest-dev然后 git clone https://github.com/ceres-solver/ceres-solver.git 从 GitHub 下载 ceres-solver 至 Applications 文件夹，在项目目录下打开终端：mkdir buildcd buildcmake ..make -j$(nproc)sudo make install（非必须）安装 qt5，这样 OpenCV 将会和 Qt 一同编译：sudo apt install qt5-default qtcreator（虚拟机安装不了）CUDA：教程将会另外发布。当然还有一些其他的 Ubuntu 配置，比如中文输入法等，有需要的话自己查资料配置。这里提一下，如果你以后希望使用 JetBrain 全家桶（e.g. Clion、Pycharm）的话，那么请不要安装搜狗输入法，会导致程序异常退出。另外，搜狗输入法也不支持 Ubuntu 20.04 ，请安装 fcitx 下的 Google 输入法。编译阶段在安装了所需的依赖后，我们终于可以编译 OpenCV 了。先从 GitHub 下载最新版的 OpenCV 和 OpenCV_contrib ，点击下图红框，选择下拉按钮 master -&amp;gt; Tags -&amp;gt;4.5.3 。然后点击右侧绿色按钮 Code，如果你打算选择最新的版本，直接复制地址，如果你选择了特定的版本，那么点击 Download ZIP ，解压至之后的 Applications 文件夹下。在 Ubuntu 中打开终端（Terminal），输入以下命令：cd ~mkdir Applicationscd Applications# 以下命令针对复制网址下载的git clone &amp;lt;path/of/opencv&amp;gt;git clone &amp;lt;path/of/opencv_contrib&amp;gt;将 opencv_contrib 目录移动到 opencv 目录中，以下使用 &amp;lt;opencv&amp;gt; 和 &amp;lt;opencv_contrib&amp;gt; 分别代表着两个文件夹名，根据实际情况带入修改：cd ~/Applications/&amp;lt;opencv&amp;gt;mkdir build最终应该如下图：接下来借助 cmake-gui 编译，打开终端输入：cmake-gui在出现的界面中，点击 Browse Source 选择源文件目录 opencv ，点击 Browse Build 选择编译文件存放目录 build ，然后点击 Configure 。会跳出一个弹窗，下拉框中选择 Unix Makefiles ，然后点击 Finish 。完成后界面如下：然后我们需要修改两个地方： 通过 search 找到 CMAKE_BUILD_TYPE 处，输入 Release 。 在 OPENCV_EXTRA_MODULES_PATH 处加入 opencv_contrib 模块路径。注意，不是选 opencv_contrib 文件夹，而是需要选中 opencv_contrib 里面的 modules 文件夹！ 这里说明一下，CMAKE_INSTALL_PREFIX 为安装路径，系统默认为 /usr/local ，如若对 Ubuntu 不熟悉，则不要更改，默认就好。确认无误后，点击 Configure ；先排除四个常见的问题： ade* 无法下载：手动下载（链接: https://pan.baidu.com/s/1oVUeBL6cbxeczRAd22-CHw 提取码: j2v7），存放在 Downloads 文件夹里，打开 &amp;lt;opencv&amp;gt;/modules/gapi/cmake/DownloadADE.cmake ，把第 10 行更换成自己下载的文件目录路径，例如 /home/&amp;lt;username&amp;gt;/Downloads/ ，其中 &amp;lt;username&amp;gt; 代表你的用户名。重新 Configure 。 ippicv_* 无法下载：手动下载（链接: https://pan.baidu.com/s/1g6gZ8CrvdE9VWGmp8XmDyw 提取码: hbor），存放在 Downloads 文件夹里，打开 &amp;lt;opencv&amp;gt;/3rdparty/ippicv/ippcv.cmake ，把 42 行路径更换成自己的下载的文件目录路径，例如 /home/&amp;lt;username&amp;gt;/Downloads/ ，其中 &amp;lt;username&amp;gt; 代表你的用户名。重新 Configure 。 face_landmark_model.dat 无法下载：手动下载（链接: https://pan.baidu.com/s/1DKkQTfAY-F91r9vZ6qPUYw 提取码: pe82），存放在 Downloads 文件夹里，打开相应的配置文件 &amp;lt;opencv&amp;gt;/&amp;lt;opencv_contrib&amp;gt;/modules/face/CMakeLists.txt ，将 CMakeLists.txt 文件的第 19 行修改为本地路径，即将原来的网址修改为下载的文件保存的路径，&quot;/home/&amp;lt;username&amp;gt;/Downloads/&quot; ，其中 &amp;lt;username&amp;gt; 代表你的用户名。重新 Configure 。 boostdesc_*.i 、 vgg_generated_*.i ：手动下载（链接: https://pan.baidu.com/s/1VCdMUUm2ipu-fbL2189lFg 提取码: 88eo），存放在 &amp;lt;opencv&amp;gt;/&amp;lt;opencv_contrib&amp;gt;/modules/xfeatures2d/src/ 路径下即可，无需修改文件。 显示 Configuring done 后（注意上翻看看有没有红色的报错，因为即使报错也是会显示 Configuring done 的，当然以上这些报错你不解决其实不会影响多少），点击 Generate 生成文件；这时资源文件就出现在 build 文件夹中，我们可以关闭 cmake 界面了。在 &amp;lt;opencv&amp;gt;/build 中打开终端，输入：make -j$(nproc)此步骤将花费较长时间，尤其是开启 CUDA 选项时。完成后，输入：sudo make install至此 OpenCV 已经完成安装了，你可以删除 &amp;lt;opencv&amp;gt; 整个文件夹。四、IDE 安装从事项目开发，一款得心应手的 IDE 是必不可缺的。笔者目前使用下来有两款 IDE 比较好用： Clion 胜在集成功能全面，配置方便，几乎不用配置任何调试环境就能使用 安装方式：Jetbrain 全家桶对于高校学生免费开放，你可以进入官网申请。选择 For students and teachers 下的 learn more ，用自己的学校邮箱申请，然后打开邮箱内的确认邮件。然后创建自己的 JetBrains Account ，在软件安装完之后的 activate 过程中输入账号密码就可以使用了。 VScode 胜在插件多，支持自定义，适合编程熟练的老手或追求自定义效果的用户，但需另外为项目配置 C++ 调试环境。 安装方式：进入官网下载， Clion 环境配置初次进入 Clion ，需要配置 Toolchains ，创建一个新项目会出现以下弹窗，一般系统会自动检测 cmake 路径，如果没有那么手动选择以下，其余的会自动检测的。如果没有跳出以上弹窗，那么点击左上角 CLion -&amp;gt; Settings 或 Preferences -&amp;gt; Build, Execution, Deployment -&amp;gt; Toolchains ，配置 Default 。VScode 环境配置前往 Ubuntu Software 下载 Visual Studio Code ，然后打开界面如下：点击图中红色区域的按，进入 Extensions ，分别搜索安装以下三个插件：安装完毕后，在任意位置创建一个空目录。VScode 不支持单文件编译，必须具有项目目录。创建完毕后，用 VScode 打开项目目录，点击 Shift+Ctrl+P （Ubuntu 版本快捷键），搜索 cmake:configure ：对每个项目首次进入时，会提示选择工具包，这里我们选择 GCC：在左侧可以先建文件，使用以下示例代码测试。以后每次编译项目，只需要简单地右击 CMakeLists.txt ，选择 Build All Projects ：编译完成后，点击下方 Terminal ，输入以下命令运行程序：cd build./&amp;lt;name/of/binary_file&amp;gt; # 一般与项目同名五、示例代码点击下载，链接: https://pan.baidu.com/s/1nCnebXdNe1XW4e1xzbrXOA 提取码: 80dc。最终运行程序应该出现一张图片显示.apple.png 的窗口。恭喜你安装成功！如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！六、参考教程 OpenCV学习笔记（一） OpenCV简介及安装 VSCode + CMake搭建C/C++开发环境（MacOS篇）作者：Harry-hhj，github主页：传送门" }, { "title": "PyTorch Basics", "url": "/posts/PyTorch-Basics/", "categories": "Tutorial, PyTorch", "tags": "getting started, computer science, pytorch", "date": "2021-08-29 11:12:00 +0800", "snippet": "PyTorch - BasicsPyTorch 是什么Torch 是一个有大量机器学习算法支持的科学计算框架，是一个与 Numpy 类似的张量 Tensor 操作库。PyTorch 是一个基于 Torch 的 Python 开源机器学习库，用于自然语言处理等应用程序。优点： 作为 Numpy 的替代品，可以使用 GPU 的强大计算能力 提供最大的灵活性和高速的深度学习研究平台缺点： 全面性：目前 PyTorch 还不支持快速傅里叶、沿维翻转张量和检查无穷与非数值张量 性能：针对移动端、嵌入式部署以及高性能服务器端的部署其性能表现有待提升 文档：社区还没有那么强大，其 C 库大多数没有文档环境搭建Miniconda3 + PyTorch首先去 Miniconda 官网下载对应系统和 Python 版本的安装包，打开终端运行脚本，按照指令完成 conda 环境搭建。然后前往 PyTorch 官网，按照需求选择，其中 Language 选择 Python ，Compute Platform 根据自己的硬件选择，有 Nvidia GPU 的选择 CUDA 版，有 AMD GPU 的选择 ROC 版（还需另外安装 ROC 环境），不需要或者没有 GPU 的选择 CPU 版。注意 MacOS 系统只能安装 CPU 版。复制命令并在命令行执行即可安装。预备知识TensorTensors （张量），与 Numpy 中的 ndarrays 类似，但是在 PyTorch 中 Tensors 可以使用 GPU 进行计算。在讨论其语法之前，先来说说什么是张量。 标量：一个单独的数 向量：一列有序排列的数，通过次序中的索引可以确定一个数 矩阵：二维数组，每个元素被两个索引唯一确定 张量：几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，标量是零阶张量，矢量是一阶张量，矩阵是二阶张量举个例子，对于任意一张彩色照片，可以表示成一个三阶张量，三个维度分别是图片的高度、宽度和 RGB 通道。下图是一个白色图片的示例：我们继续将这一例子拓展：即：我们可以用四阶张量表示一个包含多张图片的数据集，这四个维度分别是：图片在数据集中的编号，图片高度、宽度，以及 RGB 通道。这种数据表示形式在计算机视觉中非常常见，你可以在这里先有个印象。张量在深度学习中是一个很重要的概念，因为它是一个深度学习框架中的一个核心组件，后续的所有运算和优化算法几乎都是基于张量进行的。常用操作：import torch# 创建一个未初始化的 Tensorx = torch.empty(5, 3)# 创建一个随机初始化的 Tensorx = torch.rand(5, 3) # torch.rand(*sizes, out=None)-&amp;gt;Tensor: [0, 1) 均匀分布x = torch.randn(5, 3) # torch.randn(*sizes, out=None)-&amp;gt;Tensor: 标准正态分布（均值为 0 ，方差为 1 ，即高斯白噪声）x = torch.randint(1, 4, (2, 3, 2)) # torch.randint(low = 0, high, size, out=None, dtype=None)-&amp;gt;Tensor: 整数范围 [low, high)x = torch.randperm(3) # torch.randperm(n, out=None, dtpe=torch.int64)-&amp;gt;LongTensor: 1 到 n 这些数的一个随机序列# 创建 Tensor 并使用现有数据初始化x = torch([5.5, 3])# 其他特殊的创建 Tensor 的方法x = torch.zeros(5, 3, dtype=torch.long) # 全 0 x = torch.ones(5, 3, dtype=torch.double) # 全 1 x = torch.eye(5, 3) # 对角线为 1 x = torch.arange(2, 10, 2) # torch.arange(s, e, step)-&amp;gt;Tensor: 从 s 到 e ，步长为 step x = torch.linspace(2, 10, 3) # torch.linspace(s, e, step)-&amp;gt;Tensor: 从 s 到 e ，均匀切分成 steps 份x = torch.normal(0, 3, (5, 3)) # torch.normal(mean:float, std:float, size:tuple)-&amp;gt;Tensor: 均值为 mean ，方差为 std ，大小为 size x = torch.Tensor(5, 3).uniform_(-1, 1) # 均匀分布 [from, to)# new_* 方法来创建对象x = torch.new_ones(5, 3, dtype=torch.double)# 根据现有的张量创建张量，重用输入张量的属性，例如 dtype ，除非设置新的值进行覆盖x = torch.randn_like(x, dtype=torch.float) # 覆盖 dtype ，但 size 相同# 获取 sizex.size() # torch.Size 返回值是 tuple 类型, 所以它支持 tuple 类型的所有操作运算# 加法x = torch.rand(5, 3)y = torch.rand(5, 3)# Method 1z = x + y# Method 2z = torch.add(x, y)# Method 3z = torch.empty(5, 3)torch.add(x, y, out=z) # 提供输出tensor作为参数# Method 4y.add_(x) # 会改变原变量的值# 索引x[:, 1] # 与 Numpy 索引方式相同x = torch.randn(5, 3).index_select(0, torch.linspace(0, 4, 2, dtype=torch.int32)) # .index_select(dim:int, index:Tensor(int32/64))-&amp;gt;Tensor: 从 dim 维选取 index 的数据x = x.masked_select(x&amp;gt;0) # .masked_select(mask)-&amp;gt;Tensor: 选取掩膜为 1 处的元素，不保留原始位置信息x = x.nonzero() # 返回非零元素的下标# torch.gather(input, dim, index:torch.long, out=None)-&amp;gt;Tensor：根据index，在dim维度上选取数据# out[i][j][k]...[i+dim]...[z] = input[i][j][k]...[index[i][j][k]...[z]]_{i+dim}...[z]t = torch.Tensor([[1,2],[3,4]])torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]])) # [[1 1] [4 3]] # index 中元素范围 [0, n_dim-1]，用来指定第 dim 维的选取的位置# 关于 torch.gather 的更多用法请参考教程：https://zhuanlan.zhihu.com/p/352877584# 改变张量的维度和大小x = torch.randn(4, 4)y = x.view(16) # x 和 y 共享数据z = x.view(-1, 8) # size：-1 从其他维度推断# x = x.squeeze()unsqueeze()注意： 任何以 _ 结尾的操作都会用结果替换原变量。例如：x.copy_(y) ， x.t_() ，都会改变 x 。 view() 返回的新 Tensor 与原 Tensor 虽然可能有不同的 size ，但是是共享 data 的（ view 仅仅是改变了对这个张量的观察角度，内部数据并未改变）。如果需要副本先使用 .clone() 。Python 数据类型转换如果你有只有一个元素的张量，使用 .item() 来得到 Python 数据类型的数值。x = torch.randn(1)print(x.item())Numpy 转换将一个 Torch Tensor 转换为 NumPy 数组是一件轻松的事，反之亦然。Torch Tensor 与 NumPy 数组共享底层内存地址，修改一个会导致另一个的变化。# Torch Tensor -&amp;gt; NumPy数组a = torch.ones(5)b = a.numpy()a.add_(1) # 此时 b 发生变化# NumPy Array -&amp;gt; Torch Tensora = np.ones(5)b = torch.from_numpy(a)np.add(a, 1, out=a) # 此时 a 发生变化Broadcasting当对两个形状不同的 Tensor 按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个 Tensor 形状相同后再按元素运算。x = torch.arange(1, 3).view(1, 2)y = torch.arange(1, 4).view(3, 1)z = x + y # torch.Size([3, 2])CUDA使用 .to 方法 可以将 Tensor 移动到任何设备中。# is_available 函数判断是否有 cuda 可以使用# `torch.device` 将张量移动到指定的设备中if torch.cuda.is_available(): device = torch.device(&quot;cuda&quot;) # 一个 CUDA 设备对象 y = torch.ones_like(x, device=device) # 直接从 GPU 创建张量 x = x.to(device) # 或者直接使用 `.to(&quot;cuda&quot;)` 将张量移动到 cuda 中 z = x + y print(z) print(z.to(&quot;cpu&quot;, torch.double)) # `.to` 也会对变量的类型做更改更多内容，请查看官网教程。Autograd：自动求导机制PyTorch 中所有神经网络的核心是 autograd 包，它为张量上的所有操作提供了自动求导。 它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行，并且每次迭代可以是不同的。在自动求导计算中有两个重要的类： Tensor 如果设置 .requires_grad 为 True，那么将会追踪所有对于该张量的操作。当完成计算后通过调用 .backward()，自动计算所有的梯度，这个张量的所有梯度将会自动积累到 .grad 属性。 为了防止跟踪历史记录（和使用内存），可以将代码块包装在 with torch.no_grad(): 中。 这在评估模型时特别有用，因为模型可能具有 requires_grad = True 的可训练参数，但是我们不需要梯度计算。 Function Tensor 和 Function 互相连接并生成一个非循环图，它表示和存储了完整的计算历史。 每个张量都有一个 .grad_fn 属性，这个属性引用了一个创建了 Tensor 的 Function ，即该 Tensor 是不是通过某些运算得到的，若是，则 grad_fn 返回一个与这些运算相关的对象（除非这个张量是用户手动创建的，即，这个张量的 grad_fn 是 None ）。 如果需要计算导数，你可以在 Tensor 上调用 .backward() 。 如果 Tensor 是一个标量（即它包含一个元素数据）则不需要为 backward() 指定任何参数， 但是如果它有更多的元素，你需要指定一个 gradient 参数来匹配张量的形状。 注意：在其他的文章中你可能会看到说将 Tensor 包裹到 Variable 中提供自动梯度计算， Variable 这个在 0.41 版中已经被标注为过期了，现在可以直接使用 Tensor ，官方文档在这里。requires_gradx = torch.ones(2, 2, requires_grad=True) # x.grad_fn = Noney = x + 2 # y.grad_fn = &amp;lt;AddBackward0 object at 0x...&amp;gt;z = y * y * 3 # z.grad_fn = &amp;lt;MulBackward0 object at 0x...&amp;gt;out = z.mean() # out.grad_fn = &amp;lt;MeanBackward0 object at 0x...&amp;gt;x 是直接创建的，所以么有 grad_fn ， y 作为操作的结果被创建，因此具有 grad_fn 。像 x 这样的节点被称为叶子节点，叶子节点对应的 grad_fn 是 None 。输入的 requires_grad 在没有给定参数的情况下默认是 False ，可以通过 requires_grad_() 来改变张量的 requires_grad 属性。如果输入的 requires_grad 是 False ，那么之后所有计算结果的变量的 requires_grad 属性都将是 False ，且 grad_fn 为 None。backward()在调用 y.backward() 时，如果 y 是标量，则不需要为 backward() 传入任何参数；否则，需要传入一个与 y 同形的 Tensor 。因为不允许张量对张量求导，只允许标量对张量求导，求导结果是和自变量同形的张量。在数学上，如果我们有向量值函数 $\\vec y = f(\\vec x)$，且 $\\vec y$ 关于 $\\vec x$ 的梯度是一个雅可比矩阵（Jacobian matrix）：\\(J = \\begin{pmatrix}\\frac{\\partial y_1}{\\partial x_1}&amp;amp;\\cdots&amp;amp;\\frac{\\partial y_1}{\\partial x_n}\\\\\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\\\frac{\\partial y_m}{\\partial x_1}&amp;amp;\\cdots&amp;amp;\\frac{\\partial y_m}{\\partial x_n}\\\\\\end{pmatrix}\\)一般来说，torch.autograd 就是用来计算 vector-Jacobian product 的工具。也就是说，给定任一向量 $\\vec v = (v_1\\ v_2\\ \\cdots\\ v_m)^T$ ，计算 $v^T \\cdot J$ 。如果 $v$ 恰好是标量函数 $l = g(\\vec y)$ 的梯度，也就是说 $v = (\\frac{\\partial l}{y_1}\\ \\cdots \\frac{\\partial l}{y_m})^T$ ，那么根据链式法则，vector-Jacobian product 是 $l$ 关于 $\\vec x$ 的梯度：\\(J^T \\cdot v = \\begin{pmatrix}\\frac{\\partial y_1}{\\partial x_1}&amp;amp;\\cdots&amp;amp;\\frac{\\partial y_1}{\\partial x_n}\\\\\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\\\frac{\\partial y_m}{\\partial x_1}&amp;amp;\\cdots&amp;amp;\\frac{\\partial y_m}{\\partial x_n}\\\\\\end{pmatrix}\\begin{pmatrix}\\frac{\\partial l}{\\partial x_1}\\\\\\vdots\\\\\\frac{\\partial l}{\\partial x_n}\\\\\\end{pmatrix}\\)（注意，$v^T \\cdot J$ 给出了一个行向量，可以通过 $J^T \\cdot v$ 将其视为列向量）vector-Jacobian product 这种特性使得将外部梯度返回到具有非标量输出的模型变得非常方便。以下是两个例子： 标量求导 x = torch.ones(2, 2, requires_grad=True)y = x + 2z = y * y * 3out = z.mean()out.backward() # 因为 out 是一个纯量（scalar），out.backward() 等于 out.backward(torch.tensor(1))print(x.grad) # tensor([[4.5000, 4.5000], [4.5000, 4.5000]]) 非标量求导 x = torch.randn(3, requires_grad=True)y = x * 2while y.data.norm() &amp;lt; 1000: y = y * 2gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)y.backward(gradients)print(x.grad) 在这个情形中，y 不再是个标量， torch.autograd 无法直接计算出完整的雅可比矩阵，但是如果我们只想要 vector-Jacobian product ，只需将向量作为参数传入 backward 。 中断梯度追踪with torch.no_grad(): 中的变量将不进入梯度计算。直接举个例子说明：x = torch.tensor(1.0, requires_grad=True)print(x, x.requires_grad)y1 = x ** 2print(y1, y1.requires_grad)with torch.no_grad(): y2 = x**2print(y2, y2.requires_grad)y3 = y1 + y2print(y3, y3.requires_grad)y3.backward()print(x.grad) # tensor(2.)此时 y3 的梯度经由 y1 （与 y2 无关）传播给 x ，因此 x 的梯度是 2 而不是 4 。tensor.data此外，如果我们想要修改 tensor 的数值，但是又不希望被 autograd 记录（即不会影响反向传播），那么我么可以对 tensor.data 进行操作。x = torch.tensor(1.0, requires_grad=True)print(x.data) # 依然是一个 tensorprint(x.data.requires_grad) # False，即独立于计算图之外y = 2 * xx.data *= 100 # 只改变了值，不会记录在计算图，所以不会影响梯度传播y.backward()print(x)print(x.grad)如果对 x 本身直接操作，将导致 x 叶子节点身份的丢失。更多内容，请查看官网教程。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考文档 标量，向量，矩阵与张量 torch.rand()、torch.randn()、torch.randint()、torch.randperm()用法 我对torch中的gather函数的一点理解 pytorch简介和准备知识作者：Harry-hhj，github主页：传送门" }, { "title": "Install dual-OS - Win10", "url": "/posts/Install-dual-OS_Win10/", "categories": "Tutorial, Dual OS", "tags": "install, os, win", "date": "2021-08-26 16:40:00 +0800", "snippet": "安装 Win10 双系统 本篇教程是基于 MacOS 系统安装 Win10 双系统的，当然也适用于 Win10 安装 Win10 双系统，如果你愿意的话，只需要去除和 MacOS 有关的特定内容就可以了。硬件要求： Macbook pro 2019（只要不是2015年前的苹果电脑应该都可以） Windows 虚拟机或主机（我使用的是虚拟机） 一块硬盘，至少 64 GB，接口 USB 3.0 及以上（机械硬盘或者 SSD ，推荐 SSD ，笔者使用的是 SamsumgSSD9801TB ） 外接 USB 鼠标和外接 USB 键盘，外接 USB 无线网卡（可选） 一个U盘或机械硬盘（ exFAT 格式），至少 1.5 TB ，也可以放在 SSD 的非系统分区中 电脑供电电源（过程非常耗电，请插电源操作） USB-C 拓展坞（可选，根据接口需要）软件要求： 启动转换助理（苹果系统自带） WTG 辅助工具（附件1） Windows 10 镜像（附件1）为了便于区分两个 Win 系统，以下将用于制作系统盘的 Windows 系统称作宿主系统，将新制作的 Windows 系统称作目标系统。前言Macbook pro 的存储空间是非常宝贵的，因为苹果的硬盘速度虽然高，价格也非常贵。而且，我也很不喜欢装个系统把硬盘弄糟，甚至把 Mac 系统弄坏，毕竟 Mac OS 才是我日常生活的主力。在经历了两年的虚拟机之后，我终于下决心试试装双系统了。备注：每次用 DiskGenius 操作分区后都需要右击左侧磁盘选择保存分区表，推荐对所有硬盘如此操作。科普机械硬盘和固态硬盘（SSD）和 U 盘机械硬盘和固态硬盘本质不同：机械硬盘本质是电磁存储，固态则是半导体存储。防震抗摔性不同：机械硬盘很怕摔，固态抗震。数据存储速度不同：固态读写速度比机械快。功耗不同：固态硬盘的功耗比机械硬盘低。重量不同：固态硬盘的重量比机械硬盘轻。噪音不同：机械硬盘有噪音，固态硬盘没有噪音。移动硬盘和U盘SSD 硬盘与 U 盘都采用了 Flash （闪存）作为储存介质，他们的区别如下：SSD 采用 SATA 接口主控，而绝大部分优盘采用 USB 接口主控。由于 U 盘和固态硬盘之间所使用的主控芯片、 Flash 颗粒的数量和缓存容量不同造成二者存储速度存在巨大差异。固态硬盘采用了多颗 Flash 颗粒组成，而其内部也是采用了类似于 RAID 的写入方式，可同时在不同的颗粒上写入或者读取数据。而U盘通常就是单通道的写入，所以在性能上完全没有办法和固态硬盘相提并论。U盘和固态硬盘所使用的Flash都有一定的写入次数寿命。一旦当写入次数达到这个数量之后，那么就无法再写入数据了，也就意味着U盘或者固态硬盘的损坏。SSD （固态硬盘）据的主控芯片均具备了一种平均写入数据的算法，以延长使用寿命。而 U 盘就是不具备平均写入数据功能，所以一旦 U 盘用来反复读写数据话，是非常容易造成损坏的。容量与价格不同。文件系统FAT32这一种格式是任何USB存储设备都会预装的文件系统，属 Windows 平台的传统文件格式，兼容性很好。即便 FAT32 格式兼容性好，但它不支持 4 GB 以上的文件，因此对于很多镜像文件或大视频文件之类的也会有无可奈何的状况。NTFSNTFS 格式却是 Windows 平台应用最广泛的文件格式，它的优点在于能够支持大容量文件和超大分区，且集合了很多高级的技术，其中包括长文件名、压缩分区、数据保护和恢复等等的功能。但它会减短闪存的寿命。exFATexFAT 格式才是最适合 U 盘的文件格式，它是微软为了闪存设备特地设计的文件系统，是 U 盘等移动设备最好的选择之一。SSD 和 U 盘同为闪存，但SSD还是用NTFS格式为好！好了，下面正式进入教程。准备工作 - WindowsSupportMacbook 的硬件在 Windows 上是不能直接使用的，因此需要获得相应的驱动程序，这个苹果系统已经有现成的了，我们下载就行。在苹果系统中打开“启动转换助理”，如下图：打开后在左上角点击操作-下载Windows支持软件，下载完毕后，将文件转存到一个 U 盘或机械硬盘上备用（注意容量，未压缩约为 1.26 GB ），以便后续文件传输。然后将待用的硬盘（SSD）全盘格式化为 exFAT 格式，不要含有多个分区，供后续使用。Windows镜像文件网上有很多，如果你是交大学生，附件1SW_DVD5_Win_Pro_Ent_Edu_N_10_1803_64BIT_ChnSimp_-2_MLF_X21-79700 中也包含了，可通过交大网络激活。激活方式：需要连接校园网或 VPN ，用管理员身份打开命令提示符（右击选择以管理员身份运行），进入 C:\\Windows\\System32 文件夹中，输入以下命令：cscript slmgr.vbs /skms kms.sjtu.edu.cncscript slmgr.vbs /ato激活成功。WinToGo 辅助工具将上述的 Windows 镜像文件复制到宿主系统（虚拟机）中，双击打开，这时系统会显示有个 DVD 驱动器，此时先不要操作。使用附件1中的 wtga5590 ，双击 exe 文件，注意网上 4.8 版本的 wtga 不能选择 windows 版本，所以不要使用。打开软件后，第一个候选框选择上图中的 DVD驱动器/sousrces/install.wim 。然后选择版本为 企业版 ，最后选择你的硬盘。右侧高级选项选择 传统 + UEFI+GPT ，其他可以选择默认。最后选择 部署 。需要分区的朋友可以在 分区 里进行设置，需要注意给系统盘留出足够的空间。也可以按之后的教程进行操作。会弹出一个窗口提示你整个硬盘会被格式化，让你确认，点击 是 即可。耐心等待制作完成。关闭安全选项在 MacOS 系统启动时，同时安装 Command + R ，进入到恢复助理的界面，选择知道密码的用户，输入密码后选择左上角的 实用工具 ，选择里面的 允许从外部介质启动 。同时将安全启动那里选择 无安全性 。不然可能会出现以下的错误：安装驱动关机，在开机时按住 option 键，选择 EFI 启动磁盘，然后就进入了 Windows 的启动界面，注意 第一次进入会自动重启，所以在重启时还需要按住 option 键。然后就像正常的 Windows 一样初始化就行了，唯一要注意的是此时 Mac 里自带的网卡、键盘和触控板统统不能使用，需要外接 USB 设备，这就是要准备 USB 鼠标键盘和无线网卡的原因。设置好后进入Win10 桌面，这时候鼠标键盘等依旧不能使用需要安装之前下载好的 Windows支持软件 。找到你U盘里复制过来的支持软件，打开文件夹找到 setup.exe ，双击打开安装 BootCamp 驱动。安装完后，如果遇到没有声音，使用搜索栏搜索 Apple Software Update，更新后应该能解决问题，再不行就多安装几次，再不行点击带❌的音量，自动搜索驱动、重启等，应该是能解决的。安装完驱动后成后已经可以正常使用键盘、鼠标、网卡等等。但是你可能发现无法自定义设置键盘背光、触控板功能等，这是因为 BootCamp 锁定了外置磁盘的控制面板设置。这时下载之前说过的 BootCamp 控制面板工具，名字为 AppleControlPanel.exe 。之后在目录 C:\\Windows\\System32 找到 AppleControlPanel.exe 这个文件，把它替换为之前下载的同名文件。这时候在进入 Boot Camp 控制面板就可以自定义设置触控板功能了。如果没有找到 Boot Camp 控制面板，就去 Mac 上重新下载 WindowsSupport 安装，就能解决。分区分卷如果硬盘过大时我们会希望将一部分硬盘分理出系统盘作为数据盘使用或留作他用，这是我们的操作如下： 首先在宿主系统中的搜索框输入此电脑，然后右键点击管理，如下图： 在新出现的窗口点击存储-&amp;gt;磁盘管理，找到目标磁盘（根据磁盘大小），右击选择压缩卷，将系统盘的容量压缩到你认为合适的大小，这里我预留了 350 GB （仅供参考）。 将多出来的空间右击选择新加卷，格式选 exFAT，即可。 在目标系统中进入同样的界面，重新删除卷，并新建卷，这么做的目的是为了分配盘符，不然会被隐藏，在目标系统中不可见。如果希望进行更细致的格式化可以使用附件1中的 DiskGenius 重新格式化，可以选择簇大小（对簇大小的理解就是：簇大小越大，读写速度越快，但小文件浪费的空间也更多，如果不知道直接选择默认就行）。如下图： （图中我留了 256GB 的未分配空间，操作的方法是使用 DiskGenius 对 DATA 盘新建分区，再通过磁盘管理来删除卷就行了。） 最终的结果如下图所示： 结果最终我的 Windows 界面如下：恭喜成功！如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考教程 为MacBook Pro制作WTG系统盘 在我的U盘上装了 win to go瞬间感觉相见恨晚（WTG安装最详细教程） ssd固态硬盘和U盘的区别是什么呢？ U盘FAT32、NTFS、exFAT格式的区别，你都知道么？如有问题欢迎来交流！作者：Harry-hhj，github主页：传送门 链接: https://pan.baidu.com/s/10wH1h5n9tHYNvo4rWq-7zA 提取码: nwcp &amp;#8617; &amp;#8617;2 &amp;#8617;3 &amp;#8617;4 &amp;#8617;5 " }, { "title": "Building your Blog too", "url": "/posts/Building-your-Blog/", "categories": "Tutorial, Jekyll", "tags": "install, jekyll", "date": "2021-08-24 08:00:00 +0800", "snippet": "按照本篇教程的步骤，搭建属于你自己的 jekyll-theme-chirpy 吧～（其他样式请按照相应的 README.md 进行操作）搭建 GitHub 博客第一步 安装环境按照 Jekyll Docs 官方教程完成环境的搭建，该教程是全英文教程，如果能看懂建议根据该教程操作（因为该教程会保持最新），遇到问题后再来参考本教程。如果对英文教程不熟悉的，可以使用 Chrome 浏览器打开后进行页面翻译。注意：官方教程中有些操作是在普通的句子中而非列表的形式给出，所以在查阅时无比认真阅读每一句话，不要跳句！Ubuntu安装 Ruby 和其他依赖：sudo apt install ruby-full build-essential zlib1g-dev将 gem 安装到当前用户下（不要以 root 用户安装），以下的命令将在 ~/.bashrc 中添加环境变量来指定 gem 的安装路径：echo &#39;# Install Ruby Gems to ~/gems&#39; &amp;gt;&amp;gt; ~/.bashrcecho &#39;export GEM_HOME=&quot;$HOME/gems&quot;&#39; &amp;gt;&amp;gt; ~/.bashrcecho &#39;export PATH=&quot;$HOME/gems/bin:$PATH&quot;&#39; &amp;gt;&amp;gt; ~/.bashrcsource ~/.bashrc查看 ruby 的版本： ruby -v ，确保其版本高于或等于 2.5.0 。最后，通过 gem 安装 jekyll 和 bundler ：gem install jekyll bundler查看 RubyGems 的版本： gem -v ，有版本输出代表安装成功。（可选）安装最新版本的 gcc 和 g++ 。首先添加 ppa 到库，这一步实际是添加了一个 ubuntu 的源：sudo add-apt-repository ppa:ubuntu-toolchain-r/testsudo apt-get update安装新版 gcc/g++ ，目前最新的版本号是 11 ：sudo apt install -y gcc-11 g++-11这里有个小技巧，加个参数 -y 表示不询问并同意，这样就不用在之后输入 y 确认了。查看 Ubuntu 原来的 gcc/g++ 版本，并记住（Ubuntu 20.04 默认应该是 9）：gcc -vg++ -v # 如果你的电脑安装了 g++ 的话默认情况下 Ubuntu 没有安装 g++ ，如果你希望 gcc/g++ 保持配对，可以通过 gcc -v 查看版本下载对应的 g++ 。我们需要将标准的 gcc/g++ 连接到我们期望的 gcc/g++ 程序，有两种连接方式建立连接： ln 命令创建软链接 cd /usr/binsudo rm gccsudo ln -s gcc-11 g++sudo rm g++sudo ln -s g++-11 g++ 通过 update-alternatives 建立文件关联 记住你刚刚查看到的原始版本号，以下命令中的 &amp;lt;版本号&amp;gt; 用下图中你查询到的数字替代： # 首先让系统知道我们安装了多个 gcc 版本sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-&amp;lt;版本号&amp;gt; &amp;lt;版本号*10&amp;gt;sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110# 使用交互方式的命令选择默认使用的版本，默认使用 auto 选择模式，系统将默认使用优先级最高的，无需修改直接按回车（enter）：sudo update-alternatives --config gcc # g++ 同理sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-&amp;lt;版本号&amp;gt; &amp;lt;版本号*10&amp;gt;sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 110sudo update-alternatives --config g++ 如果不小心有个命令写错了，那么（没关系，我也因为偷懒使用历史命令修改的时候少改了地方错过）： # 如果是优先级写错了，重新 --install 就行了# 如果是把 g++ 装到了 gcc 里或其他类似情况，然后重新 --install 就可以了： sudo update-alternatives --remove &amp;lt;装错的链接名gcc或g++&amp;gt; &amp;lt;装错的路径&amp;gt; 切换 gcc/g++ 版本： sudo update-alternatives --config gccsudo update-alternatives --config g++ 第二步 克隆仓库有两种搭建方式，这里只介绍第二种，因为我们的目的就是为了借助 Github Page 来发布博客： 从 RubyGems 安装：易于更新，隔离不相关的项目文件，可以专注于编写。 从 GitHub 克隆：自定义开发方便，但更新难，只适合web开发者。首先前往原项目仓库，点击屏幕右侧的 fork 按钮：这样，我们的代码库里就有了一个相同的仓库，唯一不同的这个仓库的所有权属于我们自己。找到这个仓库并点击进入。点击 Code ，复制网址，然后打开 Terminal 进入项目目录， git clone &amp;lt;网址&amp;gt; ，如果还没有装过 git 先安装一下：sudo apt install git安装 gem 依赖：cd jekyll-theme-chirpybundle然后执行脚本：bash tools/init.sh 如果你不打算在 Github Pages 部署博客，那么在这个命令后加上参数 --no-gh .这一步所执行的操作是： 删除 .travis.yml 、_post 文件夹下的文件、docs 文档 如果使用了 --no-gh 参数，那么目录 .github 会被删除，否则 .github/workflows/pages-deploy.yml.hook 被删除 .hook 后缀，然后删除 .github 中的其他文件和目录 自动 commit 本次操作第三步 修改设置主要修改 _config.yml 中的变量，例如： url：如果你需要部署在 Github Pages 上，那么请一定将 url 设置为 https://&amp;lt;your-github-username&amp;gt;.github.io avatar：头像，可以使用本地图片，放在 assets/img/favicons/ 目录下，并把此处网址改为相对路径 timezone lang：按照 http://www.lingoes.net/en/translator/langcode.htm 上的缩写设置，中文为 zh修改完后，你可以现在本地预览效果，然后再决定是否保存更改并同步到远程仓库中：bundle exec jekyll s或者使用 Docker 运行网站：docker run -it --rm \\ --volume=&quot;$PWD:/srv/jekyll&quot; \\ -p 4000:4000 jekyll/jekyll \\ jekyll serve打开浏览器访问 http://localhost:4000 。第四步 Github Pages 部署请先务必确保 url 设置正确。首先重新命名 Github 上的远程仓库的名字，修改为 &amp;lt;your-github-username&amp;gt;.github.io （不要加尖括号）。然后重新关联本地项目和远程仓库：git remote set-url https://&amp;lt;your-token&amp;gt;.github.com/&amp;lt;...&amp;gt;.github.io.gitGitHub 目前已经不支持密码登陆。至于 GitHub token 的使用方法，请参考此教程。由于比较简单，这里就不细讲了。如果你对 token 不懂，那么就按照以下步骤操作，这是一种比较不安全的做法，不符合安全理念和最小权限原则：点击网页右上角头像，选择 Settings ，点击左侧 Developer settings ，点击左侧 Personal access tokens ，点击 generate new token ，选择相应的权限（最简单的方法全选，日期设为不限），把生成的 token 复制到上面的 your-token 中就行了。注意，此 token 只能看到一次，请妥善保管，可重复使用。设置完毕后通过 git push 将本地的修改提交到远程仓库，这将触发 GitHub Actions workflow ，一旦操作完成，会产生一个新的分支 gh-pages 。在网页上点击项目的 settings ，找到 Pages ，选择 gh-pages 分支作为 publishing source ，如下图：点击 Github 上的链接就可以访问你的博客啦！第五步 设置百度统计之所以不使用官方推荐的 Google Analysis ，是因为在国内大部分地区都没有办法直接访问，这种统计也就失效了。因此，我选择了更加简便的 Baidu Analysis 来代替，一样可以达到效果。首先前往百度统计注册一个账号，注册完成后新建一个网站。之后会要填写以下信息： 网站域名：&amp;lt;your/github/username&amp;gt;.github.io 网站首页：https://&amp;lt;your/github/username&amp;gt;.github.io 剩下的随便写完后会会自动跳转到获取代码（如何没有自己点击跳转），选择复制代码。接下来修改个人博客项目，需要修改三个地方： 修改 _config.yml ，在其中加入： baidu-analysis: &amp;lt;your-token&amp;gt; 其中 就是那段复制的代码中 ```hm.src = &quot;https://hm.baidu.com/hm.js?...&quot; 后的那串字符。``` 在 _includes 目录下新建 baidu-analysis.html 文件，在其中输入： &amp;lt;!-- The BA snippet--&amp;gt;&amp;lt;script&amp;gt;var _hmt = _hmt || [];(function() { var hm = document.createElement(&quot;script&quot;); hm.src = &quot;https://hm.baidu.com/hm.js?f40851b91841f1abe810a63f8d41c2e2&quot;; var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(hm, s);})();&amp;lt;/script&amp;gt; 这里无需修改，直接复制即可。 在页头模版页面中安装百度统计，这里我选择了 head.html ，实际查看代码我发现 Google Analysis 是放在 js-selector.html 中的，但是该部分属于 body 而百度统计官方建议放入 head ，因此在 head.html 最后的 &amp;lt;/head&amp;gt; 前加入以下代码： &amp;lt;!-- BA --&amp;gt; &amp;lt;!-- The BA snippet--&amp;gt;&amp;lt;script&amp;gt;var _hmt = _hmt || [];(function() { var hm = document.createElement(&quot;script&quot;); hm.src = &quot;https://hm.baidu.com/hm.js?f40851b91841f1abe810a63f8d41c2e2&quot;; var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(hm, s);})();&amp;lt;/script&amp;gt; 如果你对代码整洁度有很高的要求（其实我就算是，只是配置更新太慢了就算了），你可以尝试在 js-selector.html 中的最后一个 if 语句块中加入以上代码。 至此就完成网站统计的配置了，由于更新 _config.yml 体现在网站上的时间比较久，因此需要耐心等待，笔者等了一个晚上。去百度统计点击首页代码状态检查，如果显示 代码安装正确 ，那么恭喜你，你可以查看你的个人博客的访问情况了。如果本篇教程中有任何不对的地方，欢迎联系我指正！（评论功能可能尚在开发中）如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "First Blog", "url": "/posts/First-Blog/", "categories": "Essay", "tags": "feelings, diary", "date": "2021-08-23 20:30:00 +0800", "snippet": "随笔第一篇博客，不讲技术，先来说说自己为什么要折腾这么一个博客，为了在以后的日子里都能回想起初心，然后好坚持下去。前几天凉快了一阵子，这两天又热了起来。没打算开空调，但这温度多少会让人有些烦躁。今早刚交了简历，想着闲来没事，哦其实也不是闲，就是想放松一下，就开始捣鼓起来。先是装了个 Ubuntu 20.04 的虚拟机，想着之前一直用的是 18.04 ，今天也体验个新鲜。装完觉得这有些简陋，或许是用惯了 Macbook 的缘故，就开始美化起桌面来。弄了小半个上午，总算是弄好了，花的时间也不是很多，弄完也没什么特别的成就感，只是觉得还算不错，但也有些设计不合理的地方。算了，既然是别人写的东西，能用就很不错了，那还有什么怨言呢。虚拟机确实很方便，但不如装个真正的系统让人觉得安心、有份量，前几天也尝试过好多次，一直没成功，想着先歇一歇，等哪天又有了三分钟的热情，在 2 分 59 秒里去把它搞定，暂且以后再说。下午弄得差不多了，突然脑子里想着弄个个人博客，原因？没什么原因，甚至连用来干什么都还没想好，或许是最近写了几篇教程的缘故，又头脑发热了。大腿一拍，说干就干。前些天也搜过一堆模版，比来比去觉得这个模版顺眼，功能也挺符合需求，就用这个了。以前有个前辈（论辈分算是同辈，他对我影响挺大的，有时间可以安排一个访谈）也搭过一个，我也用过，感觉应该不是很麻烦，谁知道这个想法，坑了我一个下午。其实官方教程一个字也没写错，但我总是能很好地漏掉字里行间里的隐藏操作。仓库重新建了四五次，每次都觉得要成，左看右看从页面里看出个 404 。把每句话耐心看完，一试，诶成了。小小的事情蕴涵着多少教训，多少人因为一个冲动带来了长久的生活影响，多少人曾被另一个或一群人影响着，多少人曾因高估自己而吃了苦头，多少人还能有一份平静做自己想做的事，哪怕没有人逼着催着，又有多少成功，就是那么一个不经意而已。博客搭好了，这是它最开始的样子：还算不错。但我也知道，它只是这样了，因为我没有能力去修改它，至少暂时没有。很多的项目，我拿来，会用，但不会改，却满足得不得了。这就是我创建这个博客的原因吧，督促自己有自己的东西，逼迫自己学习新的知识，然后竭尽所能地把它说明白，首先做一个自己的老师。我正渴望着吸收更多的知识，能够和更多的人侃侃而谈，能够被更多的人认可，能够有更大的价值。所以这个博客我不想放弃，也不能放弃。当然，除了技术分享，我还会在这里发些随笔、人生感悟，让自己的博客更加有特色些。如果有志同道合、兴趣相同的朋友，也欢迎交流、投稿，我会在每篇文章下注明作者和联系方式。有关格式规范，请查看本项目 README 文档。总之，我要开始新的旅途了。现在的社会就是这样：意识到自己倾尽全部也无法改变一些现实时会想躺平，但是却又不能心安理得地躺平，于是一直陷入焦虑、浮躁。我希望在这里的世界是豁达平静的，这是一个被精心打造的世界，每个人都能在这里收获独有的回忆，然后满载而归。如果觉得本博客不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "TODO", "url": "/posts/TODO/", "categories": "NoUse", "tags": "", "date": "2000-01-01 00:00:00 +0800", "snippet": "说明Oops！跳转至的该篇教程正在排队出炉中，抱歉！作者：Harry-hhj，github主页：传送门" } ]
